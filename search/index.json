[{"categories":["Go"],"contents":"本文主要分析了 Golang 中的一个第三方库，防缓存击穿利器 singleflight，包括基本使用和源码分析。\n1. 缓存击穿 平时开发中为了提升性能，减轻DB压力，一般会给热点数据设置缓存，如 Redis，用户请求过来后先查询 Redis，有则直接返回，没有就会去查询数据库，然后再写入缓存。\n大致流程如下图所示：\n以上流程存在一个问题，cache miss 后查询DB和将数据再次写入缓存这两个步骤是需要一定时间的，这段时间内的后续请求也会出现 cache miss，然后走同样的逻辑。\n这就是缓存击穿：某个热点数据缓存失效后，同一时间的大量请求直接被打到的了DB，会给DB造成极大压力，甚至直接打崩DB。\n常见的解决方案是加锁，cache miss 后请求DB之前必须先获取分布式锁，取锁失败说明是有其他请求在查询DB了，当前请求只需要循环等待并查询Redis检测取锁成功的请求把数据回写到Redis没有，如果有的话当前请求就可以直接从缓存中取数据返回了。\n2. singleflight 虽然加锁能解决问题，但是太重了，而且逻辑比较复杂，又是加锁又是等待的。\n相比之下 singleflight 就是一个轻量级的解决方案。\nDemo如下：\npackage main import ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; \u0026#34;golang.org/x/sync/singleflight\u0026#34; ) var ( g singleflight.Group ErrCacheMiss = errors.New(\u0026#34;cache miss\u0026#34;) ) func main() { var wg sync.WaitGroup wg.Add(10) // 模拟10个并发 for i := 0; i \u0026lt; 10; i++ { go func() { defer wg.Done() data, err := load(\u0026#34;key\u0026#34;) if err != nil { log.Print(err) return } log.Println(data) }() } wg.Wait() } // 获取数据 func load(key string) (string, error) { data, err := loadFromCache(key) if err != nil \u0026amp;\u0026amp; err == ErrCacheMiss { // 利用 singleflight 来归并请求 v, err, _ := g.Do(key, func() (interface{}, error) { data, err := loadFromDB(key) if err != nil { return nil, err } setCache(key, data) return data, nil }) if err != nil { log.Println(err) return \u0026#34;\u0026#34;, err } data = v.(string) } return data, nil } // getDataFromCache 模拟从cache中获取值 cache miss func loadFromCache(key string) (string, error) { return \u0026#34;\u0026#34;, ErrCacheMiss } // setCache 写入缓存 func setCache(key, data string) {} // getDataFromDB 模拟从数据库中获取值 func loadFromDB(key string) (string, error) { fmt.Println(\u0026#34;query db\u0026#34;) unix := strconv.Itoa(int(time.Now().UnixNano())) return unix, nil } 结果如下：\nquery db 2021/07/17 11:04:13 1626491053454483100 2021/07/17 11:04:13 1626491053454483100 2021/07/17 11:04:13 1626491053454483100 2021/07/17 11:04:13 1626491053454483100 2021/07/17 11:04:13 1626491053454483100 2021/07/17 11:04:13 1626491053454483100 2021/07/17 11:04:13 1626491053454483100 2021/07/17 11:04:13 1626491053454483100 2021/07/17 11:04:13 1626491053454483100 2021/07/17 11:04:13 1626491053454483100 可以看到 10 个请求都获取到了结果，并且只有一个请求去查询数据库，极大的减轻了DB压力。\n3. 源码分析 这个库的实现很简单，除去注释大概就 100 来行代码，但是功能很强大，值得学习。\nGroup type Group struct { mu sync.Mutex // protects m m map[string]*call // lazily initialized } Group 结构体由一个互斥锁和一个 map 组成，可以看到注释 map 是懒加载的，所以 Group 只要声明就可以使用，不用进行额外的初始化零值就可以直接使用。\ntype call struct { wg sync.WaitGroup // 函数返回值和err信息 val interface{} err error // 是否调用了 forget 方法 forgotten bool // 记录这个 key 被分享了多少次 dups int chans []chan\u0026lt;- Result } call 保存了当前调用对应的信息，map 的键就是我们调用 Do 方法传入的 key\nDo func (g *Group) Do(key string, fn func() (interface{}, error)) (v interface{}, err error, shared bool) { g.mu.Lock() if g.m == nil { // 懒加载 g.m = make(map[string]*call) } // 先判断 key 是否已经存在 if c, ok := g.m[key]; ok { // 存在则说明有其他请求在同步执行，本次请求只需要等待即可 c.dups++ g.mu.Unlock() c.wg.Wait() // / 等待最先进来的那个请求执行完成，因为需要完成后才能获取到结果，这里用 wg 来阻塞，避免了手动写一个循环等待的逻辑 // 这里区分 panic 错误和 runtime 的错误，避免出现死锁，后面可以看到为什么这么做 if e, ok := c.err.(*panicError); ok { panic(e) } else if c.err == errGoexit { runtime.Goexit() } // 最后直接从 call 对象中取出数据并返回 return c.val, c.err, true } // 如果 key 不存在则会走到这里 new 一个 call 并执行 c := new(call) c.wg.Add(1) g.m[key] = c // 注意 这里在 Unlock 之前就把 call 写到 m 中了，所以 这部分逻辑只有第一次请求会执行 g.mu.Unlock() // 然后我们调用 doCall 去执行 g.doCall(c, key, fn) return c.val, c.err, c.dups \u0026gt; 0 } doCall 这个方法比较灵性，通过两个 defer 巧妙的区分了到底是发生了 panic 还是用户主动调用了 runtime.Goexit，具体信息见https://golang.org/cl/134395\nfunc (g *Group) doCall(c *call, key string, fn func() (interface{}, error)) { // 首先这两个 bool 用于标记是否正常返回或者触发了 recover normalReturn := false recovered := false defer func() { // 如果既没有正常执行完毕，又没有 recover 那就说明需要直接退出了 if !normalReturn \u0026amp;\u0026amp; !recovered { c.err = errGoexit } c.wg.Done() // 这里 done 之后前面的所有 wait 都会返回了 g.mu.Lock() defer g.mu.Unlock() // forgotten 默认值就是 false，所以默认就会调用 delete 移除掉 m 中的 key if !c.forgotten { // 然后这里也很巧妙，前面先调用了 done，于是所有等待的请求都返回了，那么这个c也没有用了，所以直接 delete 把这个 key 删掉，让后续的请求能再次触发 doCall，而不是直接从 m 中获取结果返回。 delete(g.m, key) } if e, ok := c.err.(*panicError); ok { // 如果返回的是 panic 错误，为了避免 channel 死锁，我们需要确保这个 panic 无法被恢复 if len(c.chans) \u0026gt; 0 { go panic(e) select {} // Keep this goroutine around so that it will appear in the crash dump. } else { panic(e) } } else if c.err == errGoexit { // 如果是exitError就直接退出 } else { // 这里就是正常逻辑了,往 channel 里写入数据 for _, ch := range c.chans { ch \u0026lt;- Result{c.val, c.err, c.dups \u0026gt; 0} } } }() func() { // 使用匿名函数，保证下面的 defer 能在上一个defer之前执行 defer func() { // 如果不是正常退出那肯定是 panic 了 if !normalReturn { // 如果 panic 了我们就 recover 掉，然后 new 一个 panic 的错误后面在上层重新 panic if r := recover(); r != nil { c.err = newPanicError(r) } } }() c.val, c.err = fn() // 如果我们传入的 fn 正常执行了 normalReturn 肯定会被修改为 true // 所以 defer 里可以通过这个标记来判定是否 panic 了 normalReturn = true }() // 如果 normalReturn 为 false 就表示，我们的 fn panic 了 // 如果执行到了这一步，也说明我们的 fn 也被 recover 住了，不是直接 runtime exit if !normalReturn { recovered = true } } 逻辑还是比较复杂，我们分开来看，简化后代码如下：\nfunc main() { defer func() { fmt.Println(\u0026#34;defer 1\u0026#34;) }() func() { defer func() { fmt.Println(\u0026#34;defer 2\u0026#34;) }() fmt.Println(\u0026#34;fn\u0026#34;) }() fmt.Println(\u0026#34;根据 normalReturn 标记给 recover 赋值\u0026#34;) } 第一个点就是匿名函数：使用匿名函数，保证 defer 2 能在上一个 defer 1 之前执行。\n因为 defer 1里面需要用到 normalReturn 标记，而这个标记又是在 defer2 中 处理的。同时为了捕获 fn 里的 panic 又必须使用 defer 来处理，所以用了一个匿名函数。\nGo 中的 defer 是先进后出的，所以必须用 匿名函数保证 defer2 和 defer1 不在一个 函数里，这样 defer 2就可以先执行了。\n正常执行顺序为: fn–\u0026gt;defer2–\u0026gt;根据 normalReturn 标记给 recover 赋值–\u0026gt;defer1\n第二个就是用双重 defer 区分 panic 和 runtime.Goexit。\nfn 正常执行后就会将 normalReturn 赋值为 true，然后 defer2 里根据 normalReturn 值判断 fn 是否 panic，如果 panic 了就进行 recover 捕获掉这个panic，然后把error替换为自定义的 panicError。\n并且根据 normalReturn 的值来对 recovered 标记进行赋值。\n最后第一个 defer 就可以根据 normalReturn + recovered 这两个标记和 err 是否为 panicError 来判断是 fn 里发生了 panic 还是说调用了 runtime.Goexit。\n第三个点就是 map 的移除：\nc.wg.Done() g.mu.Lock() defer g.mu.Unlock() if !c.forgotten { delete(g.m, key) } 光看这里看不出具体细节，需要结合前面 Do 方法中的这段逻辑\nif c, ok := g.m[key]; ok { c.dups++ g.mu.Unlock() c.wg.Wait() return c.val, c.err, true } 首先doCall 中调用了c.wg.Done(),然后 Do 中的阻塞在c.wg.Wait() 这里的大量请求就全部返回了，直接就 return 了。\n然后 doCall 中再调用delete(g.m, key) 把 key 从 m 中移除掉。\n通过这个done巧妙的让 Do 中的wait返回后直接把 key 移除掉，这样后续使用同样 key 的请求在执行c, ok := g.m[key]判断时就会重新调用 doCall 方法，再执行一次 fn 了。\n如果不移除就会导致后续请求直接从 m 这里取到数据返回了，根本不会执行 fn 去db中查最新的数据，而且 m 中的数据也会越堆积越多。\nDoChan 和 do 唯一的区别是 go g.doCall(c, key, fn),但对起了一个 goroutine 来执行，并通过 channel 来返回数据，这样外部可以自定义超时逻辑，防止因为 fn 的阻塞，导致大量请求都被阻塞。\nfunc (g *Group) DoChan(key string, fn func() (interface{}, error)) \u0026lt;-chan Result { ch := make(chan Result, 1) g.mu.Lock() if g.m == nil { g.m = make(map[string]*call) } if c, ok := g.m[key]; ok { c.dups++ c.chans = append(c.chans, ch) g.mu.Unlock() return ch } c := \u0026amp;call{chans: []chan\u0026lt;- Result{ch}} c.wg.Add(1) g.m[key] = c g.mu.Unlock() go g.doCall(c, key, fn) return ch } Forget 手动移除某个 key，让后续请求能走 doCall 的逻辑，而不是直接阻塞。\nfunc (g *Group) Forget(key string) { g.mu.Lock() if c, ok := g.m[key]; ok { c.forgotten = true } delete(g.m, key) g.mu.Unlock() } 4. 注意事项 1. 阻塞 singleflight 内部使用 waitGroup 来让同一个 key 的除了第一个请求的后续所有请求都阻塞。直到第一个请求执行 fn 返回后，其他请求才会返回。\n这意味着，如果 fn 执行需要很长时间，那么后面的所有请求都会被一直阻塞。\n这时候我们可以使用 DoChan 结合 ctx + select 做超时控制\nfunc loadChan(ctx context.Context,key string) (string, error) { data, err := loadFromCache(key) if err != nil \u0026amp;\u0026amp; err == ErrCacheMiss { // 使用 DoChan 结合 select 做超时控制 result := g.DoChan(key, func() (interface{}, error) { data, err := loadFromDB(key) if err != nil { return nil, err } setCache(key, data) return data, nil }) select { case r := \u0026lt;-result: return r.Val.(string), r.Err case \u0026lt;-ctx.Done(): return \u0026#34;\u0026#34;, ctx.Err() } } return data, nil } 2. 请求失败 singleflight 的实现为，如果第一个请求失败了，那么后续所有等待的请求都会返回同一个 error。\n实际上可以根据下游能支撑的 rps 定时 forget 一下 key，让更多的请求能有机会走到后续逻辑。\ngo func() { time.Sleep(100 * time.Millisecond) g.Forget(key) }() 比如1秒内有100个请求过来，正常是第一个请求能执行queryDB，后续99个都会阻塞。\n增加这个 Forget 之后，每 100ms 就能有一个请求执行 queryDB，相当于是多了几次尝试的机会，相对的也给DB造成了更大的压力，需要根据具体场景进去取舍。\n5. 参考 https://www.lixueduan.com/posts/go/singleflight/\n","permalink":"https://www.iarno.cn/article/go-singleflight/","tags":[],"title":"golang高并发singleflight防缓存击穿"},{"categories":["Nginx"],"contents":"Nginx支持TLS1.3，及0-RTT测试。\n软件版本 需要将openssl编译到nginx中, nginx -V命令查看编译信息。\nnginx/1.20.2\nopenssl-1.1.1w\nnginx.conf # 为防止重放除了GET、HEAD请求全都返回HTTP状态码425(浏览器会默认重发1次请求) map $ssl_early_data$request_method $early_data_non_idempotent { \u0026#34;1POST\u0026#34; 1; \u0026#34;1PUT\u0026#34; 1; \u0026#34;1DELETE\u0026#34; 1; \u0026#34;1PATCH\u0026#34; 1; \u0026#34;1OPTIONS\u0026#34; 0; \u0026#34;1GET\u0026#34; 0; \u0026#34;1HEAD\u0026#34; 0; default 0; } server { listen 443 ssl http2; server_name www.iarno.cn; server_tokens off; keepalive_timeout 5; ......省略 include /usr/local/nginx/conf/http/general/ssl.conf; ssl_certificate /usr/local/nginx/ssl/www.iarno.cn.crt; ssl_certificate_key /usr/local/nginx/ssl/www.iarno.cn.key; ......省略 access_log logs/https.log combinedio buffer=4k; error_log logs/https_error.log; location / { if ($early_data_non_idempotent) { return 425; # Non-idempotent operations return 425 Too Early } include /usr/local/nginx/conf/https_proxy.conf; ......省略 } } ssl.conf ssl_stapling on; ssl_session_tickets on; # 是否复用sesssion ticket, openssl发送early data数据后每次会新生成session ssl_early_data on; # 开发early data (0-RTT) ssl_session_ticket_key /usr/local/nginx/conf/ssl_session_ticket.key; ssl_session_timeout 10m; # early_data过期时间 ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers \u0026#39;TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_128_GCM_SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:ECDHE-RSA-DES-CBC3-SHA:ECDHE-ECDSA-DES-CBC3-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:DES-CBC3-SHA:HIGH:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA\u0026#39;; ssl_prefer_server_ciphers on; https_proxy.conf proxy_set_header Connection \u0026#34;\u0026#34;; proxy_set_header Host $server_name; proxy_set_header Early-Data $ssl_early_data; # 设置early data标识 proxy_connect_timeout 5s; proxy_send_timeout 5s; proxy_read_timeout 5s; TLS1.3验证 https://www.ssllabs.com/ssltest/analyze.html?d=www.taobao.com\u0026latest\nhttps://github.com/drwetter/testssl.sh\n➜ testssl.sh git:(3.2) ✗ ./testssl.sh -p www.taobao.com ########################################################### testssl.sh 3.2rc3 from https://testssl.sh/dev/ (1dbd9b8 2024-07-18 09:09:13) This program is free software. Distribution and modification under GPLv2 permitted. USAGE w/o ANY WARRANTY. USE IT AT YOUR OWN RISK! Please file bugs @ https://testssl.sh/bugs/ ########################################################### Using \u0026#34;OpenSSL 1.0.2-bad (1.0.2k-dev)\u0026#34; [~183 ciphers] xxxx:./bin/openssl.Darwin.x86_64 (built: \u0026#34;Sep 3 14:46:36 2022\u0026#34;, platform: \u0026#34;darwin64-x86_64-cc\u0026#34;) Testing all IPv4 addresses (port 443): 119.188.122.194 119.188.122.195 ----------------------------------------------------------------------------------------------- Start 2024-07-25 15:59:51 --\u0026gt;\u0026gt; 119.188.122.194:443 (www.taobao.com) \u0026lt;\u0026lt;-- Further IP addresses: 119.188.122.195 2408:8719:64:54:3::3da 2408:8719:64:54:3::3db rDNS (119.188.122.194): -- Service detected: HTTP Testing protocols via sockets except NPN+ALPN SSLv2 not offered (OK) SSLv3 not offered (OK) TLS 1 offered (deprecated) TLS 1.1 offered (deprecated) TLS 1.2 offered (OK) TLS 1.3 offered (OK): final NPN/SPDY h2, http/1.1 (advertised) ALPN/HTTP2 h2, http/1.1 (offered) Done 2024-07-25 15:59:59 [0014s] --\u0026gt;\u0026gt; 119.188.122.194:443 (www.taobao.com) \u0026lt;\u0026lt;-- ----------------------------------------------------------------------------------------------- Start 2024-07-25 15:59:59 --\u0026gt;\u0026gt; 119.188.122.195:443 (www.taobao.com) \u0026lt;\u0026lt;-- Further IP addresses: 119.188.122.194 2408:8719:64:54:3::3da 2408:8719:64:54:3::3db rDNS (119.188.122.195): -- Service detected: HTTP Testing protocols via sockets except NPN+ALPN SSLv2 not offered (OK) SSLv3 not offered (OK) TLS 1 offered (deprecated) TLS 1.1 offered (deprecated) TLS 1.2 offered (OK) TLS 1.3 offered (OK): final NPN/SPDY h2, http/1.1 (advertised) ALPN/HTTP2 h2, http/1.1 (offered) Done 2024-07-25 16:00:08 [0023s] --\u0026gt;\u0026gt; 119.188.122.195:443 (www.taobao.com) \u0026lt;\u0026lt;-- ----------------------------------------------------------------------------------------------- Done testing now all IP addresses (on port 443): 119.188.122.194 119.188.122.195 Early Data(0-RTT)验证 openssl验证 # 第一步 ➜ ~ openssl s_client -connect www.taobao.com:443 -tls1_3 -sess_out session.pem Connecting to 119.188.122.195 CONNECTED(00000006) depth=2 C=BE, O=GlobalSign nv-sa, OU=Root CA, CN=GlobalSign Root CA verify return:1 depth=1 C=BE, O=GlobalSign nv-sa, CN=GlobalSign Organization Validation CA - SHA256 - G3 verify return:1 depth=0 C=CN, ST=ZheJiang, L=HangZhou, O=Alibaba (China) Technology Co., Ltd., CN=*.tbcdn.cn verify return:1 --- Certificate chain 0 s:C=CN, ST=ZheJiang, L=HangZhou, O=Alibaba (China) Technology Co., Ltd., CN=*.tbcdn.cn i:C=BE, O=GlobalSign nv-sa, CN=GlobalSign Organization Validation CA - SHA256 - G3 a:PKEY: rsaEncryption, 2048 (bit); sigalg: RSA-SHA256 v:NotBefore: Jun 19 09:06:02 2024 GMT; NotAfter: Jul 21 09:06:01 2025 GMT 1 s:C=BE, O=GlobalSign nv-sa, CN=GlobalSign Organization Validation CA - SHA256 - G3 i:C=BE, O=GlobalSign nv-sa, OU=Root CA, CN=GlobalSign Root CA a:PKEY: rsaEncryption, 2048 (bit); sigalg: RSA-SHA256 v:NotBefore: Sep 4 00:00:00 2015 GMT; NotAfter: Sep 4 00:00:00 2025 GMT --- Server certificate -----BEGIN CERTIFICATE----- ......省略 -----END CERTIFICATE----- subject=C=CN, ST=ZheJiang, L=HangZhou, O=Alibaba (China) Technology Co., Ltd., CN=*.tbcdn.cn issuer=C=BE, O=GlobalSign nv-sa, CN=GlobalSign Organization Validation CA - SHA256 - G3 --- No client certificate CA names sent Peer signing digest: SHA256 Peer signature type: RSA-PSS Server Temp Key: X25519, 253 bits --- SSL handshake has read 4600 bytes and written 332 bytes Verification: OK --- New, TLSv1.3, Cipher is TLS_AES_256_GCM_SHA384 Server public key is 2048 bit This TLS version forbids renegotiation. Compression: NONE Expansion: NONE No ALPN negotiated Early data was not sent Verify return code: 0 (ok) --- --- Post-Handshake New Session Ticket arrived: SSL-Session: ......省略 Start Time: 1721893373 Timeout : 7200 (sec) Verify return code: 0 (ok) Extended master secret: no Max Early Data: 16384 --- read R BLOCK --- Post-Handshake New Session Ticket arrived: SSL-Session: ......省略 Start Time: 1721893373 Timeout : 7200 (sec) Verify return code: 0 (ok) Extended master secret: no Max Early Data: 16384 --- read R BLOCK closed # 第二步 ➜ ~ echo -e \u0026#34;GET / HTTP/1.1\\r\\nHost: www.taobao.com\\r\\n\\r\\n\u0026#34; \u0026gt; early_data.txt ➜ ~ # 第三步 ➜ ~ openssl s_client -connect www.taobao.com:443 -tls1_3 -sess_in session.pem -early_data early_data.txt Connecting to 119.188.122.194 CONNECTED(00000006) --- Server certificate -----BEGIN CERTIFICATE----- ......省略 -----END CERTIFICATE----- subject=C=CN, ST=ZheJiang, L=HangZhou, O=Alibaba (China) Technology Co., Ltd., CN=*.tbcdn.cn issuer=C=BE, O=GlobalSign nv-sa, CN=GlobalSign Organization Validation CA - SHA256 - G3 --- No client certificate CA names sent Server Temp Key: X25519, 253 bits --- SSL handshake has read 249 bytes and written 728 bytes Verification: OK --- Reused, TLSv1.3, Cipher is TLS_AES_256_GCM_SHA384 Server public key is 2048 bit This TLS version forbids renegotiation. Compression: NONE Expansion: NONE No ALPN negotiated Early data was accepted Verify return code: 0 (ok) --- HTTP/1.1 200 OK Server: Tengine Content-Type: text/html; charset=utf-8 Transfer-Encoding: chunked Connection: keep-alive Date: Thu, 25 Jul 2024 07:44:31 GMT x-server-id: 28c3d6b2523ca52c32ad72931842b19a621c8cdfdfbcaabcd5562acb7211986218860f5b9ea54579 x-air-hostname: air-ual033043202123.center.na610 x-air-trace-id: 7b06169817218934709936299e Cache-Control: max-age=0, s-maxage=118 x-node: 9c0775731c8445d0bdf09cefd3e4bbf3 x-eagleeye-id: 7b06169817218934709936299e x-retmsg: ok x-content-type: text/html; charset=utf-8 streaming-parser: open x-retcode: SUCCESS x-readtime: 178 x-via: cn5026.l1, cache13.cn5026, l2nu16-1.l2, cache21.l2nu16-1, wormholesource033102016177.center.na610 x-air-source: proxy x-xss-protection: 1; mode=block Strict-Transport-Security: max-age=31536000 Ups-Target-Key: air-ual.vipserver X-protocol: HTTP/1.1 EagleEye-TraceId: 7b06169817218934709936299e s-brt: 181 Via: cache21.l2nu16-1[212,162,304-0,C], cache14.l2nu16-1[167,0], cache4.cn6806[0,0,200-0,H], cache20.cn6806[1,0] Vary: Accept-Encoding Vary: Ali-Detector-Type, X-Host, Accept-Encoding, Origin etag: W/\u0026#34;bf15d-yE/eVpg40kEzpV7XQBu+BBmxaWc\u0026#34; Age: 54 Ali-Swift-Global-Savetime: 1721893471 X-Cache: HIT TCP_MEM_HIT dirn:-2:-2 X-Swift-SaveTime: Thu, 25 Jul 2024 07:44:31 GMT X-Swift-CacheTime: 118 x-air-pt: pt0 Timing-Allow-Origin: * EagleId: 77bc7a9917218935251046825e 7a84 ......... 页面源代码 0 --- Post-Handshake New Session Ticket arrived: # 如果nginx配置ssl_session_tickets=off才会有次内容，每次会新生成session SSL-Session: ......省略 Start Time: 1721893527 Timeout : 7200 (sec) Verify return code: 0 (ok) Extended master secret: no Max Early Data: 16384 --- read R BLOCK C097125AF87F0000:error:0A000126:SSL routines::unexpected eof while reading:ssl/record/rec_layer_s3.c:692: Chrome浏览器验证 chrome://flags/\n开启TLS1.3 Early Data，默认为关闭状态。\n修改nginx日志格式\nlog_format combinedio \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#39; \u0026#39;\u0026#34;$request\u0026#34; $status $body_bytes_sent \u0026#39; \u0026#39;\u0026#34;$http_referer\u0026#34; \u0026#34;$http_user_agent\u0026#34; $request_length $request_time $upstream_response_time $ssl_early_data\u0026#39;; # $ssl_early_data 访问日志新增early data标识 参考 https://blog.csdn.net/SkyChaserYu/article/details/105840504\nhttps://www.cnblogs.com/wusanga/p/17386098.html\nhttps://imququ.com/post/enable-tls-1-3.html\n","permalink":"https://www.iarno.cn/article/nginx-tls1.3/","tags":[],"title":"nginx支持TLS1.3协议"},{"categories":["Linux"],"contents":"这篇文章介绍了如何使用cURL工具获取请求和响应时间。首先，它解释了cURL输出的各个时间参数的含义，包括DNS解析时间、TCP连接建立时间、上层协议连接时间、请求开始到响应开始的时间、请求开始到第一个字节传输的时间，以及整个请求的总时间。然后，文章详细介绍了如何使用cURL进行请求，包括创建一个格式化的输出文件，以及如何发起请求。最后，它解释了请求命令中的各个参数的作用。\n一、文本输出示例 time_namelookup: 0.001s time_connect: 0.037s time_appconnect: 0.000s time_pretransfer: 0.037s time_redirect: 0.000s time_starttransfer: 0.092s ---------- time_total: 0.164s time_namelookup：DNS域名解析的时间，就是把https://ianro.cn转换成ip地址的过程 time_connect：TCP 连接建立的时间，就是三次握手的时间 time_appconnect：SSL/SSH等上层协议建立连接的时间，比如 connect/handshake 的时间 time_pretransfer：从请求开始到响应开始传输的时间 time_starttransfer：从请求开始到第一个字节将要传输的时间 time_total：这次请求花费的全部时间 二、使用 2.1 创建一个文本文件curl-format.txt， 粘贴下面内容 time_namelookup: %{time_namelookup}s\\n time_connect: %{time_connect}s\\n time_appconnect: %{time_appconnect}s\\n time_pretransfer: %{time_pretransfer}s\\n time_redirect: %{time_redirect}s\\n time_starttransfer: %{time_starttransfer}s\\n ----------\\n time_total: %{time_total}s\\n 2.2 发起请求 curl -w \u0026#34;@curl-format.txt\u0026#34; -o /dev/null -s \u0026#34;http://iarno.cn/\u0026#34; -w \u0026quot;@curl-format.txt\u0026quot; 通知cURL使用格式化的输出文件 -o /dev/null 将请求的输出重定向到/dev/null -s 通知cURL不显示进度条 \u0026quot;https://iarno.cn/\u0026quot; 是我们请求的URL，请使用引号包围（尤其当你的URL包含\u0026amp;查询字符串） 三、参考 https://cloud.tencent.com/developer/article/1919554\n","permalink":"https://www.iarno.cn/article/curl/","tags":[],"title":"使用cURL获得请求和响应时间"},{"categories":["Mysql"],"contents":"这篇文章主要介绍了Golang数据库连接池的四个参数：maxOpenConns、maxIdleConns、maxIdleTime、maxLifeTime的设置和使用。其中，maxOpenConns是连接池最多同时打开的连接数，maxIdleConns是连接池里最大空闲连接数，maxIdleTime是连接池里面的连接最大空闲时长，maxLifeTime是连接池里面的连接最大存活时长。文章还详细解释了这些参数的设置原则和注意事项。\nSetMaxOpenConns(maxOpenConns) 连接池最多同时打开的连接数。\n这个maxOpenConns理应要设置得比mysql服务器的max_connections值要小。\n一般设置为： 服务器cpu核心数 * 2 + 服务器有效磁盘数。参考这里\n可用show variables like \u0026lsquo;max_connections\u0026rsquo;; 查看服务器当前设置的最大连接数。\nSetMaxIdleConns(maxIdleConns) 连接池里最大空闲连接数。必须要比maxOpenConns小；\nSetConnMaxIdleTime(maxIdleTime) 连接池里面的连接最大空闲时长。\n当连接持续空闲时长达到maxIdleTime后，该连接就会被关闭并从连接池移除，哪怕当前空闲连接数已经小于SetMaxIdleConns(maxIdleConns)设置的值。\n连接每次被使用后，持续空闲时长会被重置，从0开始从新计算；\n用show processlist; 可用查看mysql服务器上的连接信息，Command表示连接的当前状态，Command为Sleep时表示休眠、空闲状态，Time表示此状态的已持续时长；\nSetConnMaxLifetime(maxLifeTime) 连接池里面的连接最大存活时长。\nmaxLifeTime必须要比mysql服务器设置的wait_timeout小，否则会导致golang侧连接池依然保留已被mysql服务器关闭了的连接。\nmysql服务器的wait_timeout默认是8 hour，可通过show variables like \u0026lsquo;wait_timeout\u0026rsquo;查看。\n转载 https://www.cnblogs.com/gitfong/p/13722204.html\n","permalink":"https://www.iarno.cn/article/golang%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE/","tags":[],"title":"golang数据库连接池参数设置"},{"categories":["其他"],"contents":"Stable Diffusion是一个文本到图像的潜在扩散模型，由CompVis、Stability AI和LAION的研究人员和工程师创建。它使用来自LAION-5B数据库子集的512x512图像进行训练。使用这个模型，可以生成包括人脸在内的任何图像，因为有开源的预训练模型，所以我们也可以在自己的机器上运行它。\n一、本地安装 Tip: Python 版本为 3.10.6\ngit clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git cd stable-diffusion-webui/ # 请切换Python venv, 魔法上网, 下载时间比较长 git config --global http.proxy http://127.0.0.1:10887 pip install --upgrade pip export http_proxy=http://127.0.0.1:10887;export https_proxy=http://127.0.0.1:10887; sh ./webui.sh 二、安装报错汇总 2.1 安装gfpgan报错 Installing gfpgan Traceback (most recent call last): File \u0026#34;/Users/iarno/Devspace/chatgpt/stable-diffusion-webui/launch.py\u0026#34;, line 355, in \u0026lt;module\u0026gt; prepare_environment() File \u0026#34;/Users/iarno/Devspace/chatgpt/stable-diffusion-webui/launch.py\u0026#34;, line 263, in prepare_environment run_pip(f\u0026#34;install {gfpgan_package}\u0026#34;, \u0026#34;gfpgan\u0026#34;) File \u0026#34;/Users/iarno/Devspace/chatgpt/stable-diffusion-webui/launch.py\u0026#34;, line 129, in run_pip return run(f\u0026#39;\u0026#34;{python}\u0026#34; -m pip {args} --prefer-binary{index_url_line}\u0026#39;, desc=f\u0026#34;Installing {desc}\u0026#34;, errdesc=f\u0026#34;Couldn\u0026#39;t install {desc}\u0026#34;) File \u0026#34;/Users/iarno/Devspace/chatgpt/stable-diffusion-webui/launch.py\u0026#34;, line 97, in run raise RuntimeError(message) RuntimeError: Couldn\u0026#39;t install gfpgan. Command: \u0026#34;/Users/iarno/Devspace/chatgpt/stable-diffusion-webui/venv/bin/python3.10\u0026#34; -m pip install git+https://github.com/TencentARC/GFPGAN.git@8d2447a2d918f8eba5a4a01463fd48e45126a379 --prefer-binary Error code: 2 stdout: Collecting git+https://github.com/TencentARC/GFPGAN.git@8d2447a2d918f8eba5a4a01463fd48e45126a379 Cloning https://github.com/TencentARC/GFPGAN.git (to revision 8d2447a2d918f8eba5a4a01463fd48e45126a379) to /private/var/folders/qw/4fkzpn79447fkgjgk19pq_6h0000gn/T/pip-req-build-0i1rio01 stderr: Running command git clone --filter=blob:none --quiet https://github.com/TencentARC/GFPGAN.git /private/var/folders/qw/4fkzpn79447fkgjgk19pq_6h0000gn/T/pip-req-build-0i1rio01 Running command git rev-parse -q --verify \u0026#39;sha^8d2447a2d918f8eba5a4a01463fd48e45126a379\u0026#39; Running command git fetch -q https://github.com/TencentARC/GFPGAN.git 8d2447a2d918f8eba5a4a01463fd48e45126a379 Running command git checkout -q 8d2447a2d918f8eba5a4a01463fd48e45126a379 解决方案:\ngit config --global http.proxy http://127.0.0.1:10887 2.2 未下载模型导致服务无法运行 No checkpoints found. When searching for checkpoints, looked at: - file /Users/liuli/Devspace/chatgpt/stable-diffusion-webui/model.ckpt - directory /Users/liuli/Devspace/chatgpt/stable-diffusion-webui/models/Stable-diffusion Can\u0026#39;t run without a checkpoint. Find and place a .ckpt or .safetensors file into any of those locations. The program will exit. 解决方案:\n下载模型, 并将下载的模型放到 stable-diffusion-webui/models/Stable-diffusion 目录中。\n三、使用Colab搭建 Colab 免费时长为12小时\n本地模型生成图片会受限于💻配置问题, 推荐使用谷歌免费 Colab 服务搭建, 避免多次下载 Model 模型, 可以考虑使用挂载谷歌云盘的方式(提前将下载好的Model上传至谷歌云盘)。\n3.1 安装教程: http://xhslink.com/6lTt8o\n3.2 修改项 挂载云盘:\n拷贝云盘模型:\n四、参考 https://github.com/AUTOMATIC1111/stable-diffusion-webui.git\nhttps://github.com/camenduru/stable-diffusion-webui-colab.git\nhttp://xhslink.com/6lTt8o\nhttps://www.bilibili.com/video/BV1vX4y1k7d4?vd_source=59a19d02212b7e9ac600f7c97d180b9d\nhttps://www.bilibili.com/video/BV1fL411U77A?vd_source=59a19d02212b7e9ac600f7c97d180b9d\n","permalink":"https://www.iarno.cn/article/stable-diffusion/","tags":["stable diffusion"],"title":"stable diffusion webui 安装"},{"categories":["Linux"],"contents":"Apache APISIX 是 Apache 软件基金会下的云原生 API 网关，它兼具动态、实时、高性能等特点，提供了负载均衡、动态上游、灰度发布（金丝雀发布）、服务熔断、身份认证、可观测性等丰富的流量管理功能。\n我们可以使用 Apache APISIX 来处理传统的南北向流量，也可以处理服务间的东西向流量。同时，它也支持作为 K8s Ingress Controller 来使用。\n一、安装 1.1 安装APISIX 如果当前系统没有安装 OpenResty，请使用以下命令来安装 OpenResty 和 APISIX 仓库：\nsudo yum install -y https://repos.apiseven.com/packages/centos/apache-apisix-repo-1.0-1.noarch.rpm 如果已安装 OpenResty 的官方 RPM 仓库，请使用以下命令安装 APISIX 的 RPM 仓库：\nsudo yum-config-manager --add-repo https://repos.apiseven.com/packages/centos/apache-apisix.repo 完成上述操作后使用以下命令安装 APISIX：\nsudo yum install apisix 你也可以安装指定版本的 APISIX（本示例为 APISIX v2.13.1 LTS 版本）：\nsudo yum install apisix-2.13.1 1.2 安装apisix-dashboard sudo yum install -y https://github.com/apache/apisix-dashboard/releases/download/v2.13/apisix-dashboard-2.13-0.el7.x86_64.rpm 1.3 安装etcd https://juejin.cn/post/7217053578711040057\n二、修改配置 2.1 修改APISIX配置 APISIX 的默认配置可以在 ./conf/config-default.yaml 文件中看到，该文件与 APISIX 源码强绑定，请不要手动修改 ./conf/config-default.yaml 文件。如果需要自定义任何配置，都应在 ./conf/config.yaml 文件中完成。\n请不要手动修改 APISIX 安装目录下的 ./conf/nginx.conf 文件。当 APISIX 启动时，会根据 config.yaml 的配置自动生成新的 nginx.conf 并自动启动服务。\n通过修改本地 /usr/local/apisix/conf/config.yaml 文件，或者在启动 APISIX 时使用 -c 或 --config 添加文件路径参数 apisix start -c \u0026lt;path string\u0026gt;，完成对 APISIX 服务本身的基本配置。\n比如将 APISIX 默认监听端口修改为 8000，其他配置保持默认，在 /usr/local/apisix/conf/config.yaml 中只需这样配置：\napisix: node_listen: 8000 # APISIX listening port 比如指定 APISIX 默认监听端口为 8000，并且设置 etcd 地址，其他配置保持默认。在 /usr/local/apisix/conf/config.yaml 中只需这样配置：\napisix: node_listen: 8000 # APISIX listening port deployment: role: traditional role_traditional: config_provider: etcd etcd: host: - \u0026#34;http://172.16.63.131:2379\u0026#34; - \u0026#34;http://172.16.63.132:2379\u0026#34; - \u0026#34;http://172.16.63.133:2379\u0026#34; 2.2 修改apisix-dashboard配置 配置文件默认路径为/usr/local/apisix/dashboard/conf/conf.yaml\nallow_list: # If we don\u0026#39;t set any IP list, then any IP access is allowed by default. #- 127.0.0.1 # 允许所有ip访问 # It also support CIDR like 192.168.1.0/24 and 2001:0db8::/32 # 配置etcd etcd: endpoints: # supports defining multiple etcd host addresses for an etcd cluster - 172.16.63.131:2379 - 172.16.63.132:2379 - 172.16.63.133:2379 三、启动服务 3.1 启动APISIX服务 APISIX 安装完成后，你可以运行以下命令初始化 NGINX 配置文件和 etcd：\napisix init 使用以下命令启动 APISIX：\napisix start 你可以运行 apisix help 命令，通过查看返回结果，获取其他操作的命令及描述。\n如果你是通过 RPM 包安装 APISIX，配置文件已经自动安装，你可以直接使用以下命令：\nsystemctl start apisix systemctl stop apisix 如果你是通过其他方法安装的 APISIX，可以参考配置文件模板进行修改，并将其添加在 /usr/lib/systemd/system/apisix.service 路径下。\n3.2 启动apisix-dashboard服务 sudo manager-api -p /usr/local/apisix/dashboard/ # 或者以服务运行 systemctl start apisix-dashboard 3.3 supervisord管理相关进程 [root@localhost supervisord]# cat /etc/supervisord.d/apisix.ini [program:apisix] command=systemctl start apisix [root@localhost supervisord]# cat /etc/supervisord.d/apisix-dashboard.ini [program:apisix-dashboard] command=systemctl start apisix-dashboard 四、网关新增路由 后台管理界面api-dashboard端口默认为 :9000，账号密码默认为admin\n五、访问网关配置路由 后台管理界面apisix端口默认为 :9080, 如当前示例已将端口设置为:8000\nhttp://172.16.63.131:8000/anything/foo?arg=10\n{ \u0026#34;args\u0026#34;: { \u0026#34;arg\u0026#34;: \u0026#34;10\u0026#34; }, \u0026#34;data\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;files\u0026#34;: {}, \u0026#34;form\u0026#34;: {}, \u0026#34;headers\u0026#34;: { \u0026#34;Accept\u0026#34;: \u0026#34;text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\u0026#34;, \u0026#34;Accept-Encoding\u0026#34;: \u0026#34;gzip, deflate\u0026#34;, \u0026#34;Accept-Language\u0026#34;: \u0026#34;zh-CN,zh;q=0.9,en;q=0.8\u0026#34;, \u0026#34;Host\u0026#34;: \u0026#34;172.16.63.131\u0026#34;, \u0026#34;Upgrade-Insecure-Requests\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;User-Agent\u0026#34;: \u0026#34;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36\u0026#34;, \u0026#34;X-Amzn-Trace-Id\u0026#34;: \u0026#34;Root=1-64297d93-27c7dc195ca76af57c83f9fb\u0026#34;, \u0026#34;X-Forwarded-Host\u0026#34;: \u0026#34;172.16.63.131\u0026#34; }, \u0026#34;json\u0026#34;: null, \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;origin\u0026#34;: \u0026#34;172.16.63.1, 114.253.193.20\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;http://172.16.63.131/anything/foo?arg=10\u0026#34; } 六、参考 https://apisix.apache.org/zh/docs/apisix/installation-guide/\nhttps://www.cnblogs.com/zx-admin/p/16446720.html\n","permalink":"https://www.iarno.cn/article/apisix/","tags":["APISIX"],"title":"centos搭建apisix网关"},{"categories":["Linux"],"contents":"这篇文章主要介绍了如何在CentOS系统上搭建etcd集群。首先，文章详细解释了etcd的特点和相关概念。然后，文章通过实例详细介绍了如何在三个节点上安装etcd，包括初始化节点和新增节点。最后，文章还介绍了如何移除节点。文章的内容详细且实用，对于需要在CentOS系统上搭建etcd集群的读者来说非常有帮助。\netcd基于Raft一致性算法实现了数据的高可用和强一致性，可以支持数千台机器的集群。通过将数据存储在内存中并异步持久化到磁盘上，Etcd在性能和数据可靠性之间取得了很好的平衡。\netcd被广泛用于Kubernetes中的服务发现和配置管理，例如存储Pod的状态、控制器的配置等。\n一、etcd的特点 分布式：Etcd采用分布式的架构，支持多台机器构成的集群。在集群中，每个节点都可以读写数据，同时也会复制数据到其他节点，以保证数据的可靠性和一致性。 高可用性：Etcd采用Raft一致性算法来实现数据的高可用性和强一致性。在集群中，如果某个节点出现故障，其他节点会自动接管该节点的工作，保证数据的可用性和服务的连续性。 强一致性：Etcd保证了数据的强一致性，即任何时候，任何一个节点读取到的数据都是最新的。在写入数据时，Etcd会保证所有节点都成功写入数据后才返回成功结果，以保证数据的一致性。 高性能：Etcd采用了内存存储和异步持久化的方式，以保证读写操作的高性能。同时，Etcd还提供了一套简单易用的HTTP API，使得开发人员可以方便地进行数据读写和监控。 简单易用：Etcd提供了一套简单易用的API，使得开发人员可以方便地进行数据读写和监控。同时，Etcd还提供了命令行工具和图形化管理界面，以方便用户进行集群的管理和维护。 安全性：Etcd支持TLS加密和身份认证，以保证数据的安全性。同时，Etcd还提供了访问控制机制，可以控制不同用户和应用程序对数据的访问权限。 二、概念术语 Member： 一个etcd实例。它管理着一个Node，并且可以为客户端请求提供服务。\nPeer： 对同一个etcd集群中另外一个Member的称呼。\nClient： 向etcd集群发送HTTP请求的客户端。\nWAL： 预写式日志，etcd用于持久化存储的日志格式。\nLeader： Raft算法中通过竞选而产生的处理所有数据提交的节点。\nFollower： 竞选失败的节点作为Raft中的从属节点，为算法提供强一致性保证。\nCandidate： 当Follower超过一定时间接收不到Leader的心跳时转变为Candidate开始竞选。\nTerm： 某个节点成为Leader到下一次竞选时间，称为一个Term。\n三、集群安装部署 etcd版本为3.5.4, 本示例使用的二进制安装。\netcd name IP地址 节点说明 etcd版本 etcd-node-1 172.16.63.131 初始化节点 3.5.4 etcd-node-2 172.16.63.132 初始化节点 3.5.4 etcd-node-3 172.16.63.133 新增节点 3.5.4 3.1 集群安装 3个节点安装etcd\nETCD_VERSION=\u0026#39;3.5.4\u0026#39; wget https://github.com/etcd-io/etcd/releases/download/v${ETCD_VERSION}/etcd-v${ETCD_VERSION}-linux-amd64.tar.gz tar -xvf etcd-v${ETCD_VERSION}-linux-amd64.tar.gz \u0026amp;\u0026amp; \\ cd etcd-v${ETCD_VERSION}-linux-amd64 \u0026amp;\u0026amp; \\ sudo cp -a etcd etcdctl /usr/bin/ 3.2 参数说明 etcd可以指定config配置文件启动服务, 也可以参数形式启动, 其他参数具体说明略。\n[root@localhost iarno]# etcd --help Usage: ...... etcd --config-file # config配置文件地址 json文件 Path to the server configuration file. Note that if a configuration file is provided, other command line flags and environment variables will be ignored. ......省略 Member: # 本节点etcd信息 --name \u0026#39;default\u0026#39; # 名称 Human-readable name for this member. --data-dir \u0026#39;${name}.etcd\u0026#39; # 数据存放路径 Path to the data directory. --listen-peer-urls \u0026#39;http://localhost:2380\u0026#39; # 该节点接受其他节点连接的地址, 可理解为本机会启动一个2380端口服务 List of URLs to listen on for peer traffic. --listen-client-urls \u0026#39;http://localhost:2379\u0026#39; # etcd客户端地址, 可理解为本机会启动一个2379端口服务 List of URLs to listen on for client traffic. ......省略 Clustering: # 集群 --initial-advertise-peer-urls \u0026#39;http://localhost:2380\u0026#39; # 指定该节点在集群中作为Peer节点时，用于广播宣传自己的URL地址 List of this member\u0026#39;s peer URLs to advertise to the rest of the cluster. --initial-cluster \u0026#39;default=http://localhost:2380\u0026#39; # 用于指定Etcd集群的成员。每个成员由一个\u0026lt;name\u0026gt;=\u0026lt;url\u0026gt;的键值对表示，其中\u0026lt;name\u0026gt;是成员的名称，\u0026lt;url\u0026gt;是成员的Peer URL地址。 Initial cluster configuration for bootstrapping. --initial-cluster-state \u0026#39;new\u0026#39; # 初始集群状态, existing后期新加节点需要 Initial cluster state (\u0026#39;new\u0026#39; or \u0026#39;existing\u0026#39;). --initial-cluster-token \u0026#39;etcd-cluster\u0026#39; # 集群初始token Initial cluster token for the etcd cluster during bootstrap. Specifying this can protect you from unintended cross-cluster interaction when running multiple clusters. --advertise-client-urls \u0026#39;http://localhost:2379\u0026#39; # 用于指定Etcd集群的客户端接入地址 List of this member\u0026#39;s client URLs to advertise to the public. The client URLs advertised should be accessible to machines that talk to etcd cluster. etcd client libraries parse these URLs to connect to the cluster. ......省略 3.3 服务启动 如果启动参数listen-client-urls未加127.0.0.1:2379, 之后执行etcdctl命令查看集群相关信息必须携带 --endpoints=${HOST_1}:2379,${HOST_2}:2379 参数, 否则命令会报错。\netcd-node-1\nTOKEN=my-etcd-token-1 CLUSTER_STATE=new NAME_1=etcd-node-1 NAME_2=etcd-node-2 HOST_1=172.16.63.131 HOST_2=172.16.63.132 CLUSTER=${NAME_1}=http://${HOST_1}:2380,${NAME_2}=http://${HOST_2}:2380,${NAME_3}=http://${HOST_3}:2380 # For node 1 THIS_NAME=${NAME_1} THIS_IP=${HOST_1} nohup etcd --data-dir=data.etcd --name ${THIS_NAME} \\ --initial-advertise-peer-urls http://${THIS_IP}:2380 \\ --listen-peer-urls http://${THIS_IP}:2380 \\ --advertise-client-urls http://127.0.0.1:2379,http://${THIS_IP}:2379 \\ --listen-client-urls http://127.0.0.1:2379,http://${THIS_IP}:2379 \\ --initial-cluster ${CLUSTER} \\ --initial-cluster-state ${CLUSTER_STATE} \\ --initial-cluster-token ${TOKEN}\u0026amp; etcd-node-2\nTOKEN=my-etcd-token-1 CLUSTER_STATE=new NAME_1=etcd-node-1 NAME_2=etcd-node-2 HOST_1=172.16.63.131 HOST_2=172.16.63.132 CLUSTER=${NAME_1}=http://${HOST_1}:2380,${NAME_2}=http://${HOST_2}:2380,${NAME_3}=http://${HOST_3}:2380 # For node 2 THIS_NAME=${NAME_2} THIS_IP=${HOST_2} nohup etcd --data-dir=data.etcd --name ${THIS_NAME} \\ --initial-advertise-peer-urls http://${THIS_IP}:2380 \\ --listen-peer-urls http://${THIS_IP}:2380 \\ --advertise-client-urls http://127.0.0.1:2379,http://${THIS_IP}:2379 \\ --listen-client-urls http://127.0.0.1:2379,http://${THIS_IP}:2379 \\ --initial-cluster ${CLUSTER} \\ --initial-cluster-state ${CLUSTER_STATE} \\ --initial-cluster-token ${TOKEN}\u0026amp; 3.4 查看member信息 started说明节点状态正常。\n[root@localhost etcd-v3.5.4-linux-amd64]# etcdctl member list -w table +------------------+---------+-------------+---------------------------+-------------------------------------------------+------------+ | ID | STATUS | NAME | PEER ADDRS | CLIENT ADDRS | IS LEARNER | +------------------+---------+-------------+---------------------------+-------------------------------------------------+------------+ | 2da4f3ecb804e704 | started | etcd-node-2 | http://172.16.63.132:2380 | http://127.0.0.1:2379,http://172.16.63.132:2379 | false | | 8f3d892540699071 | started | etcd-node-1 | http://172.16.63.131:2380 | http://127.0.0.1:2379,http://172.16.63.131:2379 | false | +------------------+---------+-------------+---------------------------+-------------------------------------------------+------------+ 3.5 简单写入数据测试 注: etcd版本不兼容, 此版本使用put写入数据。\n# etcd-node-1 [root@localhost etcd-v3.5.4-linux-amd64]# etcdctl put greeting \u0026#34;Hello, etcd\u0026#34; OK # etcd-node-2 [root@localhost etcd-v3.5.4-linux-amd64]# etcdctl get greeting greeting Hello, etcd 3.6 新增节点 # 在 etcd-node-1 或 etcd-node-2 节点上执行此命令 NAME_1=etcd-node-1 NAME_2=etcd-node-2 NAME_3=etcd-node-3 HOST_1=172.16.63.131 HOST_2=172.16.63.132 HOST_3=172.16.63.133 # new member etcdctl --endpoints=${HOST_1}:2379,${HOST_2}:2379 \\ member add ${NAME_4} \\ --peer-urls=http://${HOST_3}:2380 3.7 新节点启动服务 注意，CLUSTER_STATE 为 existing\netcd-node-3\nTOKEN=my-etcd-token-1 CLUSTER_STATE=existing NAME_1=etcd-node-1 NAME_2=etcd-node-2 NAME_3=etcd-node-3 HOST_1=172.16.63.131 HOST_2=172.16.63.132 HOST_3=172.16.63.133 CLUSTER=${NAME_1}=http://${HOST_1}:2380,${NAME_2}=http://${HOST_2}:2380,${NAME_3}=http://${HOST_3}:2380 THIS_NAME=${NAME_3} THIS_IP=${HOST_3} nohup etcd --data-dir=data.etcd --name ${THIS_NAME} \\ --initial-advertise-peer-urls http://${THIS_IP}:2380 \\ --listen-peer-urls http://${THIS_IP}:2380 \\ --advertise-client-urls http://127.0.0.1:2379,http://${THIS_IP}:2379 \\ --listen-client-urls http://127.0.0.1:2379,http://${THIS_IP}:2379 \\ --initial-cluster ${CLUSTER} \\ --initial-cluster-state ${CLUSTER_STATE} \\ --initial-cluster-token ${TOKEN}\u0026amp; 3.8 移除节点 etcdctl member remove ${MEMBER_ID} 四、参考 https://etcd.io/docs/v3.5/tutorials/how-to-deal-with-membership/\nhttps://juejin.cn/post/6844904031186321416\n","permalink":"https://www.iarno.cn/article/etcd/","tags":["APISIX"],"title":"centos搭建etcd集群"},{"categories":["Go"],"contents":"这篇文章主要讲述了Gin框架中的参数绑定功能，包括Bind和ShouldBind的区别以及使用方法。Bind在出错时会返回400状态码，而ShouldBind则允许用户自定义错误码。文章还详细介绍了ShouldBind和ShouldBindJSON的使用场景，前者主要用于非GET请求的json参数绑定，后者则专门用于json参数的绑定。\ntype params struct { Total int `form:\u0026#34;total\u0026#34; json:\u0026#34;total\u0026#34; binding:\u0026#34;omitempty,numeric\u0026#34;` } Bind和ShouldBind 区别 区别就是Bindxxx会的返回400http状态码错误，而Shouldxxx不会用户可以自定义错误码。\nShouldBind 绑定不是GET请求的 json 参数，但可以绑定成功POST请求的 json 参数。\nShouldBindJSON 绑定 json 参数。\n","permalink":"https://www.iarno.cn/article/gin-should-binding/","tags":null,"title":"gin Bind 参数绑定"},{"categories":["Go"],"contents":"这篇文章详细介绍了在Golang中使用的各种绑定标签。包括但不限于required、unique、omitempty等，每个标签都有详细的说明和使用示例。这些标签在使用Gin框架进行数据验证时非常有用。文章还提供了一个链接，供读者进一步了解和学习这些标签的使用。\n标记 标记说明 例 required 必填 Field或Struct validate:\u0026quot;required\u0026quot; unique 保证唯一性,不同类型处理不同; 对于map，unique约束没有重复的value值； 对于数组和切片，没有重复的元素值 Field validate:\u0026quot;unique\u0026quot; omitempty 空时忽略 Field或Struct validate:\u0026quot;omitempty\u0026quot; len 长度 Field validate:\u0026quot;len=0\u0026quot; eq 等于 Field validate:\u0026quot;eq=0\u0026quot; gt 大于 Field validate:\u0026quot;gt=0\u0026quot; gte 大于等于 Field validate:\u0026quot;gte=0\u0026quot; lt 小于 Field validate:\u0026quot;lt=0\u0026quot; lte 小于等于 Field validate:\u0026quot;lte=0\u0026quot; eqfield 同一结构体字段相等 Field validate:\u0026quot;eqfield=Field2\u0026quot; nefield 同一结构体字段不相等 Field validate:\u0026quot;nefield=Field2\u0026quot; gtfield 大于同一结构体字段 Field validate:\u0026quot;gtfield=Field2\u0026quot; gtefield 大于等于同一结构体字段 Field validate:\u0026quot;gtefield=Field2\u0026quot; ltfield 小于同一结构体字段 Field validate:\u0026quot;ltfield=Field2\u0026quot; ltefield 小于等于同一结构体字段 Field validate:\u0026quot;ltefield=Field2\u0026quot; eqcsfield 跨不同结构体字段相等 Struct1.Field validate:\u0026quot;eqcsfield=Struct2.Field2\u0026quot; necsfield 跨不同结构体字段不相等 Struct1.Field validate:\u0026quot;necsfield=Struct2.Field2\u0026quot; gtcsfield 大于跨不同结构体字段 Struct1.Field validate:\u0026quot;gtcsfield=Struct2.Field2\u0026quot; gtecsfield 大于等于跨不同结构体字段 Struct1.Field validate:\u0026quot;gtecsfield=Struct2.Field2\u0026quot; ltcsfield 小于跨不同结构体字段 Struct1.Field validate:\u0026quot;ltcsfield=Struct2.Field2\u0026quot; ltecsfield 小于等于跨不同结构体字段 Struct1.Field validate:\u0026quot;ltecsfield=Struct2.Field2\u0026quot; min 最大值 Field validate:\u0026quot;min=1\u0026quot; max 最小值 Field validate:\u0026quot;max=2\u0026quot; structonly 仅验证结构体，不验证任何结构体字段 Struct validate:\u0026quot;structonly\u0026quot; nostructlevel 不运行任何结构级别的验证 Struct validate:\u0026quot;nostructlevel\u0026quot; dive 向下延伸验证，多层向下需要多个dive标记 string validate:\u0026quot;gt=0,dive,len=1,dive,required\u0026quot; dive Keys \u0026amp; EndKeys 与dive同时使用，用于对map对象的键的和值的验证，keys为键，endkeys为值 map[string]string `validate:”gt=0,dive,keys,eq=1 required_with 其他字段其中一个不为空且当前字段不为空 Field validate:\u0026quot;required_with=Field1 Field2\u0026quot; required_with_all 其他所有字段不为空且当前字段不为空 Field validate:\u0026quot;required_with_all=Field1 Field2\u0026quot; required_without 其他字段其中一个为空且当前字段不为空 Field `validate:”required_without=Field1 Field2” required_without_all 其他所有字段为空且当前字段不为空 Field validate:\u0026quot;required_without_all=Field1 Field2\u0026quot; isdefault 是默认值 Field validate:\u0026quot;isdefault=0\u0026quot; oneof 其中之一 Field validate:\u0026quot;oneof=5 7 9\u0026quot; containsfield 字段包含另一个字段 Field validate:\u0026quot;containsfield=Field2\u0026quot; excludesfield 字段不包含另一个字段 Field validate:\u0026quot;excludesfield=Field2\u0026quot; unique 是否唯一，通常用于切片或结构体 Field validate:\u0026quot;unique\u0026quot; alphanum 字符串值是否只包含 ASCII 字母数字字符 Field validate:\u0026quot;alphanum\u0026quot; alphaunicode 字符串值是否只包含 unicode 字符 Field validate:\u0026quot;alphaunicode\u0026quot; alphanumunicode 字符串值是否只包含 unicode 字母数字字符 Field validate:\u0026quot;alphanumunicode\u0026quot; numeric 字符串值是否包含基本的数值 Field validate:\u0026quot;numeric\u0026quot; hexadecimal 字符串值是否包含有效的十六进制 Field validate:\u0026quot;hexadecimal\u0026quot; hexcolor 字符串值是否包含有效的十六进制颜色 Field validate:\u0026quot;hexcolor\u0026quot; lowercase 符串值是否只包含小写字符 Field validate:\u0026quot;lowercase\u0026quot; uppercase 符串值是否只包含大写字符 Field validate:\u0026quot;uppercase\u0026quot; email 字符串值包含一个有效的电子邮件 Field validate:\u0026quot;email\u0026quot; json 字符串值是否为有效的 JSON Field validate:\u0026quot;json\u0026quot; file 符串值是否包含有效的文件路径，以及该文件是否存在于计算机上 Field validate:\u0026quot;file\u0026quot; url 符串值是否包含有效的 url Field validate:\u0026quot;url\u0026quot; uri 符串值是否包含有效的 uri Field validate:\u0026quot;uri\u0026quot; base64 字符串值是否包含有效的 base64值 Field validate:\u0026quot;base64\u0026quot; contains 字符串值包含子字符串值 Field validate:\u0026quot;contains=@\u0026quot; containsany 字符串值包含子字符串值中的任何字符 Field validate:\u0026quot;containsany=abc\u0026quot; containsrune 字符串值包含提供的特殊符号值 Field validate:\u0026quot;containsrune=☢\u0026quot; excludes 字符串值不包含子字符串值 Field validate:\u0026quot;excludes=@\u0026quot; excludesall 字符串值不包含任何子字符串值 Field validate:\u0026quot;excludesall=abc\u0026quot; excludesrune 字符串值不包含提供的特殊符号值 Field validate:\u0026quot;containsrune=☢\u0026quot; startswith 字符串以提供的字符串值开始 Field validate:\u0026quot;startswith=abc\u0026quot; endswith 字符串以提供的字符串值结束 Field validate:\u0026quot;endswith=abc\u0026quot; ip 字符串值是否包含有效的 IP 地址 Field validate:\u0026quot;ip\u0026quot; ipv4 字符串值是否包含有效的 ipv4地址 Field validate:\u0026quot;ipv4\u0026quot; datetime 字符串值是否包含有效的 日期 Field validate:\u0026quot;datetime\u0026quot; 参考 https://pkg.go.dev/github.com/go-playground/validator/v10#section-readme\n","permalink":"https://www.iarno.cn/article/binding-tag/","tags":null,"title":"gin binding tag"},{"categories":["Mysql"],"contents":"这篇文章详细解释了MySQL中的join、inner join、left join和right join的用法。通过实例展示了如何在两张表之间进行有效连接，以及如何使用左连接和右连接来处理不存在的数据。文章还包含了一些实用的MySQL命令和查询结果，以帮助读者更好地理解这些概念。\njoin \u0026amp; inner join 理解为“有效连接”，两张表中都有的数据才会显示。\nMySQL [test_join]\u0026gt; show tables; +---------------------+ | Tables_in_test_join | +---------------------+ | table_A | | table_B | +---------------------+ 2 rows in set (0.00 sec) MySQL [test_join]\u0026gt; select * from table_A; +----+--------+ | id | a_name | +----+--------+ | 1 | aaa | | 2 | bbb | | 3 | ccc | +----+--------+ 3 rows in set (0.00 sec) MySQL [test_join]\u0026gt; select * from table_B; +----+-------------------------+--------+ | id | aid (table_A表中的主键id) | b_name | +----+-------------------------+--------+ | 1 | 1 | 111 | | 2 | 1 | 222 | | 3 | 2 | 333 | | 4 | 1 | 444 | +----+-------------------------+--------+ 4 rows in set (0.00 sec) MySQL [test_join]\u0026gt; select * from table_A A join table_B B on A.id = B.aid; +----+--------+----+------+--------+ | id | a_name | id | aid | b_name | +----+--------+----+------+--------+ | 1 | aaa | 1 | 1 | 111 | | 1 | aaa | 2 | 1 | 222 | | 2 | bbb | 3 | 2 | 333 | | 1 | aaa | 4 | 1 | 444 | +----+--------+----+------+--------+ 4 rows in set (0.01 sec) MySQL [test_join]\u0026gt; select * from table_A A inner join table_B B on A.id = B.aid; +----+--------+----+------+--------+ | id | a_name | id | aid | b_name | +----+--------+----+------+--------+ | 1 | aaa | 1 | 1 | 111 | | 1 | aaa | 2 | 1 | 222 | | 2 | bbb | 3 | 2 | 333 | | 1 | aaa | 4 | 1 | 444 | +----+--------+----+------+--------+ 4 rows in set (0.01 sec) left join 以左表为主, 出左表全部数据, 右表不存在数据 null 补全。\nMySQL [test_join]\u0026gt; select * from table_A A left join table_B B on A.id = B.aid; +----+--------+------+------+--------+ | id | a_name | id | aid | b_name | +----+--------+------+------+--------+ | 1 | aaa | 1 | 1 | 111 | | 1 | aaa | 2 | 1 | 222 | | 2 | bbb | 3 | 2 | 333 | | 1 | aaa | 4 | 1 | 444 | | 3 | ccc | NULL | NULL | NULL | +----+--------+------+------+--------+ 5 rows in set (0.00 sec) right join 以右表为主, 出右表全部数据, 左表不存在数据 null 补全。\nMySQL [test_join]\u0026gt; select * from table_B B right join table_A A on B.aid = A.id; +------+------+--------+----+--------+ | id | aid | b_name | id | a_name | +------+------+--------+----+--------+ | 1 | 1 | 111 | 1 | aaa | | 2 | 1 | 222 | 1 | aaa | | 3 | 2 | 333 | 2 | bbb | | 4 | 1 | 444 | 1 | aaa | | NULL | NULL | NULL | 3 | ccc | +------+------+--------+----+--------+ 5 rows in set (0.01 sec) 参考 https://zhuanlan.zhihu.com/p/85856388\n","permalink":"https://www.iarno.cn/article/mysql-join/","tags":null,"title":"mysql join、inner join、left join 、right join 详解"},{"categories":["Go"],"contents":"这篇文章介绍了如何使用Go语言连接MySQL数据库并导出CSV文件。首先，我们需要使用sql.Open函数连接到数据库。然后，我们使用db.Query函数查询用户数据。接着，我们将查询结果添加到一个二维字符串数组中，准备写入CSV文件。最后，我们调用WriteCsv函数将数据写入CSV文件。这个函数首先创建一个新的文件，然后使用csv.NewWriter创建一个新的CSV writer，最后将数据写入文件并刷新writer。\npackage main import ( \u0026#34;database/sql\u0026#34; \u0026#34;encoding/csv\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;time\u0026#34; _ \u0026#34;github.com/go-sql-driver/mysql\u0026#34; ) func main() { // 连接数据库 db, err := sql.Open(\u0026#34;mysql\u0026#34;, \u0026#34;username:password@tcp(host:3306)/数据库名?charset=utf8mb4\u0026amp;parseTime=True\u0026#34;) if err != nil { log.Printf(\u0026#34;open mysql failed: %v\u0026#34;, err) return } defer db.Close() rows, err := db.Query(\u0026#34;select id, name, email from user\u0026#34;) if err != nil { log.Printf(\u0026#34;query failed: %v\u0026#34;, err) return } var csvData [][]string csvData = append(csvData, []string{\u0026#34;用户ID\u0026#34;, \u0026#34;用户名\u0026#34;, \u0026#34;邮箱\u0026#34;}) for rows.Next() { var userID string var name string var email string if err := rows.Scan(\u0026amp;userID, \u0026amp;name, \u0026amp;email); err != nil { log.Printf(\u0026#34;scan failed: %v\u0026#34;, err) return } // 修改数据库 // if _, err := db.Exec(\u0026#34;UPDATE user SET name=? where id=?\u0026#34;, \u0026#34;test\u0026#34;, userID); err != nil { //\tlog.Printf(\u0026#34;exec failed: %v, id=%v\u0026#34;, err, userID) //\treturn // } lineData := []string{ userID, name, email, } csvData = append(csvData, lineData) } fileName := time.Now().Format(\u0026#34;20060102150405\u0026#34;) + \u0026#34;.csv\u0026#34; filePath := \u0026#34;/tmp/\u0026#34; + fileName fileErr := WriteCsv(filePath, csvData) if fileErr != nil { log.Printf(\u0026#34;writeCsv fialed: %v\u0026#34;, fileErr) return } // 接口请求导出 // ctx.FileAttachment(filePath, fileName) } //filePath: 文件全路径 绝对路径 //content: 包含行列 需要头部要增加第一列 func WriteCsv(filePath string, content [][]string) error { file, err := os.Create(filePath) if err != nil { return err } defer file.Close() // 写入UTF-8 BOM，防止中文乱码 file.WriteString(\u0026#34;\\xEF\\xBB\\xBF\u0026#34;) w := csv.NewWriter(file) for _, v := range content { err = w.Write(v) if err != nil { return err } } w.Flush() return nil } ","permalink":"https://www.iarno.cn/article/export-csv/","tags":null,"title":"golang连接mysql数据库导出csv文件"},{"categories":["Go"],"contents":"这篇文章介绍了如何使用Go语言的Gin框架和httputil.NewSingleHostReverseProxy方法实现代理服务。文章提供了详细的代码示例，展示了如何创建一个反向代理，将请求转发到指定的远程服务器。同时，文章还解释了如何设置请求的头部、主机、URL方案和路径等信息。\n代码示例 package main import ( \u0026#34;net/http\u0026#34; \u0026#34;net/http/httputil\u0026#34; \u0026#34;net/url\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; ) func proxy(c *gin.Context) { remote, err := url.Parse(\u0026#34;http://www.iarno.cn\u0026#34;) if err != nil { panic(err) } proxy := httputil.NewSingleHostReverseProxy(remote) proxy.Director = func(req *http.Request) { req.Header = c.Request.Header req.Host = remote.Host req.URL.Scheme = remote.Scheme req.URL.Host = remote.Host req.URL.Path = c.Param(\u0026#34;proxyPath\u0026#34;) } proxy.ServeHTTP(c.Writer, c.Request) } func main() { r := gin.Default() //Create a catchall route r.Any(\u0026#34;/*proxyPath\u0026#34;, proxy) r.Run(\u0026#34;:8080\u0026#34;) } 参考 https://le-gall.bzh/post/go/a-reverse-proxy-in-go-using-gin/\n","permalink":"https://www.iarno.cn/article/gin-proxy/","tags":["proxy代理"],"title":"gin proxy代理"},{"categories":["Go"],"contents":"这篇文章主要解决了在使用Go语言的gin框架进行请求绑定时，如果请求对象为数组，绑定可能不会生效的问题。文章首先展示了问题的产生，然后提供了解决方案：在数组类型的绑定标签中，将required改为dive。这样，gin就会递归验证数组中的每一个对象。最后，文章提供了相关的参考链接。\n请求结构体如下 // 学生结构 type StudentParam struct { StudentID uint64 `json:\u0026#34;student_id\u0026#34; binding:\u0026#34;required\u0026#34;` // 请求时此参数验证并未生效 StudentName int `json:\u0026#34;type\u0026#34; binding:\u0026#34;required\u0026#34;` // 请求时此参数验证并未生效 } // 批量创建学生 type CreateStudentsParam struct { Students []StudentParam `json:\u0026#34;students\u0026#34; binding:\u0026#34;required\u0026#34;` } var param CreateStudentsParam err := c.ShouldBindJSON(\u0026amp;param) 解决方法 type CreateStudentsParam struct { Students []StudentParam `json:\u0026#34;students\u0026#34; binding:\u0026#34;dive\u0026#34;` // 将binding:\u0026#34;required\u0026#34;改为binding:\u0026#34;dive\u0026#34; } 参考 https://www.utf8.hk/archives/go-gin-binding-error.html\n","permalink":"https://www.iarno.cn/article/gin-binding/","tags":null,"title":"gin当请求对象为数组时，binding不生效问题解决"},{"categories":["Python"],"contents":"这篇文章是关于Django项目实践的教程。首先，我们介绍了如何安装Django。然后，我们创建了一个新的Django项目，并进行了数据库的初始化。接着，我们启动了Django服务，并展示了如何在浏览器中查看项目。最后，我们创建了一个新的应用程序，并定义了一个简单的模型。这篇文章是对Django项目实践的基础介绍，适合初学者阅读。\n安装django sudo pip install django 创建项目 (python3.9.6) ➜ django-admin startproject learning_log . (python3.9.6) ➜ ll total 8 drwxr-xr-x 7 iarno staff 224B 8 24 23:15 learning_log -rwxrwxrwx 1 iarno staff 668B 8 24 23:15 manage.py 创建数据库 (python3.9.6) ➜ python manage.py migrate Operations to perform: Apply all migrations: admin, auth, contenttypes, sessions Running migrations: Applying contenttypes.0001_initial... OK Applying auth.0001_initial... OK Applying admin.0001_initial... OK Applying admin.0002_logentry_remove_auto_add... OK Applying admin.0003_logentry_add_action_flag_choices... OK Applying contenttypes.0002_remove_content_type_name... OK Applying auth.0002_alter_permission_name_max_length... OK Applying auth.0003_alter_user_email_max_length... OK Applying auth.0004_alter_user_username_opts... OK Applying auth.0005_alter_user_last_login_null... OK Applying auth.0006_require_contenttypes_0002... OK Applying auth.0007_alter_validators_add_error_messages... OK Applying auth.0008_alter_user_username_max_length... OK Applying auth.0009_alter_user_last_name_max_length... OK Applying auth.0010_alter_group_name_max_length... OK Applying auth.0011_update_proxy_permissions... OK Applying auth.0012_alter_user_first_name_max_length... OK Applying sessions.0001_initial... OK 启动服务 (python3.9.6) ➜ python manage.py runserver Watching for file changes with StatReloader Performing system checks... System check identified no issues (0 silenced). August 24, 2022 - 15:17:29 Django version 3.2.7, using settings \u0026#39;learning_log.settings\u0026#39; Starting development server at http://127.0.0.1:8000/ Quit the server with CONTROL-C. 创建应用程序 (python3.9.6) ➜ python manage.py startapp learning_logs (python3.9.6) ➜ ll (python3.9.6) ➜ learning_log ls db.sqlite3 learning_log learning_logs ll_env manage.py (python3.9.6) ➜ learning_log ls learning_logs __init__.py __pycache__ admin.py apps.py migrations models.py tests.py views.py 定义模型 # learning_logs/models.py from django.db import models # Create your models here. class Topic(models.Model): \u0026#34;\u0026#34;\u0026#34;用户学习主题\u0026#34;\u0026#34;\u0026#34; text = models.CharField(max_length=200) date_added = models.DateTimeField(auto_now_add=True) def __str__(self): return self.text ","permalink":"https://www.iarno.cn/article/django-01/","tags":["Python编程从入门到实战","Django"],"title":"Django 项目实践01"},{"categories":["Python"],"contents":"这篇文章是关于Python单元测试的教程。文章首先介绍了Python代码测试的重要性，然后详细解释了如何使用Python的unittest模块进行单元测试。文章中还提供了一个简单的单元测试示例，包括如何创建测试类，如何编写测试方法，以及如何使用断言进行测试。这篇文章对于想要学习Python单元测试的读者来说是非常有帮助的。\n异常处理 方法名test开头\n\u0026#34;\u0026#34;\u0026#34; 单元测试 \u0026#34;\u0026#34;\u0026#34; import unittest class TestACase(unittest.TestCase): \u0026#34;\u0026#34;\u0026#34;Test Class\u0026#34;\u0026#34;\u0026#34; def test_a(self): \u0026#34;\u0026#34;\u0026#34;test func\u0026#34;\u0026#34;\u0026#34; test_list = [\u0026#34;test\u0026#34;] self.assertEqual(\u0026#34;test\u0026#34;, \u0026#34;test\u0026#34;) self.assertEqual(\u0026#34;test\u0026#34;, \u0026#34;test1\u0026#34;) self.assertIn(\u0026#34;test\u0026#34;, test_list) unittest.main() ","permalink":"https://www.iarno.cn/article/py-test/","tags":["Python编程从入门到实战"],"title":"Python 单元测试"},{"categories":["Linux"],"contents":"本文介绍了cloc代码统计工具的安装和使用方法。cloc可以统计代码文件的数量、空行、注释和代码行数。通过执行cloc命令，可以得到详细的统计结果，包括各种语言的文件数、空行数、注释数和代码行数。这是一个非常实用的工具，可以帮助我们更好地理解和管理代码。\n安装 yum install -y cloc 执行命令 [iarno@xxxx devspace] cloc test/ 260 text files. 130 unique files. 140 files ignored. github.com/AlDanial/cloc v 1.70 T=9.69 s (12.6 files/s, 1053.1 lines/s) ------------------------------------------------------------------------------- Language files blank comment code ------------------------------------------------------------------------------- Go 107 1255 398 6461 YAML 7 215 439 973 Markdown 1 25 0 190 Bourne Shell 5 52 53 95 Protocol Buffers 1 5 4 31 HTML 1 0 0 10 ------------------------------------------------------------------------------- SUM: 122 1552 894 7760 ------------------------------------------------------------------------------- files 文件数 blank 空行 comment 注释 code 代码行数 ","permalink":"https://www.iarno.cn/article/cloc/","tags":null,"title":"Cloc 代码统计"},{"categories":["Python"],"contents":"这篇文章介绍了Python的异常处理方法，主要讲解了try-except语句的使用。文章通过一个实例，展示了如何使用try-except语句来处理文件读取时可能出现的FileNotFoundError异常。当文件不存在时，程序会捕获这个异常，并打印出\u0026quot;file not found\u0026quot;。如果文件存在且无异常，程序会读取文件内容并打印出来。\n异常处理 \u0026#34;\u0026#34;\u0026#34; 异常处理 \u0026#34;\u0026#34;\u0026#34; try: with open(\u0026#34;file/read.txt\u0026#34;, encoding = \u0026#34;UTF-8\u0026#34;) as file_obj: lines = file_obj.readlines() except FileNotFoundError: # 或者 pass 关键字忽略错误 print(\u0026#34;file not found\u0026#34;) else: # 没有异常抛出时执行 for line in lines: print(line) ","permalink":"https://www.iarno.cn/article/py-file/","tags":["Python编程从入门到实战"],"title":"Python 异常处理"},{"categories":["Python"],"contents":"这篇文章主要介绍了Python中文件的读取和写入操作。首先，通过open函数和with关键字，我们可以方便地打开文件并在不再需要时自动关闭。文章详细介绍了如何读取文件的每一行，包括如何去除空行。然后，文章展示了如何将文件的内容读取到列表中。在文件写入部分，我们学习了如何使用不同的模式（如写入模式和附加模式）来写入文件。如果文件不存在，Python会自动创建。\n关键字with在不访问文件后将自动关闭。\n读取文件 \u0026#34;\u0026#34;\u0026#34; 读取文件 \u0026#34;\u0026#34;\u0026#34; # 带有空行 with open(\u0026#34;test.txt\u0026#34;, encoding = \u0026#34;UTF-8\u0026#34;) as file_obj: for line in file_obj: print(line) # 去除空行 with open(\u0026#34;test.txt\u0026#34;, encoding = \u0026#34;UTF-8\u0026#34;) as file_obj: for line in file_obj: print(line.rstrip()) # 创建列表 with open(\u0026#34;test.txt\u0026#34;, encoding = \u0026#34;UTF-8\u0026#34;) as file_obj: for line in file_obj: lines = file_obj.readlines() for line in lines: print(line.rstrip()) 写入文件 # 写入文件 # 文件不存在自动创建 # r读模式、w写模式、a附加模式、r+读写模式 with open(\u0026#34;write.txt\u0026#34;, \u0026#39;a\u0026#39;, encoding = \u0026#34;UTF-8\u0026#34;) as file_obj: file_obj.write(\u0026#34;111 \\n\u0026#34;) file_obj.write(\u0026#34;222 \\n\u0026#34;) ","permalink":"https://www.iarno.cn/article/py-except/","tags":["Python编程从入门到实战"],"title":"Python 文件篇"},{"categories":["其他"],"contents":"这篇文章主要介绍了Conda包管理工具的使用，包括安装方法、设置镜像源、创建和激活环境等操作。同时，文章还解答了在使用过程中可能遇到的问题，如设置清华源问题和激活后包版本未变的问题，并给出了解决方案。最后，文章提供了一些参考链接，包括Conda的官方文档和其他相关教程。\n支持语言包括 Python，R，Ruby，Lua，Scala，Java，JavaScript，C / C ++，FORTRAN。\n安装 https://conda.io/en/latest/miniconda.html\n查看官网或网上🏄🏻自行下载安装。\n设置镜像源 vim ~/.condarc\n(python3.9.6) ➜ ~ cat ~/.condarc show_channel_urls: true ssl_verify: false channels: - http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/osx-64/ - http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/osx-64/ auto_activate_base: false 可以通过.condare文件设置源，也可以通过命令来设置。\n案例 # 创建 python3.9.6 版本 ➜ ~ conda create --name python3.9.6 python=3.9.6 输入y即可创建成功 # 激活 python3.9.6 ➜ ~ conda activate python3.9.6 (python3.9.6) ➜ ~ python --version Python 3.9.6 # 退出激活 ➜ ~ conda deactivate 问题 设置清华源问题 CondaHTTPError: HTTP 000 CONNECTION FAILED\nCollecting package metadata (current_repodata.json): failed CondaHTTPError: HTTP 000 CONNECTION FAILED for url \u0026lt;https://repo.anaconda.com/pkgs/main/linux-64/current_repodata.json\u0026gt; Elapsed: - An HTTP error occurred when trying to retrieve this URL. HTTP errors are often intermittent, and a simple retry will get you on your way. If your current network has https://www.anaconda.com blocked, please file a support request with your network engineering team. \u0026#39;https://repo.anaconda.com/pkgs/main/linux-64\u0026#39; 问题原因是不能使用清华的https源地址，需切换为http地址。\n激活后包版本没变 出现这种情况一般有两种可能:\n环境变量未设置，需要在path中加上anaconda的bin目录 环境变量顺序不对 Linux中默认的环境变量为 /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin 只有在conda activate激活状态echo $PAHT才可以看出对应的环境变量配置。\n参考 Conda 官方文档\nConda 安装使用详解 https://www.jianshu.com/p/b2b117ac5561\nLinux安装anaconda之后运行python版本未切换问题\n","permalink":"https://www.iarno.cn/article/conda/","tags":null,"title":"Conda 包管理工具"},{"categories":["Linux"],"contents":"这篇文章主要介绍了Linux下的core文件分析方法。首先，文章解释了如何使用ulimit命令设置生成core文件，以及各参数的含义。接着，文章详细描述了core文件的生成过程和作用，以及如何设置core dump的文件目录和命名规则。文章还提供了如何使用gdb工具分析core文件的方法，并解释了在什么情况下可能不会生成core文件以及如何解决。最后，文章提供了相关的参考链接。\nunlimit设置 ulimit -c unlimited 生成core文件,就是程序运行发行段错误时的文件\n参数说明: -a 显示目前资源限制的设定。\n-c \u0026lt;core文件上限\u0026gt; 设定core文件的最大值,单位为区块。\n-d \u0026lt;数据节区大小\u0026gt; 程序数据节区的最大值,单位为KB。\n-f \u0026lt;文件大小\u0026gt; shell所能建立的最大文件,单位为区块。\n-H 设定资源的硬性限制,也就是管理员所设下的限制。\n-m \u0026lt;内存大小\u0026gt; 指定可使用内存的上限,单位为KB。\n-n \u0026lt;文件数目\u0026gt; 指定同一时间最多可开启的文件数。\n-p \u0026lt;缓冲区大小\u0026gt; 指定管道缓冲区的大小,单位512字节。\n-s \u0026lt;堆叠大小\u0026gt; 指定堆叠的上限,单位为KB。\n-S 设定资源的弹性限制。\n-t \u0026lt;CPU时间\u0026gt; 指定CPU使用时间的上限,单位为秒。\n-u \u0026lt;程序数目\u0026gt; 用户最多可开启的程序数目。\n-v \u0026lt;虚拟内存大小\u0026gt; 指定可使用的虚拟内存上限,单位为KB\ncore文件 开发和使用Unix程序时, 有时程序莫名其妙的死了, 却没有任何的提示(有时候会提示core dumped). 这时候可以查看一下有没有形如core.进程号的文件生成, 这个文件便是操作系统把程序down掉时的内存内容扔出来生成的, 它可以做为调试程序的参考。 core dump又叫核心转储, 当程序运行过程中发生异常, 程序异常退出时, 由操作系统把程序当前的内存状况存储在一个core文件中, 叫core dump.\n设置Core Dump的核心转储文件目录和命名规则 在默认的情况下,很多系统的core文件是生成在你运行程序的目录下,或者你在程序中chdir后的那个目录,然后在core文件的后面加了一个 pid。在实际工作中,这样可能会造成很多目录下产生core文件,不便于管理,实际上,在2.6下,core文件的生成位置和文件名的命名都是可以配置 的。\n/proc/sys/kernel/core_uses_pid 可以控制产生的core文件的文件名中是否添加pid作为扩展,如果添加则文件内容为1,否则为0\nproc/sys/kernel/core_pattern 可以设置格式化的core文件保存位置或文件名,比如原来文件内容是core-%e 可以这样修改:\necho \u0026#34;/tmp/core-%e-%p\u0026#34; \u0026gt; core_pattern 将会控制所产生的core文件会存放到/corefile目录下,产生的文件名为core-命令名-pid-时间戳 以下是参数列表:\n%p - insert pid into filename 添加pid %u - insert current uid into filename 添加当前uid %g - insert current gid into filename 添加当前gid %s - insert signal that caused the coredump into the filename 添加导致产生core的信号 %t - insert UNIX time that the coredump occurred into filename 添加core文件生成时的unix时间 %h - insert hostname where the coredump happened into filename 添加主机名 %e - insert coredumping executable name into filename 添加命令名 分析core文件 gdb -c core文件路径 [应用程序的路径] # 分析php core文件 sudo gdb -e /usr/local/php/sbin/php-fpm -c core.7569 进去后输入where或bt回车, 就可以显示程序在哪一行当掉的, 在哪个函数中.\n为什么没有core文件生成 有时候程序down了, 但是core文件却没有生成. core文件的生成跟你当前系统的环境设置有关系, 可以用下面的语句设置一下, 然后再运行程序便成生成core文件.\nulimit -c unlimited 参考 https://blog.csdn.net/u013427969/article/details/83962303\nhttps://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/gdb.html\n","permalink":"https://www.iarno.cn/article/core/","tags":null,"title":"Core 文件分析"},{"categories":["Linux"],"contents":"这篇文章详细介绍了如何使用 dig 命令来查询 DNS 信息。首先，它解释了如何使用 dig 命令查询单个主机的信息，然后介绍了如何从指定的 DNS 服务器上进行查询，最后，文章还讲解了如何使用 dig 的 -x 选项来反向解析 IP 地址对应的域名。文章中还包含了一些实际的命令示例和结果输出，帮助读者更好地理解和使用 dig 命令。\nLinux下解析域名除了使用nslookup之外，开可以使用dig命令来解析域名。\ndig命令可以得到更多的域名信息。dig 命令主要用来从 DNS 域名服务器查询主机地址信息。dig的全称是 (domain information groper)。它是一个用来灵活探测DNS的工具。它会打印出\u0026gt;DNS name server的回应。\n查询单个域名的DNS信息 dig 命令最典型的用法就是查询单个主机的信息。\nlinuxidc@linuxidc:~$ dig www.linuxidc.com [+trace] ; \u0026lt; \u0026lt;\u0026gt;\u0026gt; DiG 9.11.3-1Ubuntu1.5-Ubuntu \u0026lt; \u0026lt;\u0026gt;\u0026gt; www.linuxidc.com ;; global options: +cmd ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt; \u0026lt;- opcode: QUERY, status: NOERROR, id: 17774 ;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 65494 ;; QUESTION SECTION: ;www.linuxidc.com. IN A ;; ANSWER SECTION: www.linuxidc.com. 5 IN A 122.228.238.15 www.linuxidc.com. 5 IN A 106.42.25.203 ;; Query time: 10 msec ;; SERVER: 127.0.0.53#53(127.0.0.53) ;; WHEN: Sun Mar 03 10:55:35 CST 2019 ;; MSG SIZE rcvd: 77 ​\t输出说明 第一部分显示 dig 命令的版本和输入的参数。 第二部分显示服务返回的一些技术详情，比较重要的是 status。如果 status 的值为 NOERROR 则说明本次查询成功结束。 第三部分中的 \u0026ldquo;QUESTION SECTION\u0026rdquo; 显示我们要查询的域名。 第四部分的 \u0026ldquo;ANSWER SECTION\u0026rdquo; 是查询到的结果。 第五部分则是本次查询的一些统计信息，比如用了多长时间，查询了哪个 DNS 服务器，在什么时间进行的查询等等。\n默认情况下 dig 命令查询 A 记录，上图中显示的 A 即说明查询的记录类型为 A 记录。在尝试查询其它类型的记录前让我们先来了解一下常见的 DNS 记录类型。\n从指定的 DNS 服务器上查询 由于一些原因，希望从指定的 DNS 服务器上进行查询(从默认的 DNS 服务器上获得的结果可能不准确)。指定 DNS 服务器的方式为使用 @ 符号：\nlinuxidc@linuxidc:~$ dig @8.8.8.8 m.linuxidc.com ; \u0026lt; \u0026lt;\u0026gt;\u0026gt; DiG 9.11.3-1ubuntu1.5-Ubuntu \u0026lt; \u0026lt;\u0026gt;\u0026gt; @8.8.8.8 m.linuxidc.com ; (1 server found) ;; global options: +cmd ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt; \u0026lt;- opcode: QUERY, status: NOERROR, id: 38966 ;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 512 ;; QUESTION SECTION: ;m.linuxidc.com. IN A ;; ANSWER SECTION: m.linuxidc.com. 199 IN A 122.228.238.71 m.linuxidc.com. 199 IN A 113.107.238.155 ;; Query time: 120 msec ;; SERVER: 8.8.8.8#53(8.8.8.8) ;; WHEN: Sun Mar 03 11:21:48 CST 2019 ;; MSG SIZE rcvd: 75 从上图可以看到本次查询的 DNS 服务器为 8.8.8.8。\n如果不指定 DNS 服务器，dig 会依次使用 /etc/resolv.conf 里的地址作为 DNS 服务器：\nlinuxidc@linuxidc:~$ dig m.linuxidc.com 上面查询的 DNS 服务器就变成了：\n反向查询 在前面的查询中我们指定了查询服务器为 8.8.8.8，这是谁家的 DNS 服务器？其实我们可以使用 dig 的 -x 选项来反向解析 IP 地址对应的域名：\nlinuxidc@linuxidc:~$ dig -x 8.8.8.8 +short google-public-dns-a.google.com. ","permalink":"https://www.iarno.cn/article/dig/","tags":null,"title":"Dig 命令使用详解"},{"categories":["Go"],"contents":"这篇文章介绍了Golang的单元测试工具Gomonkey。Gomonkey支持为函数、成员方法、函数变量、接口和全局变量打桩。文章详细展示了如何使用Gomonkey进行单元测试，并列出了可能导致打桩失败的原因。同时，文章还解释了什么是内联，并展示了如何禁用内联进行测试。\n功能列表 支持为一个函数打一个桩 支持为一个函数打一个特定的桩序列 支持为一个成员方法打一个桩 支持为一个成员方法打一个特定的桩序列 支持为一个函数变量打一个桩 支持为一个函数变量打一个特定的桩序列 支持为一个接口打桩 支持为一个接口打一个特定的桩序列 支持为一个全局变量打一个桩 打桩失败的可能原因 gomonkey 不是并发安全的。如果有多协程并发对同一个目标的打桩的情况，则需要将之前的协程先优雅退出。 打桩目标为内联的函数或成员方法。可通过命令行参数-gcflags=-l（go1.10 版本之前）或 -gcflags=all=-l（go1.10 版本及之后）关闭内联优化。 gomonkey 对于私有成员方法的打桩失败。go1.6 版本的反射机制支持私有成员方法的查询，而 go1.7 及之后的版本却不支持，所以当用户使用 go1.7 及之后的版本时，gomonkey 对于私有成员方法的打桩会触发异常。 示例 package monkey import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;github.com/agiledragon/gomonkey\u0026#34; . \u0026#34;github.com/smartystreets/goconvey/convey\u0026#34; ) // ############################################################### // ########################## ApplyFunc ########################## // ############################################################### func logicFunc(a, b int) (int, error) { sum, err := netWorkFunc(a, b) if err != nil { return 0, err } return sum, nil } func netWorkFunc(a, b int) (int, error) { if a \u0026lt; 0 \u0026amp;\u0026amp; b \u0026lt; 0 { errmsg := \u0026#34;a\u0026lt;0 \u0026amp;\u0026amp; b\u0026lt;0\u0026#34; //gomonkey有bug，函数一定要有栈分配变量，不然mock不住 return 0, fmt.Errorf(\u0026#34;%v\u0026#34;, errmsg) } return a + b, nil } func TestApplyFunc(t *testing.T) { Convey(\u0026#34;Test ApplyFunc: \u0026#34;, t, func() { // 为函数打桩 var patches = gomonkey.ApplyFunc(netWorkFunc, func(a, b int) (int, error) { return 20, nil }) defer patches.Reset() sum, err := logicFunc(10, 20) // logicFunc中调用了netWorkFunc So(sum, ShouldEqual, 20) So(err, ShouldBeNil) }) } // ############################################################### // ######################### ApplyMethod ######################### // ############################################################### type myType struct { } func (m *myType) logicFunc(a, b int) (int, error) { sum, err := m.NetWorkFunc(a, b) if err != nil { return 0, err } return sum, nil } func (m *myType) NetWorkFunc(a, b int) (int, error) { if a \u0026lt; 0 \u0026amp;\u0026amp; b \u0026lt; 0 { errmsg := \u0026#34;a\u0026lt;0 \u0026amp;\u0026amp; b\u0026lt;0\u0026#34; return 0, fmt.Errorf(\u0026#34;%v\u0026#34;, errmsg) } return a + b, nil } func TestApplyMethod(t *testing.T) { Convey(\u0026#34;Test ApplyMethod: \u0026#34;, t, func() { var p *myType patches := gomonkey.ApplyMethod(reflect.TypeOf(p), \u0026#34;NetWorkFunc\u0026#34;, func(_ *myType, a, b int) (int, error) { return 20, nil }) defer patches.Reset() var m myType sum, err := m.logicFunc(10, 20) So(sum, ShouldEqual, 20) So(err, ShouldBeNil) }) } // ############################################################### // ######################### ApplyGlobalVar ###################### // ############################################################### var num = 10 func TestApplyGlobalVar(t *testing.T) { Convey(\u0026#34;Test ApplyGlobalVar: \u0026#34;, t, func() { Convey(\u0026#34;change\u0026#34;, func() { patches := gomonkey.ApplyGlobalVar(\u0026amp;num, 150) defer patches.Reset() So(num, ShouldEqual, 150) }) Convey(\u0026#34;recover\u0026#34;, func() { So(num, ShouldEqual, 10) }) }) } // ############################################################### // ########################## ApplyFuncSeq ####################### // ############################################################### func getInt() (int) { a := 100 return a } func TestMockFuncSeq(t *testing.T) { Convey(\u0026#34;Test ApplyFuncSeq: \u0026#34;, t, func() { outputs := []gomonkey.OutputCell{ {Values:gomonkey.Params{2}, Times:1}, {Values:gomonkey.Params{1}, Times:0}, {Values:gomonkey.Params{3}, Times:2}, } var p1 = gomonkey.ApplyFuncSeq(getInt, outputs) defer p1.Reset() So(getInt(), ShouldEqual, 2) So(getInt(), ShouldEqual, 1) So(getInt(), ShouldEqual, 3) So(getInt(), ShouldEqual, 3) }) Convey(\u0026#34;Test ApplyFuncSeq: \u0026#34;, t, func () { So(getInt(), ShouldEqual, 100) }) } 执行命令 [iarno@nd01v monkey]$ go test -v -gcflags=-l . === RUN TestApplyFunc Test ApplyFunc: ✔✔ 2 total assertions --- PASS: TestApplyFunc (0.00s) === RUN TestApplyMethod Test ApplyMethod: ✔✔ 4 total assertions --- PASS: TestApplyMethod (0.00s) === RUN TestApplyGlobalVar Test ApplyGlobalVar: change ✔ recover ✔ 6 total assertions --- PASS: TestApplyGlobalVar (0.00s) === RUN TestMockFuncSeq Test ApplyFuncSeq: ✔✔✔✔ 10 total assertions Test ApplyFuncSeq: ✔ 11 total assertions --- PASS: TestMockFuncSeq (0.00s) PASS ok hellogolang/monkey (cached) 什么是内联 为了减少函数调用时的堆栈等开销，对于简短的函数，会在编译时，直接内嵌调用的代码。\n我们禁用下内联，然后执行， go test -v -gcflags=-l monkey_test.go\n参考 https://github.com/agiledragon/gomonkey\nhttps://juejin.cn/post/7111691109528502286\n","permalink":"https://www.iarno.cn/article/gomonkey/","tags":null,"title":"Gomonkey测试框架"},{"categories":["Go"],"contents":"这篇文章介绍了GoConvey测试框架的使用。GoConvey是一款针对Golang的测试框架，可以管理和运行测试用例，提供丰富的断言函数，并支持Web界面特性。文章详细介绍了如何安装GoConvey，如何编写测试用例，并展示了测试用例的执行结果。同时，文章还提供了一些编写测试用例的建议和参考链接。\n可以管理和运行测试用例，同时提供了丰富的断言函数，并支持很多 Web 界面特性。\nGolang虽然自带了单元测试功能，并且在GoConvey框架诞生之前也出现了许多第三方测试框架，但没有一个测试框架像GoConvey一样能够让程序员如此简洁优雅的编写测试代码。\n安装 go get github.com/smartystreets/goconvey 案例 package convey import ( \u0026#34;testing\u0026#34; . \u0026#34;github.com/smartystreets/goconvey/convey\u0026#34; ) func ShouldCustomize(actual interface{}, expected ...interface{}) string { if actual == \u0026#34;ok\u0026#34; \u0026amp;\u0026amp; expected[0] == \u0026#34;ok\u0026#34; { return \u0026#34;\u0026#34; } else { return \u0026#34;Fail!!!\u0026#34; } } func TestConvey(t *testing.T) { Convey(\u0026#34;test convey == convey\u0026#34;, t, func() { So(\u0026#34;convey\u0026#34;, ShouldEqual, \u0026#34;convey\u0026#34;) }) Convey(\u0026#34;test convey == convery\u0026#34;, t, func() { So(\u0026#34;convey\u0026#34;, ShouldEqual, \u0026#34;convery\u0026#34;) }) // 定制断言函数 Convey(\u0026#34;test customize should: \u0026#34;, t, func () { So(\u0026#34;ok\u0026#34;, ShouldCustomize, \u0026#34;ok\u0026#34;) So(\u0026#34;ok\u0026#34;, ShouldCustomize, \u0026#34;no\u0026#34;) }) } 执行命令 [iarno@xxx convey]$ go test -v . === RUN TestConvey test convey == convey ✔ 1 total assertion test convey == convery ✘ Failures: * /hellogolang/convey/convey_test.go Line 24: Expected: \u0026#39;convery\u0026#39; Actual: \u0026#39;convey\u0026#39; (Should be equal) Diff: \u0026#39;convery\u0026#39; 2 total assertions test customize should: ✔✘ Failures: * /hellogolang/convey/convey_test.go Line 29: Fail!!! 4 total assertions --- FAIL: TestConvey (0.00s) FAIL FAIL 小结 import goconvey包时，前面加点号\u0026quot;.\u0026quot;，以减少冗余的代码 测试函数的名字必须以Test开头，而且参数类型必须为*testing.T 每个测试用例必须使用Convey语句包裹起来，推荐使用Convey语句的嵌套，即一个函数有一个或多个测试函数，一个测试函数嵌套两层或三层Convey语句：当使用非BDD风格来写测试用例时，一个测试函数由两层Convey语句组成（第一层Convey语句对应目标函数，第二层Convey语句对应测试用例） 参考 https://github.com/smartystreets/goconvey\nhttps://www.jianshu.com/p/e3b2b1194830\n","permalink":"https://www.iarno.cn/article/goconvey/","tags":null,"title":"GoConvey测试框架"},{"categories":["其他"],"contents":"这篇文章介绍了如何使用tcpdump工具抓取和分析域名DNS解析过程。首先，使用tcpdump命令启动对DNS报文的抓包。然后，使用host命令进行DNS查询。最后，分析tcpdump的输出结果，解读DNS查询和应答报文的内容。文章还提到了如何使用tcpdump的-X选项以16进制和ASCII方式打印报文内容，以及如何将抓到的数据包写入到文件中，然后导入到Wireshark中查看。\n1 .启动 tcpdump 对 DNS 报文进行抓包 tcpdump -i eth0 -nt -s 500 port domain 使用port domain来过滤数据包，表示只抓取使用 domain（域名）服务的数据包，即 DNS 查询和应答报文\n-i Listen on interface. If unspecified, tcpdump searches the system interface list for the lowest numbered, configured up interface (excluding loopback). Ties are broken by choosing the earliest match. On Linux systems with 2.2 or later kernels, an interface argument of ‘‘any’’ can be used to capture packets from all interfaces. Note that captures on the ‘‘any’’ device will not be done in promiscuous mode. If the -D flag is supported, an interface number as printed by that flag can be used as the interface argument. -n Don’t convert host addresses to names. This can be used to avoid DNS lookups. -t Don’t print a timestamp on each dump line. -s Snarf snaplen bytes of data from each packet rather than the default of 65535 bytes. Packets truncated because of a limited snapshot are indicated in the output with ‘‘[|proto]’’, where proto is the name of the protocol level at which the truncation has occurred. Note that taking larger snapshots both increases the amount of time it takes to process packets and, effectively, decreases the amount of packet buffering. This may cause packets to be lost. You should limit snaplen to the smallest number that will capture the protocol information you’re interested in. Setting snaplen to 0 sets it to the default of 65535, for backwards compatibility with recent older versions of tcpdump. -X When parsing and printing, in addition to printing the headers of each packet, print the data of each packet (minus its link level header) in hex and ASCII. This is very handy for analysing new protocols. 2 .使用 host 命令进行 DNS 查询 命令如下：\nhost -t A www.baidu.com 3.分析 tcpdump 输出 当执行完第 2 步后，tcpdump 就会有输出，如下：\n[root@iZ25p102vo3Z ~]# tcpdump -i eth0 -nt -s 500 port domain tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on eth0, link-type EN10MB (Ethernet), capture size 500 bytes IP 10.162.201.34.48965 \u0026gt; 10.202.72.118.domain: 18831+ A? www.qq.com. (28) IP 10.202.72.118.domain \u0026gt; 10.162.201.34.48965: 18831 1/4/9 A 101.226.103.106 (275) 这两个数据包开始的“IP”指出，它们后面的内容描述的是 IP 数据报。 Tcpdump 以 “IP 地址.端口号” 的形式来描述通信的某一端； 以 “\u0026gt;” 表示数据传输的方向，“\u0026gt;” 前面是源端，后面是目的端。 可见，第一个数据包是测试机器（IP 地址是 10.162.201.34）向其首选 DNS 服务器（IP 地址是 10.202.72.118） 发送的 DNS 查询报文（目标端口 53 是 DNS 服务使用的端口）， 第二个数据包是服务器反馈的 DNS 应答报文。\n第一个数据包中，数值 18831 是 DNS 查询报文的标识值，因此该值也出现在 DNS 应答报文中。 “+” 表示启用递归查询标志。 “A?” 表示使用 A 类型的查询方式。 “www.qq.com” 则是 DNS 查询问题中的查询名。 括号中的数值 28 是 DNS 查询报文的长度（以字节为单位）。\n第二个数据包中，“1/4/9” 表示该报文中包含 1 个应答资源记录、4 个授权资源记录和 9 个额外信息记录。 该应答报文的长度为 275 字节。\n注意：我们抓包的时候没有开启 tcpdump 的 -X 选项（或者 -x 选项）。 如果使用 -X 选项，我们将能看到 DNS 报文的每一个字节，也就能明白上面 28 字节的查询报文和 275 字节的应答报文的具体含义。\n上面使用 -X 选项，是以 16 进制和 ASCII 方式打印，不太直观地看出来报文内容， 这里我们可以使用 Tcpdump 将抓到的数据包写入到文件中，然后导入到 Wireshark 中查看。\n[root@VM_15_187_centos ~]# tcpdump -i eth0 -nt -s 500 -X port domain -w dns-dump.pcap -v tcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 500 bytes ^C2 packets captured 2 packets received by filter 0 packets dropped by kernel 转载 https://jaminzhang.github.io/dns/use-tcpdump-to-analyze-dns-communication/\n","permalink":"https://www.iarno.cn/article/tcpdump-dns/","tags":["dns抓包"],"title":"使用tcpdump查看域名DNS解析过程"},{"categories":["Go"],"contents":"这篇文章主要分析了Go语言中不同JSON库的性能。作者测试了ffjson、easyjson、jsoniter、codecjson和jsonparser等库，结果显示easyjson在序列化和反序列化方面表现最优，性能提升显著。jsoniter性能也很好，且100%兼容原生库。ffjson和codecjson的性能提升不明显，而jsonparser并不适合这样的场景。作者建议在追求极致性能时考虑使用easyjson，否则使用jsoniter。\nGo 语言里面原生支持了这种数据格式的序列化以及反序列化，内部使用反射机制实现，性能有点差，在高度依赖 json 解析的应用里，往往会成为性能瓶颈，好在已有很多第三方库帮我们解决了这个问题，但是这么多库，对于像我这种有选择困难症的人来说，到底要怎么选择呢，下面就给大家来一一分析一下\nffjson go get -u github.com/pquerna/ffjson 原生的库性能比较差的主要原因是使用了很多反射的机制，为了解决这个问题，ffjson 通过预编译生成代码，类型的判断在预编译阶段已经确定，避免了在运行时的反射\n但也因此在编译前需要多一个步骤，需要先生成 ffjson 代码，生成代码只需要执行 ffjson \u0026lt;file.go\u0026gt; 就可以了，其中 file.go 是一个包含 json 结构体定义的 go 文件。注意这里 ffjson 是这个库提供的一个代码生成工具，直接执行上面的 go get 会把这个工具安装在 $GOPATH/bin 目录下，把 $GOPATH/bin 加到 $PATH 环境变量里面，可以全局访问\n另外，如果有些结构，不想让 ffjson 生成代码，可以通过增加注释的方式\n// ffjson: skip type Foo struct { Bar string } // ffjson: nodecoder type Foo struct { Bar string } easyjson go get -u github.com/mailru/easyjson/... easyjson 的思想和 ffjson 是一致的，都是增加一个预编译的过程，预先生成对应结构的序列化反序列化代码，除此之外，easyjson 还放弃了一些原生库里面支持的一些不必要的特性，比如：key 类型声明，key 大小写不敏感等等，以达到更高的性能\n生成代码执行 easyjson -all \u0026lt;file.go\u0026gt; 即可，如果不指定 -all 参数，只会对带有 //easyjson:json 的结构生成代码\n//easyjson:json type A struct { Bar string } jsoniter go get -u github.com/json-iterator/go 这是一个很神奇的库，滴滴开发的，不像 easyjson 和 ffjson 都使用了预编译，而且 100% 兼容原生库，但是性能超级好，也不知道怎么实现的，如果有人知道的话，可以告诉我一下吗？\n使用上面，你只要把所有的\nimport \u0026#34;encoding/json\u0026#34; 替换成\nimport \u0026#34;github.com/json-iterator/go\u0026#34; var json = jsoniter.ConfigCompatibleWithStandardLibrary 就可以了，其它都不需要动\ncodec-json go get -u github.com/ugorji/go/codec 这个库里面其实包含很多内容，json 只是其中的一个功能，比较老，使用起来比较麻烦，性能也不是很好\njsonparser go get -u github.com/buger/jsonparser 严格来说，这个库不属于 json 序列化的库，只是提供了一些 json 解析的接口，使用的时候需要自己去设置结构里面的值，事实上，每次调用都需要重新解析 json 对象，性能并不是很好\n就像名字暗示的那样，这个库只是一个解析库，并没有序列化的接口\n性能测试 对上面这些 json 库，作了一些性能测试，测试代码在：https://github.com/hatlonely/\u0026hellip;，下面是在我的 Macbook 上测试的结果（实际结果和库的版本以及机器环境有关，建议自己再测试一遍）：\nBenchmarkMarshalStdJson-4 1000000 1097 ns/op BenchmarkMarshalJsonIterator-4 2000000 781 ns/op BenchmarkMarshalFfjson-4 2000000 941 ns/op BenchmarkMarshalEasyjson-4 3000000 513 ns/op BenchmarkMarshalCodecJson-4 1000000 1074 ns/op BenchmarkMarshalCodecJsonWithBufio-4 1000000 2161 ns/op BenchmarkUnMarshalStdJson-4 500000 2512 ns/op BenchmarkUnMarshalJsonIterator-4 2000000 591 ns/op BenchmarkUnMarshalFfjson-4 1000000 1127 ns/op BenchmarkUnMarshalEasyjson-4 2000000 608 ns/op BenchmarkUnMarshalCodecJson-4 20000 122694 ns/op BenchmarkUnMarshalCodecJsonWithBufio-4 500000 3417 ns/op BenchmarkUnMarshalJsonparser-4 2000000 877 ns/op 从上面的结果可以看出来：\neasyjson 无论是序列化还是反序列化都是最优的，序列化提升了1倍，反序列化提升了3倍 jsoniter 性能也很好，接近于easyjson，关键是没有预编译过程，100%兼容原生库 ffjson 的序列化提升并不明显，反序列化提升了1倍 codecjson 和原生库相比，差不太多，甚至更差 jsonparser 不太适合这样的场景，性能提升并不明显，而且没有反序列化 所以综合考虑，建议大家使用 jsoniter，如果追求极致的性能，考虑 easyjson\n参考链接 ffjson: https://github.com/pquerna/ff\u0026hellip;\neasyjson: https://github.com/mailru/eas\u0026hellip;\njsoniter: https://github.com/json-itera\u0026hellip;\njsonparser: https://github.com/buger/json\u0026hellip;\ncodecjson: http://ugorji.net/blog/go-cod\u0026hellip;\ngolang-json性能对比:https://github.com/iarno/golang-json\n转载 https://segmentfault.com/a/1190000013022780\n","permalink":"https://www.iarno.cn/article/golang-json/","tags":null,"title":"Golang json 性能分析"},{"categories":["Go"],"contents":"这篇文章详述了Go语言的benchmark性能测试的使用方法和解析。它详细阐述了go test命令的参数及其作用，并通过一个实例展示了如何进行性能测试和结果分析。文章还介绍了如何利用pprof进行性能分析，并提供了相关的参考链接。\n使用方法 下面展示一个基准测试的示例代码来剖析下它的使用方式：\nfunc Benchmark_test(b *testing.B) { for i := 0; i \u0026lt; b.N ; i++ { s := make([]int, 0) for i := 0; i \u0026lt; 10000; i++ { s = append(s, i) } } } 进行基准测试的文件必须以*_test.go的文件为结尾，这个和测试文件的名称后缀是一样的，例如abc_test.go 参与Benchmark基准性能测试的方法必须以Benchmark为前缀，例如BenchmarkABC() 参与基准测试函数必须接受一个指向Benchmark类型的指针作为唯一参数，*testing.B 基准测试函数不能有返回值 b.ResetTimer是重置计时器，调用时表示重新开始计时，可以忽略测试函数中的一些准备工作 b.N是基准测试框架提供的，表示循环的次数，因为需要反复调用测试的代码，才可以评估性能 命令及参数 性能测试命令为go test [参数]，比如go test -bench=. -benchmem，具体的命令参数及含义如下：\n参数 含义 -bench regexp 性能测试，支持表达式对测试函数进行筛选。 -bench . 则是对所有的benchmark函数测试，指定名称则只执行具体测试方法而不是全部 -benchmem 性能测试的时候显示测试函数的内存分配的统计信息 －count n 运行测试和性能多少此，默认一次 -run regexp 只运行特定的测试函数， 比如-run ABC只测试函数名中包含ABC的测试函数 -timeout t 测试时间如果超过t, panic,默认10分钟 -v 显示测试的详细信息，也会把Log、Logf方法的日志显示出来 测试结果 执行命令后，性能测试的结果展示如下\n$ go test -bench=. -benchmem goos: darwin goarch: amd64 pkg: program/benchmark cpu: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz Benchmark_test-12 7439091 152.0 ns/op 248 B/op 5 allocs/op PASS ok promgram/benchmark 1.304s 对以上结果进行逐一分析：\n结果项 含义 Benchmark_test-12 Benchmark_test 是测试的函数名 -12 表示GOMAXPROCS（线程数）的值为12 7439091 表示一共执行了7439091次，即b.N的值 152.0 ns/op 表示平均每次操作花费了152.0纳秒 248B/op 表示每次操作申请了248Byte的内存申请 5 allocs/op 表示每次操作申请了5次内存 性能对比实例 下面通过一个数字转换字符串的实例来对比性能测试效果，并进行分析。\n//Sprintf func BenchmarkSprintf(b *testing.B) { num := 10 b.ResetTimer() for i := 0; i \u0026lt; b.N; i++ { fmt.Sprintf(\u0026#34;%d\u0026#34;, num) } } //Format func BenchmarkFormat(b *testing.B) { num := int64(10) b.ResetTimer() for i := 0; i \u0026lt; b.N; i++ { strconv.FormatInt(num, 10) } } //Itoa func BenchmarkItoa(b *testing.B) { num := 10 b.ResetTimer() for i := 0; i \u0026lt; b.N; i++ { strconv.Itoa(num) } } 下面执行命令go test -bench=. -benchmem，收到测试报告如下：\n% go test -bench=. -benchmem goos: darwin goarch: amd64 pkg: program/benchmark cpu: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz BenchmarkSprintf-12 16364854 63.70 ns/op 2 B/op 1 allocs/op BenchmarkFormat-12 493325650 2.380 ns/op 0 B/op 0 allocs/op BenchmarkItoa-12 481683436 2.503 ns/op 0 B/op 0 allocs/op PASS ok program/benchmark 4.007s 可以发现，BenchmarkSprintf方法耗时最长，BenchmarkFormat最快，BenchmarkItoa也很快。差别在于fmt.Sprintf()执行过程中进行了一次内存分配1 allocs/op。\n结合pprof分析 参数 含义 命令示例 -cpuprofile [file] 输出cpu性能文件 go test -bench=. -benchmem -cpuprofile=cpu.out -memprofile [file] 输出mem内存性能文件 go test -bench=. -benchmem -memprofile=cpu.out 生成的CPU、内存文件可以通过go tool pprof [file]进行查看，然后在pprof中通过list [file]方法查看CPU、内存的耗时情况\n### 内存情况 (pprof) list BenchmarkArrayAppend Total: 36.49GB ROUTINE ======================== program/benchmark.BenchmarkArrayAppend in /Users/guanjian/workspace/go/program/benchmark/benchmark_test.go 11.98GB 11.98GB (flat, cum) 32.83% of Total . . 7://Array . . 8:func BenchmarkArrayAppend(b *testing.B) { . . 9: for i := 0; i \u0026lt; b.N; i++ { . . 10: var arr []int . . 11: for i := 0; i \u0026lt; 10000; i++ { 11.98GB 11.98GB 12: arr = append(arr, i) . . 13: } . . 14: } . . 15:} ## CPU情况 (pprof) list BenchmarkArrayAppend Total: 8.86s ROUTINE ======================== program/benchmark.BenchmarkArrayAppend in /Users/guanjian/workspace/go/program/benchmark/benchmark_test.go 10ms 640ms (flat, cum) 7.22% of Total . . 6: . . 7://Array . . 8:func BenchmarkArrayAppend(b *testing.B) { . . 9: for i := 0; i \u0026lt; b.N; i++ { . . 10: var arr []int 10ms 10ms 11: for i := 0; i \u0026lt; 10000; i++ { . 630ms 12: arr = append(arr, i) . . 13: } . . 14: } . . 15:} 总结 go提供了benchmark性能测试的工具，提供了对函数使用内存、CPU等情况的报告分析，还可以借助pprof获得更好的分析报告等，如果想要深入分析，还可以使用之前介绍的gdb进行底层代码的链路跟踪，以及对代码进行反编译查看具体的性能损耗情况。\n参考 go benchmark 性能测试 单元测试 基准测试 使用方法详解 go benchmark 性能测试 转载 https://juejin.cn/post/6970615934255906830\n","permalink":"https://www.iarno.cn/article/benchmark/","tags":null,"title":"Golang benchmark 性能测试"},{"categories":["BigData"],"contents":"本文主要介绍了Maven的安装和使用，包括项目构建、依赖管理等。首先，我们需要下载并配置Maven，然后通过pom.xml文件进行项目管理。文章详细解释了如何使用Maven创建Java应用，以及如何构建和测试项目。最后，我们学习了如何执行jar包，包括pom.xml文件中需要引入的assembly插件和执行命令。\n下载 https://www.runoob.com/maven/maven-setup.html\n约定配置 Maven 提倡使用一个共同的标准目录结构，Maven 使用约定优于配置的原则，大家尽可能的遵守这样的目录结构。如下所示：\n目录 目的 ${basedir} 存放pom.xml和所有的子目录 ${basedir}/src/main/java 项目的java源代码 ${basedir}/src/main/resources 项目的资源，比如说property文件，springmvc.xml ${basedir}/src/test/java 项目的测试类，比如说Junit代码 ${basedir}/src/test/resources 测试用的资源 ${basedir}/src/main/webapp/WEB-INF web应用文件目录，web项目的信息，比如存放web.xml、本地图片、jsp视图页面 ${basedir}/target 打包输出目录 ${basedir}/target/classes 编译输出目录 ${basedir}/target/test-classes 测试编译输出目录 Test.java Maven只会自动运行符合该命名规则的测试类 ~/.m2/repository Maven默认的本地仓库目录位置 pom.xml说明 https://www.runoob.com/maven/maven-pom.html\n配置阿里云仓库 \u0026lt;mirror\u0026gt; \u0026lt;id\u0026gt;alimaven\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;aliyun maven\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://maven.aliyun.com/nexus/content/groups/public/\u0026lt;/url\u0026gt; \u0026lt;mirrorOf\u0026gt;central\u0026lt;/mirrorOf\u0026gt; \u0026lt;/mirror\u0026gt; \u0026lt;mirror\u0026gt; \u0026lt;id\u0026gt;UK\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;UK Central\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://uk.maven.org/maven2\u0026lt;/url\u0026gt; \u0026lt;mirrorOf\u0026gt;central\u0026lt;/mirrorOf\u0026gt; \u0026lt;/mirror\u0026gt; \u0026lt;mirror\u0026gt; \u0026lt;id\u0026gt;ibiblio.org\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;ibiblio Mirror of http://repo1.maven.org/maven2/\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://mirrors.ibiblio.org/pub/mirrors/maven2\u0026lt;/url\u0026gt; \u0026lt;mirrorOf\u0026gt;central\u0026lt;/mirrorOf\u0026gt; \u0026lt;!-- United States, North Carolina --\u0026gt; \u0026lt;/mirror\u0026gt; \u0026lt;mirror\u0026gt; \u0026lt;id\u0026gt;jboss-public-repository-group\u0026lt;/id\u0026gt; \u0026lt;mirrorOf\u0026gt;central\u0026lt;/mirrorOf\u0026gt; \u0026lt;name\u0026gt;JBoss Public Repository Group\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://repository.jboss.org/nexus/content/groups/public\u0026lt;/url\u0026gt; \u0026lt;/mirror\u0026gt; Maven 构建 Java 项目 Maven 使用原型 archetype 插件创建项目。要创建一个简单的 Java 应用，我们将使用 maven-archetype-quickstart 插件。\n在下面的例子中，我们将在 C:\\MVN 文件夹下创建一个基于 maven 的 java 应用项目。\n命令格式如下：\nmvn archetype:generate \u0026#34;-DgroupId=com.companyname.bank\u0026#34; \u0026#34;-DartifactId=consumerBanking\u0026#34; \u0026#34;-DarchetypeArtifactId=maven-archetype-quickstart\u0026#34; \u0026#34;-DinteractiveMode=false\u0026#34; 参数说明：\n-DgroupId: 组织名，公司网址的反写 + 项目名称 -DartifactId: 项目名-模块名 -DarchetypeArtifactId: 指定 ArchetypeId，maven-archetype-quickstart，创建一个简单的 Java 应用 -DinteractiveMode: 是否使用交互模式 Maven 构建 \u0026amp; 项目测试 在上一章节中我们学会了如何使用 Maven 创建 Java 应用。接下来我们要学习如何构建和测试这个项目。\n进入 C:/MVN 文件夹下，打开 consumerBanking 文件夹。你将看到有一个 pom.xml 文件，代码如下：\n\u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;com.companyname.bank\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;consumerBanking\u0026lt;/artifactId\u0026gt; \u0026lt;packaging\u0026gt;jar\u0026lt;/packaging\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;consumerBanking\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://maven.apache.org\u0026lt;/url\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;junit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.8.1\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/project\u0026gt; 从以上 xml代码中，可知 Maven 已经添加了 JUnit 作为测试框架。\n默认情况下 Maven 添加了一个源码文件 C:\\MVN\\consumerBanking\\src\\main\\java\\com\\companyname\\bank\\App.java和一个测试文件 C:\\MVN\\consumerBanking\\src\\test\\java\\com\\companyname\\bank\\AppTest.java。\n打开命令控制台，跳转到 C:\\MVN\\consumerBanking 目录下，并执行以下 mvn 命令开始构建项目：\nC:\\MVN\\consumerBanking\u0026gt;mvn clean package [INFO] Scanning for projects... [INFO] ------------------------------------------------------------------- [INFO] Building consumerBanking [INFO] task-segment: [clean, package] [INFO] ------------------------------------------------------------------- [INFO] [clean:clean {execution: default-clean}] [INFO] Deleting directory C:\\MVN\\consumerBanking\\target ... ... ... [INFO] [jar:jar {execution: default-jar}] [INFO] Building jar: C:\\MVN\\consumerBanking\\target\\ consumerBanking-1.0-SNAPSHOT.jar [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESSFUL [INFO] ------------------------------------------------------------------------ [INFO] Total time: 2 seconds [INFO] Finished at: Tue Jul 10 16:52:18 IST 2012 [INFO] Final Memory: 16M/89M [INFO] ------------------------------------------------------------------------ 执行完后，我们已经构建了自己的项目并创建了最终的 jar 文件，下面是要学习的关键概念：\n我们给了 maven 两个目标，首先清理目标目录（clean），然后打包项目构建的输出为 jar（package）文件。 打包好的 jar 文件可以在 consumerBanking\\target 中获得，名称为 consumerBanking-1.0-SNAPSHOT.jar。 测试报告存放在 consumerBanking\\target\\surefire-reports 文件夹中。 Maven 编译源码文件，以及测试源码文件。 接着 Maven 运行测试用例。 最后 Maven 创建项目包。 C:\\MVN\\consumerBanking\\target\\classes\u0026gt;java com.companyname.bank.App 你可以看到结果：\nHello World! 执行jar包 pom.xml文件需引入assembly插件。\n\u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-assembly-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.3.0\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;descriptorRefs\u0026gt; \u0026lt;descriptorRef\u0026gt;jar-with-dependencies\u0026lt;/descriptorRef\u0026gt; \u0026lt;/descriptorRefs\u0026gt; \u0026lt;archive\u0026gt; \u0026lt;manifest\u0026gt; \u0026lt;mainClass\u0026gt;cn.iarno.www.App\u0026lt;/mainClass\u0026gt; \u0026lt;/manifest\u0026gt; \u0026lt;/archive\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;phase\u0026gt;package\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;single\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; 执行命令:\n[root@hadoop target]# java -jar xxx.-jar-with-dependencies.jar ","permalink":"https://www.iarno.cn/article/maven/","tags":["hadoop"],"title":"Maven 安装使用"},{"categories":["BigData"],"contents":"这篇文章是关于如何在ECS实例上快速搭建Hadoop伪分布式环境的教程。主要步骤包括安装JDK，安装Hadoop，配置Hadoop，配置SSH免密登录，以及启动Hadoop。每个步骤都有详细的命令和操作说明，以及相关的参考链接。完成所有步骤后，可以通过访问特定的URL来验证Hadoop环境是否已成功搭建。\n大多数教程都是从 http://s.iarno.cn/pegHbK 下载安装包，目前该网站已收费，所以另寻途径安装hadoop环境。\n背景信息 Hadoop是一款由Apache基金会用Java语言开发的分布式开源软件框架，用户可以在不了解分布式底层细节的情况下，开发分布式程序，充分利用集群的能力进行高速运算和存储。Hadoop的核心部件是HDFS（Hadoop Distributed File System）和MapReduce：\nHDFS：是一个分布式文件系统，可对应用程序数据进行分布式储存和读取。 MapReduce：是一个分布式计算框架，MapReduce的核心思想是把计算任务分配给集群内的服务器执行。通过对计算任务的拆分（Map计算和Reduce计算），再根据任务调度器（JobTracker）对任务进行分布式计算。 更多信息，请参见Hadoop官网。\n操作步骤 在ECS实例上快速搭建Hadoop伪分布式环境的操作步骤如下：\n步骤一：安装JDK 步骤二：安装Hadoop 步骤三：配置Hadoop 步骤四：配置SSH免密登录 步骤五：启动Hadoop 步骤一：安装JDK 远程连接已创建的ECS实例。 具体操作，请参见连接方式概述。\n执行以下命令，下载JDK 1.8安装包。\nwget https://download.java.net/openjdk/jdk8u41/ri/openjdk-8u41-b04-linux-x64-14_jan_2020.tar.gz 执行以下命令，解压下载的JDK 1.8安装包。\ntar -zxvf openjdk-8u41-b04-linux-x64-14_jan_2020.tar.gz 执行以下命令，移动并重命名JDK安装包。\n本示例中将JDK安装包重命名为java8，您可以根据需要使用其他名称。\nmv java-se-8u41-ri/ /usr/java8 执行以下命令，配置Java环境变量。\n如果您将JDK安装包重命名为其他名称，需将以下命令中的java8替换为实际的名称。\necho \u0026#39;export JAVA_HOME=/usr/java8\u0026#39; \u0026gt;\u0026gt; /etc/profile echo \u0026#39;export PATH=$PATH:$JAVA_HOME/bin\u0026#39; \u0026gt;\u0026gt; /etc/profile source /etc/profile 执行以下命令，查看Java是否成功安装。\njava -version 如果返回以下信息，则表示Java已安装成功。\nopenjdk version \u0026#34;1.8.0_41\u0026#34; OpenJDK Runtime Environment (build 1.8.0_41-b04) OpenJDK 64-Bit Server VM (build 25.40-b25, mixed mode) 步骤二：安装Hadoop 执行以下命令，下载Hadoop安装包。\nwget https://mirrors.bfsu.edu.cn/apache/hadoop/common/hadoop-2.10.1/hadoop-2.10.1.tar.gz 执行以下命令，解压Hadoop安装包至/opt/hadoop。\ntar -zxvf hadoop-2.10.1.tar.gz -C /opt/ mv /opt/hadoop-2.10.1 /opt/hadoop 执行以下命令，配置Hadoop环境变量。\necho \u0026#39;export HADOOP_HOME=/opt/hadoop/\u0026#39; \u0026gt;\u0026gt; /etc/profile echo \u0026#39;export PATH=$PATH:$HADOOP_HOME/bin\u0026#39; \u0026gt;\u0026gt; /etc/profile echo \u0026#39;export PATH=$PATH:$HADOOP_HOME/sbin\u0026#39; \u0026gt;\u0026gt; /etc/profile source /etc/profile 执行以下命令，修改配置文件yarn-env.sh和hadoop-env.sh。\necho \u0026#34;export JAVA_HOME=/usr/java8\u0026#34; \u0026gt;\u0026gt; /opt/hadoop/etc/hadoop/yarn-env.sh echo \u0026#34;export JAVA_HOME=/usr/java8\u0026#34; \u0026gt;\u0026gt; /opt/hadoop/etc/hadoop/hadoop-env.sh 执行以下命令，测试Hadoop是否安装成功。\nhadoop version 如果返回以下信息，则表示安装成功。\nHadoop 2.10.1 Subversion https://github.com/apache/hadoop -r 1827467c9a56f133025f28557bfc2c562d78e816 Compiled by centos on 2020-09-14T13:17Z Compiled with protoc 2.5.0 From source with checksum 3114edef868f1f3824e7d0f68be03650 This command was run using /opt/hadoop/share/hadoop/common/hadoop-common-2.10.1.jar 步骤三：配置Hadoop 修改Hadoop配置文件core-site.xml。 执行以下命令，进入编辑页面。\nvim /opt/hadoop/etc/hadoop/core-site.xml 输入i，进入编辑模式。\n在\u0026lt;configuration\u0026gt;\u0026lt;/configuration\u0026gt;节点内，插入如下内容。\n\u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hadoop.tmp.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:/opt/hadoop/tmp\u0026lt;/value\u0026gt; \u0026lt;!-- 自行修改 --\u0026gt; \u0026lt;description\u0026gt;location to store temporary files\u0026lt;/description\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;fs.defaultFS\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hdfs://localhost:8020\u0026lt;/value\u0026gt; \u0026lt;!-- host+port自行修改 --\u0026gt; \u0026lt;/property\u0026gt; 按Esc，退出编辑模式，并输入:wq保存并退出。\n修改Hadoop配置文件hdfs-site.xml。 执行以下命令，进入编辑页面。\nvim /opt/hadoop/etc/hadoop/hdfs-site.xml 输入i，进入编辑模式。\n在\u0026lt;configuration\u0026gt;\u0026lt;/configuration\u0026gt;节点内，插入如下内容。\n\u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.replication\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;1\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.name.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:/opt/hadoop/tmp/dfs/name\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.datanode.data.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:/opt/hadoop/tmp/dfs/data\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; 按Esc，退出编辑模式，并输入:wq后保存并退出。\n步骤四：配置SSH免密登录 执行以下命令，创建公钥和私钥。\nssh-keygen -t rsa 回显信息如下所示，表示创建公钥和私钥成功。\n[root@iZbp1chrrv37a2kts7sydsZ ~]# ssh-keygen -t rsa Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa. Your public key has been saved in /root/.ssh/id_rsa.pub. The key fingerprint is: SHA256:gjWO5mgARst+O5VUaTnGs+LxVhfmCJnQwKfEBTro2oQ root@iZbp1chrrv37a2kts7s**** The key\u0026#39;s randomart image is: +---[RSA 2048]----+ | . o+Bo= | |o o .+.# o | |.= o..B = + . | |=. oO.o o o | |Eo..=o* S . | |.+.+o. + | |. +o. . | | . . | | | +----[SHA256]-----+ 执行以下命令，将公钥添加到authorized_keys文件中。\ncd .ssh cat id_rsa.pub \u0026gt;\u0026gt; authorized_keys 步骤五：启动Hadoop 执行以下命令，初始化namenode 。\nhadoop namenode -format 依次执行以下命令，启动Hadoop。\nstart-dfs.sh 在弹出的提示中，依次输入yes。\nstart-yarn.sh 回显信息如下所示。\n[root@iZbp1chrrv37a2kts7s**** .ssh]# start-yarn.sh starting yarn daemons starting resourcemanager, logging to /opt/hadoop/logs/yarn-root-resourcemanager-iZbp1chrrv37a2kts7sydsZ.out localhost: starting nodemanager, logging to /opt/hadoop/logs/yarn-root-nodemanager-iZbp1chrrv37a2kts7sydsZ.out 执行以下命令，可查看成功启动的进程。\njps 成功启动的进程如下所示。\n[root@iZbp1chrrv37a2kts7s**** .ssh]# jps 11620 DataNode 11493 NameNode 11782 SecondaryNameNode 11942 ResourceManager 12344 Jps 12047 NodeManager 打开浏览器访问http://\u0026lt;ECS公网IP\u0026gt;:8088和http://\u0026lt;ECS公网IP\u0026gt;:50070。\n显示如下界面，则表示Hadoop伪分布式环境已搭建完成。\n注意 需确保在ECS实例所在安全组的入方向中放行Hadoop所需的8088和50070端口，否则无法访问。具体操作，请参见添加安全组规则。\n参考链接 http://s.iarno.cn/fRVfE9\nhttp://s.iarno.cn/WrjzRC\n","permalink":"https://www.iarno.cn/article/hadoop%E6%90%AD%E5%BB%BA%E4%B8%80/","tags":["hadoop"],"title":"Hadoop 环境搭建（一）"},{"categories":["Python"],"contents":"这篇文章是关于Python列表的详细教程。它首先介绍了如何访问和修改列表元素，然后讲解了如何在列表末尾添加元素和在列表中插入元素。接着，文章详细解释了如何使用del和pop()方法根据索引删除元素，以及如何根据值删除元素。文章还介绍了sort()和sorted()方法进行列表排序，以及如何倒序打印列表元素和获取列表长度。最后，文章讲解了如何遍历整个列表，创建数值列表和数字列表，以及如何使用列表解析和列表切片。\n3.1 访问元素 items = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;, 1] print(items[0]) print(items[-1]) print(items[10]) # 越界报错 # output # a # 1 # Traceback (most recent call last): # File \u0026#34;xxxxx\u0026#34;, line 7, in \u0026lt;module\u0026gt; # print(items[10]) # IndexError: list index out of range 3.2 修改元素 items = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;, 1] print(items) items[3] = \u0026#34;d\u0026#34; print(items) # output # [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, 1] # [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;] 列表末尾添加元素 items = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;] print(items) items.append(\u0026#34;d\u0026#34;) print(items) # output # [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;] # [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;] 列表中插入元素 items = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;] print(items) items.insert(3, \u0026#34;f\u0026#34;) print(items) items.insert(10, \u0026#34;z\u0026#34;) # 最后一位元素索引加1，并不是在第10个索引位新加入元素 print(items[8]) # 越界报错 # output # [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;] # [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;f\u0026#39;] # Traceback (most recent call last): # File \u0026#34;xxxxx\u0026#34;, line 43, in \u0026lt;module\u0026gt; # print(items[8]) # IndexError: list index out of range 使用del删除元素 items = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;] del items[0] #del items[10] # 越界报错 print(items) # output # [\u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;] 使用方法pop()根据索引删除元素 items = [1, 2, 3] items.pop() first = items.pop(0) #items.pop(10) # 越界报错 print(first) print(items) # output # 1 # [2] 根据值删除元素 items = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;a\u0026#34;] items.remove(\u0026#34;a\u0026#34;) # remove只删除第一个指定的值,最后一个a元素还在 #items.remove(\u0026#34;d\u0026#34;) # 报错 print(items) # output # [\u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;a\u0026#39;] sort()列表永久排序 items = [\u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;f\u0026#34;] items.sort() print(items) # output # [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;f\u0026#39;] sorted()列表临时排序 items = [\u0026#34;b\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;d\u0026#34;, \u0026#34;c\u0026#34;] print(sorted(items)) print(items) # output # [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;] # [\u0026#39;b\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;c\u0026#39;] 倒着打印列表元素 items = [\u0026#34;a\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;d\u0026#34;, \u0026#34;f\u0026#34;] items.reverse() print(items) # output # [\u0026#39;f\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;a\u0026#39;] 获取列表长度 items = [1, 2, 3, 4] print(len(items)) # output # 4 4.1 遍历整个列表 items = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;] for item in items: print(item) # output # a # b # c 4.3 创建数值列表 for value in range(1, 4): print(value) # output 不包含4 # 1 # 2 # 3 创建数字列表 items = *list*(range(1, 4)) print(items) # output # [1, 2, 3] 打印1到10的偶数 for n in range(2, 11, 2): print(n) # output # 2 # 4 # 6 # 8 4.3.4 列表解析 items = [] for value in range(1, 10): items.append(value**2) print(items) # output # [1, 4, 9, 16, 25, 36, 49, 64, 81] items = [value**2 for value in range(1, 10)] print(items) # output # [1, 4, 9, 16, 25, 36, 49, 64, 81] 4.4 使用列表的一部分 items = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;] print(items[1:]) print(items[:2]) print(items[:10]) # 没问题，和前面越界做对比 print(items[-10:]) # output # [\u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;] # [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;] # [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;] # [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;] ","permalink":"https://www.iarno.cn/article/py_list/","tags":["Python编程从入门到实战"],"title":"Python 列表"},{"categories":["Python"],"contents":"这篇文章主要介绍了Python中的变量和简单数据类型，包括字符串、整数、浮点数和常量。在字符串部分，文章详细解释了如何使用方法修改字符串中的大小写，如何在字符串中使用变量，如何使用制表符和换行符添加空格，以及如何删除字符串两端的特殊字符。在数字部分，文章讲解了整数和浮点数的基本操作，以及如何在数字中使用下划线。此外，文章还介绍了如何给多个变量赋值，以及如何定义常量。\n2.3 字符串 使用方法修改字符串中大小写 name = \u0026#34;hello world\u0026#34; print(name) print(name.title()) print(name.upper()) ## 转大写 print(name.upper().lower()) # 转小写 # output # hello world # Hello World # HELLO WORLD # hello world 字符串中使用变量 str1 = \u0026#34;zhang\u0026#34; str2 = \u0026#34;san\u0026#34; name = f\u0026#34;name: {str1} {str2}\u0026#34; print(name) # f是format的简写(Python3.6引入)把花括号内的变量替换为其值 # output # name: zhang san 制表符和换行符来添加空格 print(\u0026#34;Languages:\\nPython\\nGolang\\nPhp\u0026#34;) print(\u0026#34;Languages:\\n\\tPython\\n\\tGolang\\n\\tPhp\u0026#34;) # output # Languages: # Python # Golang # Php # Languages: # Python # Golang # Php 删除左右两条特殊字符 str1 = \u0026#34;Python#\u0026#34; print(str1.rstrip(\u0026#34;#\u0026#34;)) str2 = \u0026#34;#Python\u0026#34; print(str2.lstrip(\u0026#34;#\u0026#34;)) str3 = \u0026#34;#Python#\u0026#34; print(str3.strip(\u0026#34;#\u0026#34;)) # output # Python # Python # Python 2.4 数 整数 print(3**2) print(3**3) # output # 9 # 27 浮点数 print(0.1 + 0.1) # Notice: 结果位保留的小数位可能是不确定的 print(0.2 + 0.1) print(3 * 0.1) # output # 0.2 # 0.30000000000000004 # 0.30000000000000004 无论是哪种运算，只要有操作数是浮点数，Python默认得到的总是浮点数，即便结果原本为整数也是如此。\nprint(4/2) print(1 + 2.0) print(2 * 3.0) print(3.0 ** 2) # output # 2.0 # 3.0 # 6.0 # 9.0 数中的下划线 m = 14_000_000 print(m) # output # 14000000 给多个变量赋值 x, y, z = 1, 0.2, \u0026#34;x\u0026#34; print(x,y,z) # output # 1 0.2 x 常量 # 命名大写 MAX_CONNECTIONS = 5000 视频链接 https://las.h5.xeknow.com/s/2dehjV\n","permalink":"https://www.iarno.cn/article/py_string/","tags":["Python编程从入门到实战"],"title":"Python 变量和简单数据类型"},{"categories":["其他"],"contents":"本文详细介绍了如何使用LVS和Keepalived实现集群高可用。首先，我们在LVS服务器上安装ipvsadm和keepalived服务，然后在WEB服务器上安装nginx服务并配置index.html文件。接着，我们在LVS服务器上配置keepalived.conf文件和RS服务，最后通过访问VIP来验证配置的正确性。整个过程中，我们详细解释了每一步的操作和配置的含义，帮助读者更好地理解和实践。\n机器说明 IP 说明 192.168.199.13 LVS服务器 192.168.199.11 WEB服务器1 192.168.199.12 WEB服务器2 192.168.199.101 VIP(虚拟IP) LVS服务器 # 安装ipvsadm [root@localhost ~] yum install ipvsadm -y # 安装keepalived服务 [root@localhost ~] yum install keepalived -y WEB服务器1 # 安装nginx服务 [root@localhost ~] yum -y install gcc zlib zlib-devel pcre-devel openssl openssl-devel [root@localhost ~] wget https://nginx.org/download/nginx-1.21.3.tar.gz \u0026amp;\u0026amp; tar -zxf nginx-1.21.3.tar.gz \u0026amp;\u0026amp; cd nginx-1.21.3/ [root@localhost ~] ./configure \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install [root@localhost ~] /usr/local/nginx/sbin/nginx # 配置index.html文件 [root@localhost ~] cat /usr/local/nginx/html/index.html 192.168.199.11 # 修改arp_ignore和arp_announce配置 # 注意！！！我的网卡是ens33，按自己实际网卡来操作，比如eth0目录下 [root@localhost ~] echo 1 \u0026gt; /proc/sys/net/ipv4/conf/ens33/arp_ignore [root@localhost ~] echo 2 \u0026gt; /proc/sys/net/ipv4/conf/ens33/arp_announce [root@localhost ~] echo 1 \u0026gt; /proc/sys/net/ipv4/conf/all/arp_ignore [root@localhost ~] echo 2 \u0026gt; /proc/sys/net/ipv4/conf/all/arp_announce # 环回接口配置VIP，实现对内可见对外隐藏 # 切记！！！ 切记！！！ 掩码是4个255 [root@localhost ~] ifconfig lo:2 192.168.199.101 netmask 255.255.255.255 WEB服务器2 操作同WEB服务器1\nLVS服务器 # 修改keepalived.conf文件 [root@localhost ~] cat /etc/keepalived/keepalived.conf ! Configuration File for keepalived global_defs { # ... 此处省略关于邮件的配置 router_id LVS_01 # 表示运行keepalived服务器的一个标识 } vrrp_instance VI_1 { state MASTER # 指定keepalived的角色，MASTER表示此主机是主服务器，BACKUP表示此主机是备用服务器 interface ens33 # 指定HA监测的网卡 根据自己实际网卡配置，例如eth0 virtual_router_id 51 # 虚拟路由标识，这个标识是一个数字，同一个vrrp实例使用唯一的标识。即同一vrrp_instance下，MASTER和BACKUP必须是一致的 priority 100 # 定义优先级，数字越大，优先级越高，在同一个vrrp_instance下，MASTER的优先级必须大于BACKUP的优先级 advert_int 1 # 设定MASTER与BACKUP负载均衡器之间同步检查的时间间隔，单位是秒 authentication { # 设置验证类型和密码 auth_type PASS # 设置验证类型，主要有PASS和AH两种 auth_pass 1111 # 设置验证密码，在同一个vrrp_instance下，MASTER与BACKUP必须使用相同的密码才能正常通信 } virtual_ipaddress { # 设置虚拟IP地址，可以设置多个虚拟IP地址，每行一个 192.168.199.101/24 dev ens33 label ens33:2 # 192.168.199.101为vip ens33同上 ens33:2接口 } } # 配置RS服务 virtual_server 192.168.199.101 80 { delay_loop 6 # 设置运行情况检查时间，单位是秒 lb_algo rr # 设置负载调度算法，这里设置为rr，即轮询算法 lb_kind DR # 设置LVS实现负载均衡的机制，有NAT、TUN、DR三个模式可选 persistence_timeout 50 # 会话保持时间，单位是秒。这个选项对动态网页是非常有用的，为集群系统中的session共享提供了一个很好的解决方案。 # 有了这个会话保持功能，用户的请求会被一直分发到某个服务节点，直到超过这个会话的保持时间。 # 需要注意的是，这个会话保持时间是最大无响应超时时间，也就是说，用户在操作动态页面时，如果50秒内没有执行任何操作 # 那么接下来的操作会被分发到另外的节点，但是如果用户一直在操作动态页面，则不受50秒的时间限制 protocol TCP # 指定转发协议类型，有TCP和UDP两种 # WEB服务器1 80端口 real_server 192.168.199.11 80 { weight 1 # 配置服务节点的权值，权值大小用数字表示，数字越大，权值越高，设置权值大小可以为不同性能的服务器 # 分配不同的负载，可以为性能高的服务器设置较高的权值，而为性能较低的服务器设置相对较低的权值，这样才能合理地利用和分配系统资源 HTTP_GET { url { path / status_code 200 } connect_timeout 3 # 表示3秒无响应超时 nb_get_retry 3 # 表示重试次数 delay_before_retry 3 # 表示重试间隔 } } # WEB服务器2 80端口 real_server 192.168.199.12 80 { weight 1 HTTP_GET { url { path / status_code 200 } connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } } } # 配置完成之后重启keepalived # centos7 [root@localhost ~] systemctl restart keepalived.service # ipvsadm 查看rs情况 # ipvsadm -lnc 会查看当前连接情况 [root@localhost ~] ipvsadm -ln IP Virtual Server version 1.2.1 (size=4096) Prot LocalAddress:Port Scheduler Flags -\u0026gt; RemoteAddress:Port Forward Weight ActiveConn InActConn TCP 192.168.199.101:80 rr -\u0026gt; 192.168.199.11:80 Route 1 0 0 -\u0026gt; 192.168.199.12:80 Route 1 0 0 访问VIP # 请求结果会轮着来 [root@localhost ~] curl -X GET http://192.168.199.101:80 192.168.199.11 [root@localhost ~] curl -X GET http://192.168.199.101:80 192.168.199.12 ","permalink":"https://www.iarno.cn/article/lvs-2/","tags":["lvs"],"title":"LVS + Keepalived实现集群高可用"},{"categories":["其他"],"contents":"这篇文章详细介绍了如何使用LVS进行负载均衡的实践操作。首先，文章列出了所需的服务器IP和角色，然后分别介绍了在LVS服务器和WEB服务器上的配置步骤。在LVS服务器上，主要是安装ipvsadm，配置VIP网卡和使用ipvsadm配置VIP。在WEB服务器上，主要是安装nginx服务，配置index.html文件，修改arp_ignore和arp_announce配置，以及环回接口配置VIP。最后，文章展示了如何在LVS服务器上添加rs，以及如何访问VIP。\n机器说明 192.168.199.10lvs服务器、192.168.199.11web服务器1、192.168.199.12web服务器2、192.168.199.100vip。\nIP 说明 192.168.199.10 LVS服务器 192.168.199.11 WEB服务器1 192.168.199.12 WEB服务器2 192.168.199.100 VIP(虚拟IP) LVS服务器 # 安装ipvsadm [root@localhost ~] yum install ipvsadm -y # 配置VIP网卡 # 注意！！！ 我的网卡是ens33，请根据自己的实际网卡来配置比如eth0网卡 [root@localhost ~] ifconfig ens33:8 192.168.199.100/24 # 使用ipvsadm配置VIP # -A 参数添加VIP # -t 参数tcp协议 # 192.168.199.100:80 VIP端口是80 # -s 参数负载算法，rr为轮询 [root@localhost ~] ipvsadm -A -t 192.168.199.100:80 -s rr WEB服务器1 # 安装nginx服务 [root@localhost ~] yum -y install gcc zlib zlib-devel pcre-devel openssl openssl-devel [root@localhost ~] wget https://nginx.org/download/nginx-1.21.3.tar.gz \u0026amp;\u0026amp; tar -zxf nginx-1.21.3.tar.gz \u0026amp;\u0026amp; cd nginx-1.21.3/ [root@localhost ~] ./configure \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install [root@localhost ~] /usr/local/nginx/sbin/nginx # 配置index.html文件 [root@localhost ~] cat /usr/local/nginx/html/index.html 192.168.199.11 # 修改arp_ignore和arp_announce配置 # 注意！！！我的网卡是ens33，按自己实际网卡来操作，比如eth0目录下 [root@localhost ~] echo 1 \u0026gt; /proc/sys/net/ipv4/conf/ens33/arp_ignore [root@localhost ~] echo 2 \u0026gt; /proc/sys/net/ipv4/conf/ens33/arp_announce [root@localhost ~] echo 1 \u0026gt; /proc/sys/net/ipv4/conf/all/arp_ignore [root@localhost ~] echo 2 \u0026gt; /proc/sys/net/ipv4/conf/all/arp_announce # 环回接口配置VIP，实现对内可见对外隐藏 # 切记！！！ 切记！！！ 掩码是4个255 [root@localhost ~] ifconfig lo:2 192.168.199.100 netmask 255.255.255.255 WEB服务器2 操作同WEB服务器1\nLVS服务器 # lvs添加rs # -a 参数添加rs # -t 参数tcp协议 # 192.168.199.100:80 如上第一配置的vip及端口 # -r rs服务器ip即WEB服务1或WEB服务器2对应的IP # -g 参数lvs模式，不填默认为DR模式 [root@localhost ~] ipvsadm -a -t 192.168.199.100:80 -r 192.168.199.11 -g [root@localhost ~] ipvsadm -a -t 192.168.199.100:80 -r 192.168.199.12 -g # ipvsadm 查看rs情况 # ipvsadm -lnc 会查看当前连接情况 [root@localhost ~] ipvsadm -ln IP Virtual Server version 1.2.1 (size=4096) Prot LocalAddress:Port Scheduler Flags -\u0026gt; RemoteAddress:Port Forward Weight ActiveConn InActConn TCP 192.168.199.100:80 rr -\u0026gt; 192.168.199.11:80 Route 1 0 0 -\u0026gt; 192.168.199.12:80 Route 1 0 0 访问VIP # 请求结果会轮着来 [root@localhost ~] curl -X GET http://192.168.199.100:80 192.168.199.11 [root@localhost ~] curl -X GET http://192.168.199.100:80 192.168.199.12 ","permalink":"https://www.iarno.cn/article/lvs-1/","tags":["lvs"],"title":"LVS负载均衡实践"},{"categories":["其他"],"contents":"这篇文章主要介绍了如何在Mac上安装VM虚拟机和Centos虚拟机，并进行网络配置。首先，从VMware官网下载并安装VMware Fusion。然后，从Centos官网下载Centos镜像，并在VMware Fusion中创建Centos虚拟机。最后，进行虚拟机网络配置，包括选择网络模式，查看WIFI项，配置虚拟机的ifcfg-ens33文件，设置GATEWAY和DNS，最后重启network服务。\n安装VMware Fusion Mac 安装VM虚拟机 、centos虚拟机创建、网络相关配置。\n官网地址 https://www.vmware.com/cn/products/fusion/fusion-evaluation.html\n下载Centos镜像 官网地址 https://www.centos.org/download/\n创建Centos虚拟机 将已下载好的centos镜像拖拽进来 保存完之后启动虚拟机即可！ 注: 默认会提示网络问题可以先忽略进入到虚拟机，具体网络配置如下。 Centos虚拟机网络配置 ！！！ 网络选择“与我的Mac共享”或“WI-FI” 配置虚拟机网络 系统偏好设置网络查看WIFI项 配置虚拟机ifcfg-ens33文件 GATEWAY 对应值为 系统偏好设置-网络-wifi-TCP/IP 中的路由器值 DNS 对应值为 系统偏好设置-网络-DNS 有几个配置就配置几个即可 配置完之后重启network /bin/systemctl restart network.service\n","permalink":"https://www.iarno.cn/article/mac-vm/","tags":["虚拟机"],"title":"Mac 安装VM虚拟机及网络配置"},{"categories":["其他"],"contents":"这篇文章主要介绍了如何使用Go语言开发自定义插件。首先，我们需要下载并安装go-pluginserver，然后在CentOS环境下安装C相关的编译环境。接着，我们可以下载官方的插件示例，并通过Go语言编写自己的插件。最后，我们需要配置相关的环境变量并启动Kong服务。文章还提供了Konga插件的示例图和相关参考链接。\n目录 下载安装 go-pluginserver Github: https://github.com/Kong/go-pluginserver\n下载安装go-pluginserver\ngit clone https://github.com/Kong/go-pluginserver.git cd go-pluginserver # 构建生成 go-pluginserver 二进制文件 go build 安装c相关编译环境 Contos\nyum install make automake gcc gcc-c++ kernel-devel 下载官方插件示例 Github: https://github.com/Kong/go-plugins.git\n# git clone https://github.com/Kong/go-plugins.git cd go-plugins go build -buildmode=plugin go-hello.go Demo package main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/Kong/go-pdk\u0026#34; ) // Config konga 界面相关字段 // 注：如果修改Config字段需重启kong服务才可生效 type Config struct { Message string } func New() interface{} { return \u0026amp;Config{} } // Access 阶段 func (conf Config) Access(kong *pdk.PDK) { // 获取请求header中的host信息 host, err := kong.Request.GetHeader(\u0026#34;host\u0026#34;) if err != nil { // 记录err日志 kong.Log.Err(err.Error()) } // 获取插件配置信息message message := conf.Message if message == \u0026#34;\u0026#34; { message = \u0026#34;hello\u0026#34; } // 设置header头 kong.Response.SetHeader(\u0026#34;x-hello-from-go\u0026#34;, fmt.Sprintf(\u0026#34;Go says %s to %s\u0026#34;, message, host)) } kong服务启动 配置相关环境变量\nKONG_PLUGINS=bundled,go-hello （go-hello 插件名称）\nKONG_GO_PLUGINS_DIR=/home/kong/go-plugins （ .so 文件目录）\nKONG_GO_PLUGINSERVER_EXE=/home/kong/go-plugins/go-pluginserver （go-pluginserver 文件目录）\nsudo docker run -d --name kong-2.2.1 \\ -e \u0026#34;KONG_DATABASE=cassandra\u0026#34; \\ -e \u0026#34;KONG_CASSANDRA_KEYSPACE=internal_gateway_dev\u0026#34; \\ -e \u0026#34;KONG_CASSANDRA_USERNAME=internal_gateway_dev\u0026#34; \\ -e \u0026#34;KONG_CASSANDRA_PASSWORD=xxxx\u0026#34; \\ -e \u0026#34;KONG_CASSANDRA_CONTACT_POINTS=xxxx\u0026#34; \\ -e \u0026#34;KONG_CASSANDRA_TIMEOUT=30000\u0026#34; \\ -e \u0026#34;KONG_PROXY_ACCESS_LOG=/dev/stdout\u0026#34; \\ -e \u0026#34;KONG_ADMIN_ACCESS_LOG=/dev/stdout\u0026#34; \\ -e \u0026#34;KONG_PROXY_ERROR_LOG=/dev/stderr\u0026#34; \\ -e \u0026#34;KONG_ADMIN_ERROR_LOG=/dev/stderr\u0026#34; \\ -e \u0026#34;KONG_ADMIN_LISTEN=0.0.0.0:8001, 0.0.0.0:8444 ssl\u0026#34; \\ -e \u0026#34;KONG_PLUGINS=bundled,go-hello\u0026#34; \\ -e \u0026#34;KONG_GO_PLUGINS_DIR=/home/kong/go-plugins\u0026#34; \\ -e \u0026#34;KONG_GO_PLUGINSERVER_EXE=/home/kong/go-plugins/go-pluginserver\u0026#34; \\ -p 8000:8000 \\ -p 8443:8443 \\ -p 0.0.0.0:8001:8001 \\ -p 127.0.0.1:8444:8444 \\ -v /home/xx/devspace/go-plugins:/home/kong/go-plugins \\ # 本地挂载目录 kong:2.2.1-centos konga 插件示例图 参考 https://www.yuque.com/baxiang/ms/ggqrk7\n","permalink":"https://www.iarno.cn/article/plugin-dev4/","tags":["网关"],"title":"Kong - 自定义插件开发(四)"},{"categories":["其他"],"contents":"这篇文章介绍了如何使用Docker启动Kong并加载自定义插件。详细介绍了Docker启动命令中的环境变量和挂载路径的配置。特别注意，如果出现ntt-auth plugin is in use but not enabled错误，需要检查插件路径和KONG_PLUGINS环境变量。\n使用自定义插件，Docker容器启动相关配置如下：\nDocker 启动 sudo docker run -d --name kong-2.2.1 \\ -e \u0026#34;KONG_DATABASE=cassandra\u0026#34; \\ -e \u0026#34;KONG_CASSANDRA_KEYSPACE=xxxxxx\u0026#34; \\ -e \u0026#34;KONG_CASSANDRA_USERNAME=xxxxx\u0026#34; \\ -e \u0026#34;KONG_CASSANDRA_PASSWORD=xxxxxxx\u0026#34; \\ -e \u0026#34;KONG_CASSANDRA_CONTACT_POINTS=x.x.x.x\u0026#34; \\ -e \u0026#34;KONG_CASSANDRA_TIMEOUT=30000\u0026#34; \\ -e \u0026#34;KONG_PROXY_ACCESS_LOG=/dev/stdout\u0026#34; \\ -e \u0026#34;KONG_ADMIN_ACCESS_LOG=/dev/stdout\u0026#34; \\ -e \u0026#34;KONG_PROXY_ERROR_LOG=/dev/stderr\u0026#34; \\ -e \u0026#34;KONG_ADMIN_ERROR_LOG=/dev/stderr\u0026#34; \\ -e \u0026#34;KONG_ADMIN_LISTEN=0.0.0.0:8001, 0.0.0.0:8444 ssl\u0026#34; \\ -e \u0026#34;KONG_PLUGINS=bundled,ntt-auth\u0026#34; \\ -e \u0026#34;KONG_LUA_PACKAGE_PATH=/home/?.lua;;\u0026#34; \\ -p 8000:8000 \\ -p 8443:8443 \\ -p 0.0.0.0:8001:8001 \\ -p 127.0.0.1:8444:8444 \\ -v /home/devspace/kong-plugin:/home/kong/plugins/ntt-auth/ \\ -v /etc/localtime:/etc/localtime:ro \\ kong:2.2.1-centos 注意以下相关配置: -e \u0026quot;KONG_PLUGINS=bundled,ntt-auth\u0026quot; # ntt-auth 自定插件名称\n-e \u0026quot;KONG_LUA_PACKAGE_PATH=/home/?.lua;;\u0026quot; # 默认会加上/kong/plugins/ntt-auth/ 路径\n-v /home/devspace/kong-plugin:/home/kong/plugins/ntt-auth/ # 插件挂载路径\n问题 如果出现 ntt-auth plugin is in use but not enabled 错误，请查看插件路径或KONG_PLUGINS环境变量。\n","permalink":"https://www.iarno.cn/article/plugin-dev3/","tags":["网关"],"title":"Kong - 自定义插件开发(三)"},{"categories":["其他"],"contents":"这篇文章主要介绍了如何在Kong中开发自定义插件。首先，它解释了Kong插件的生命周期，并展示了如何在Lua中实现base_plugin.lua接口的方法。然后，文章提供了一个NttAuthHandler插件的示例，包括access、init_worker和log阶段的实现。接着，文章介绍了如何定义插件的schema。最后，文章讨论了在Docker容器部署中如何使用lua_shared_dict共享内存，并提供了Kong Nginx模板的相关配置。\n生命周期 Kong 插件允许您在请求/响应或 tcp 流连接的生命周期的多个入口点注入自定义逻辑（在 Lua 中），因为它由 Kong 代理。为此，必须实现base_plugin.lua接口的一种或几种方法。这些方法将在以下命名空间的模块中实现： kong.plugins.\u0026lt;plugin_name\u0026gt;.handler\nhandel.lua local NttAuthHandler = { PRIORITY = 1001, VERSION = \u0026#34;1.0.0\u0026#34;, } -- access 阶段 function NttAuthHandler:access(conf) -- 自定义插件逻辑具体逻辑 -- 验证 local ok, err = nttAuth(conf) if not ok then return kong.response.error(err.status, err.message, {[\u0026#34;Content-Type\u0026#34;] = \u0026#34;application/json\u0026#34;}) end end -- init_worker 阶段 function NttAuthHandler:init_worker(conf) ... end -- log 阶段 function NttAuthHandler:log(conf) ... end return NttAuthHandler schema.lua local typedefs = require \u0026#34;kong.db.schema.typedefs\u0026#34; local schema = { name = \u0026#34;ntt-auth\u0026#34;, fields = { { consumer = typedefs.no_consumer }, { protocols = typedefs.protocols_http }, { config = { type = \u0026#34;record\u0026#34;, fields = { { auth_service = { type = \u0026#34;string\u0026#34; }, }, { appid_in_header = { type = \u0026#34;boolean\u0026#34;, required = true, default = false }, }, }, }, }, }, } return schema 其他 如果Docker容器部署需要使用到lua_shared_dict共享内存，Docker容器中Kong Nginx模板相关配置如下:\n# kong nginx配置模板 vi /usr/local/share/lua/5.1/kong/templates/nginx_kong.lua lua_shared_dict kong_db_cache_miss 12m; lua_shared_dict ntt_auth ${{MEM_CACHE_SIZE}}; // 放在 if database == \u0026#34;off\u0026#34; 前面 参考 https://docs.konghq.com/gateway-oss/2.2.x/plugin-development/custom-logic/\nhttps://docs.konghq.com/gateway-oss/2.2.x/plugin-development/plugin-configuration/\n","permalink":"https://www.iarno.cn/article/plugin-dev2/","tags":["网关"],"title":"Kong - 自定义插件开发(二)"},{"categories":["其他"],"contents":"这篇文章主要介绍了如何开发Kong自定义插件。首先，将插件视为一组Lua模块，Kong会检测并加载遵循特定命名约定的插件模块。插件由两个强制性模块组成：handler.lua和schema.lua。一些插件可能需要更深入地集成到Kong中，例如在数据库中有自己的表，或在Admin API中公开端点等，这些都可以通过向插件添加新模块来完成。\n介绍 将您的插件视为一组Lua 模块。本章中描述的每个文件都被视为一个单独的模块。如果它们的名称遵循以下约定，Kong 将检测并加载您的插件模块：\nkong.plugins.\u0026lt;plugin_name\u0026gt;.\u0026lt;module_name\u0026gt; 你的模块当然需要通过你的package.path 变量访问 ，它可以通过lua_package_path 配置属性调整到你的需要 。然而，安装插件的首选方式是通过 LuaRocks，Kong 与它本地集成。\n为了让 Kong 意识到它必须寻找你插件的模块，你必须将它添加到配置文件中的 plugins属性中，这是一个逗号分隔的列表。例如：\nplugins = bundled,my-custom-plugin # your plugin name here 或者，如果您不想加载任何捆绑的插件：\nplugins = my-custom-plugin # your plugin name here 现在，Kong 将尝试从以下命名空间加载几个 Lua 模块：\nkong.plugins.my-custom-plugin.\u0026lt;module_name\u0026gt; 其中一些模块是强制性的（例如handler.lua），一些是可选的，并且允许插件实现一些额外的功能（例如api.lua扩展管理 API 端点）。\n现在让我们准确描述您可以实现的模块是什么以及它们的目的是什么。\n基本插件模块 在最纯粹的形式中，插件由两个强制性模块组成：\nsimple-plugin ├── handler.lua └── schema.lua handler.lua：插件的核心。它是一个要实现的接口，其中每个函数都将在请求/连接的生命周期中的所需时刻运行。 schema.lua：您的插件可能必须保留用户输入的一些配置。该模块保存该配置的架构并在其上定义规则，以便用户只能输入有效的配置值。 高级插件模块 一些插件可能需要与 Kong 更深入地集成：在数据库中有自己的表，在 Admin API 中公开端点等。每一个都可以通过向插件添加一个新模块来完成。如果插件实现了所有可选模块，那么它的结构如下所示：\ncomplete-plugin ├── api.lua ├── daos.lua ├── handler.lua ├── migrations │ ├── init.lua │ └── 000_base_complete_plugin.lua └── schema.lua 这是可能要实现的模块的完整列表以及它们的用途的简要说明。本指南将详细介绍，让您掌握其中的每一个。\n模块名称 必需的 描述 api.lua 不 定义可在 Admin API 中使用的端点列表，以与插件处理的自定义实体进行交互。 daos.lua 不 定义一个 DAO（数据库访问对象）列表，它们是插件所需的自定义实体的抽象，并存储在数据存储中。 handler.lua 是的 要实现的接口。每个函数都将由 Kong 在请求/连接的生命周期中的所需时刻运行。 migrations/*.lua 不 数据库迁移（例如创建表）。仅当您的插件必须将自定义实体存储在数据库中并通过daos.lua定义的 DAO 之一与它们交互时，才需要迁移。 schema.lua 是的 保存插件配置的架构，以便用户只能输入有效的配置值。 该密钥的验证插件与此文件结构插件的例子。有关更多详细信息，请参阅其源代码。\n参考 https://docs.konghq.com/gateway-oss/2.2.x/plugin-development/file-structure/\n","permalink":"https://www.iarno.cn/article/plugin-dev1/","tags":["网关"],"title":"Kong - 自定义插件开发(一)"},{"categories":["Lua"],"contents":"本文主要介绍了四种限流算法：固定窗口计数器算法、滑动窗口计数算法、漏桶算法、令牌桶算法，并通过Lua脚本和Redis实现了令牌桶算法。文章详细解释了如何使用Redis的SCRIPT LOAD和EVALSHA命令来执行限流逻辑，并通过返回值判断是否触发限流行为。最后，文章对四种算法进行了比较和总结，认为令牌桶算法是一种相对完美的限流算法，适用于大多数限流场景。\n一、限流简介 什么是限流 在不同场景下限流的定义也各不相同，可以是每秒请求数、每秒事务处理数、网络流量。\n通常我们所说的限流指的是限制到达系统并发请求数，使得系统能够正常的处理部分用户的请求，来保证系统的稳定性。\n为什么限流 接口无法控制调用方的行为。热点业务突发请求、恶意请求攻击等会带来瞬时的请求量激增，导致服务占用大量的 CPU、内存等资源，使得其他正常的请求变慢或超时，甚至引起服务器宕机。\n按照请求次数进行收费的接口需要根据客户支付的金额来限制客户可用的次数。\n限流的行为 限流的行为指的就是在接口的请求数达到限流的条件时要触发的操作，一般可进行以下行为。\n拒绝服务：把多出来的请求拒绝掉 服务降级：关闭或是把后端服务做降级处理。这样可以让服务有足够的资源来处理更多的请求 特权请求：资源不够了，我只能把有限的资源分给重要的用户 延时处理：一般会有一个队列来缓冲大量的请求，这个队列如果满了，那么就只能拒绝用户了，如果这个队列中的任务超时了，也要返回系统繁忙的错误了 弹性伸缩：用自动化运维的方式对相应的服务做自动化的伸缩 二、限流架构 单点限流 当我们的系统应用只部署在一个节点上来提供服务时，就可以采用单点限流的架构来对应用的接口进行限流，只要单点应用进行了限流，那么他所依赖的各种服务也得到了保护。\n分布式限流 为了提供高性能的服务，往往我们的应用都是以集群结构部署在多个节点上的。这时候单点限流只能限制传入单个节点的请求，保护自身节点，无法保护应用依赖的各种服务资源。那么如果在集群中的每个节点上都进行单点限流是否可行呢？\n假设我们的应用集群中有三个节点，为了保护应用依赖的资源我们限制资源每秒最大请求数为300个，如果超过这个限制那么资源将因过载导致不再可用。这样分配到集群中的每个应用节点的每秒最大请求数为100个才可以满足保护资源的要求，超过100则拒绝服务提示业务繁忙。\n假如某一秒内有300个请求打到应用集群，应用集群再去请求所依赖的资源服务，是满足资源服务每秒300个最大请求数的限制的，所以这些请求都能够得到处理并且正常返回。\n但是，如果因为种种原因负载均衡调度器把这 300 个请求中的 50 个分配给了节点1，50 个分配给了节点2，剩余 200 个分配给了节点3。因为我们之前限制每个节点的每秒最大请求数为 100，所以就会出现节点1的50个请求全部正常返回、节点2上的 50 个请求全部正常返回，而节点三上的200个请求只有100个正常返回，另外100个被拒绝服务。这种集群中每个节点都进行单点限流的方式显然不能满足我们的业务需要。\n我们可以使用基于各种中间件的分布式限流来解决集群结构下应用限流不准确的问题。将限流的配置以及通过整个集群的请求数都保存在中间件中，然后通过计算来判断是否达到限流行为的触发条件。分布式限流可以统一地限制整个集群的流量，整个集群的请求数得到了限制，那么集群所依赖的资源服务也就得到了保障。\n三、限流算法 固定窗口计数器 将时间按照设定的周期划分为多个窗口 在当前时间窗口内每来一次请求就将计数器加一 如果计数器超过了限制数量，则拒绝服务 当时间到达下一个窗口时，计数器的值重置 这种算法很好实现，但是会出现限流不准确的问题，例如：\n假设限制每秒通过5个请求，时间窗口的大小为1秒，当前时间窗口周期内的后半秒正常通过了5个请求，下一个时间窗口周期内的前半秒正常通过了5个请求，在这两个窗口内都没有超过限制。但是在这两个窗口的中间那一秒实际上通过了 10 个请求，显然不满足每秒5个请求的限制。\n滑动窗口计数器 将设定的时间周期设为滑动窗口的大小，记录每次请求的时刻 当有新的请求到来时将窗口滑到该请求来临的时刻 判断窗口内的请求数是否超过了限制，超过限制则拒绝服务，否则请求通过 丢弃滑动窗口以外的请求 这种算法解决了固定窗口计数器出现的通过请求数是限制数两倍的缺陷，但是实现起来较为复杂，并且需要记录窗口周期内的请求，如果限流阈值设置过大，窗口周期内记录的请求就会很多，就会比较占用内存\n漏桶算法 将进来的请求流量视为水滴先放入桶内 水从桶的底部以固定的速率匀速流出，相当于在匀速处理请求 当漏桶内的水满时(超过了限流阈值)则拒绝服务 这个算法可以比较平滑均匀的限制请求，Nginx 中的 limit_req 模块的底层实现就是用的这种算法，具体可参考【NGINX和NGINX Plus的速率限制】(https://www.nginx.com/blog/rate-limiting-nginx)\n但是漏桶算法也有一定的缺陷，因为水从桶的底部以固定的速率匀速流出，当有在服务器可承受范围内的瞬时突发请求进来，这些请求会被先放入桶内，然后再匀速的进行处理，这样就会造成部分请求的延迟。所以他无法应对在限流阈值范围内的突发请求。\n令牌桶算法 按照一定的速率生产令牌并放入令牌桶中 如果桶中令牌已满，则丢弃令牌 请求过来时先到桶中拿令牌，拿到令牌则放行通过，否则拒绝请求 这种算法能够把请求均匀的分配在时间区间内，又能接受服务可承受范围内的突发请求。所以令牌桶算法在业内使用也非常广泛。接下来会详细介绍该算法的实现。\n四、令牌桶算法实现 我们采用 Redis + Lua 脚本的方式来实现令牌桶算法，在 Redis 中使用 Lua 脚本有诸多好处，例如：\n减少网络开销：本来多次网络请求的操作，可以用一个请求完成，原先多次请求的逻辑放在 Redis 服务器上完成。使用脚本，减少了网络往返时延。 原子操作：Redis会将整个脚本作为一个整体执行，中间不会被其他进程或者进程的命令插入。 复用：客户端发送的脚本会永久存储在Redis中，意味着其他客户端可以复用这一脚本而不需要使用代码完成同样的逻辑。 复用：客户端发送的脚本会永久存储在Redis中，意味着其他客户端可以复用这一脚本而不需要使用代码完成同样的逻辑。 这其中最重要的方法就是原子操作。将 Redis 的多条命令写成一个 Lua 脚本，然后调用脚本执行操作，相当于只有一条执行脚本的命令，所以整个 Lua 脚本中的操作都是原子性的。\n在 Redis 中使用 Lua 脚本主要涉及 Script Load、Eval、Evalsha 三个命令：\nEval ${lua_script} 可以直接执行 Lua 脚本。\nScript Load ${lua_script} 命令是将脚本载入 Redis，载入成功后会返回一个脚本的sha1值，一旦载入则永久存储在 Redis 中，后续可以通过 Evalsha ${sha1} 来直接调用此脚本。我们采用先 Load 脚本得到 Sha1 值，再调用这个 sha1 值来执行脚本的方式可以减少像eval ${lua_script} 命令这样每次都向 Redis 中发送一长串 Lua 脚本带来的网络开销。\n使用 Redis 中的 Hash 数据结构来存储限流配置，每个 Hash 表的 Key 为限流的粒度，可以是接口Uri、客户端 IP、应用uuid或者他们的组合形式。每个 Hash 表为一个令牌桶，Hash 表中包含如下字段：\nlast_time 最近一次请求的时间戳，毫秒级别。 curr_permits 当前桶内剩余令牌数量，单位为：个。 bucket_cap 桶的容量，即桶内可容纳最大令牌数量，代表限流时间周期内允许通过的最大请求数。 period 限流的时间周期，单位为：秒。 rate 令牌产生的速率，单位：个/秒，rate = bucket_cap / period 在上面的令牌桶算法描述中生产令牌的方式是按照一定的速率生产令牌并放入令牌桶中，这种方式需要一个线程不停地按照一定的速率生产令牌并更新相应的桶，如果被限流的接口(每个桶)令牌生产的速率都不一样，那么就需要开多个线程，很浪费资源。\n为了提高系统的性能，减少限流层的资源消耗，我们将令牌的生产方式改为：每次请求进来时一次性生产上一次请求到本次请求这一段时间内的令牌。随意每次请求生成的令牌数就是 (curr_time -last_time) / 1000 * rate，注意：这里两次时间戳的差值单位是毫秒，而令牌产生速率的单位是 个/秒，所以要除以 1000，把时间戳的差值的单位也换算成秒。\n令牌桶算法的实现逻辑为： 假如我们的限流策略是一分钟内最多能通过100个请求，那么相应的令牌产生速率为 600 / 60 = 10 (个/秒)。那么当限流策略刚刚配置好这一时刻就有突发的10个请求进来，此时令牌桶内还没来的及生产令牌，所以请求拿不到令牌就会被拒绝，这显然不符合我们要求。\n为了解决这一问题，我们在限流策略刚刚配置好后的第一个请求来临时将当前可用令牌的值设置为桶的最大容量 100，将最近一次请求时间设置为本次请求来临时一分钟后的时间戳，减去出本次请求需要的令牌后更新桶。这样，在这一分钟以内，有下一次请求进来时，从 Hash 表内取出配置计算当前时间就会小于最近一次请求的时间，随后计算生成的令牌就会是一个小于0的负数。所以在更新桶这一步，要根据生成的令牌是否为负数来决定是否更新最后一次请求时间的值。\n用 Lua 脚本实现上述逻辑： local key = KEYS[1] -- 要进行限流的Key，可以是 uri local consume_permits = tonumber(ARGV[1]) -- 请求消耗的令牌数，每个请求消耗一个 local curr_time = tonumber(ARGV[2]) -- 当前时间 local limiter_info = redis.pcall(\u0026#34;HMGET\u0026#34;, key, \u0026#34;last_time\u0026#34;, \u0026#34;curr_permits\u0026#34;, \u0026#34;bucket_cap\u0026#34;, \u0026#34;rate\u0026#34;, \u0026#34;period\u0026#34;) if not limiter_info[3] then return -1 end local last_time = tonumber(limiter_info[1]) or 0 local curr_permits = tonumber(limiter_info[2]) or 0 local bucket_cap = tonumber(limiter_info[3]) or 0 local rate = tonumber(limiter_info[4]) or 0 local period = tonumber(limiter_info[5]) or 0 local total_permits = bucket_cap local is_update_time = true if last_time \u0026gt; 0 then local new_permits = math.floor((curr_time-last_time)/1000 * rate) if new_permits \u0026lt;= 0 then new_permits = 0 is_update_time = false end total_permits = new_permits + curr_permits if total_permits \u0026gt; bucket_cap then total_permits = bucket_cap end else last_time = curr_time + period * 1000 end local res = 1 if total_permits \u0026gt;= consume_permits then total_permits = total_permits - consume_permits else res = 0 end if is_update_time then redis.pcall(\u0026#34;HMSET\u0026#34;, key, \u0026#34;curr_permits\u0026#34;, total_permits, \u0026#34;last_time\u0026#34;, curr_time) else redis.pcall(\u0026#34;HSET\u0026#34;, key, \u0026#34;curr_permits\u0026#34;, total_permits) end return res 上述脚本在调用时接收三个参数，分别为：限流的key、请求消耗的令牌数、 当前时间戳(毫秒级别)。\n在我们的业务代码中，先调用 Redis 的 SCRIPT LOAD 命令将上述脚本 Load 到 Redis 中并将该命令返回的脚本 sha1 值保存。\n在后续的请求进来时，调用 Redis 的 EVALSHA 命令执行限流逻辑，根据返回值判断是否对本次请求触发限流行为。假如限流的 key 为每次请求的 uri，每次请求消耗 1 个令牌，那么执行 Evalsha 命令进行限流判断的具体操作为：EVALSHA ${sha1} 1 ${uri} 1 ${当前时间戳} （第一个数字 1 代表脚本可接收的参数中有 1 个Key，第二个数字 1 代表本次请求消耗一个令牌）；执行完这条命令后如果返回值是 1 代表桶中令牌够用，请求通过；如果返回值为 0 代表桶中令牌不够，触发限流；如果返回值为 -1 代表本次请求的 uri 未配置限流策略，可根据自己的实际业务场景判断是通过还是拒绝。\nRedis相关操作 # 通过 SCRIPT LOAD 生成的 sha1 校验码 root@e2ea48309e5f:/home/lua/rate-limiting# redis-cli SCRIPT LOAD \u0026#34;$(cat /home/lua/rate-limiting/demo.lua)\u0026#34; \u0026#34;f1acffb11bcfea38c1acf25ce4135f7b95233807\u0026#34; # 执行命令 参数解释：1个key 缓存key为test 每次1个令牌 当前时间 root@e2ea48309e5f:/home/lua/rate-limiting# redis-cli 127.0.0.1:6379\u0026gt; EVALSHA \u0026#34;f1acffb11bcfea38c1acf25ce4135f7b95233807\u0026#34; 1 test 1 1619017529 (integer) 1 127.0.0.1:6379\u0026gt; EVALSHA \u0026#34;f1acffb11bcfea38c1acf25ce4135f7b95233807\u0026#34; 1 test 1 1619017529 (integer) 1 127.0.0.1:6379\u0026gt; EVALSHA \u0026#34;f1acffb11bcfea38c1acf25ce4135f7b95233807\u0026#34; 1 test 1 1619017529 (integer) 1 127.0.0.1:6379\u0026gt; EVALSHA \u0026#34;f1acffb11bcfea38c1acf25ce4135f7b95233807\u0026#34; 1 test 1 1619017529 (integer) 0 127.0.0.1:6379\u0026gt; EVALSHA \u0026#34;f1acffb11bcfea38c1acf25ce4135f7b95233807\u0026#34; 1 test 1 1619017529 (integer) 0 五、总结 本文主要介绍了四种限流的算法，分别为：固定窗口计数器算法、滑动窗口计数算法、漏桶算法、令牌桶算法。\n固定窗口计数算法简单易实现，其缺陷是可能在中间的某一秒内通过的请求数是限流阈值的两倍，该算法仅适用于对限流准确度要求不高的应用场景。 滑动窗口计数算法解决了固定窗口计数算法的缺陷，但是该算法较难实现，因为要记录每次请求所以可能出现比较占用内存比较多的情况。 漏桶算法可以做到均匀平滑的限制请求，Ngixn 热 limit_req 模块也是采用此种算法。因为匀速处理请求的缘故所以该算法应对限流阈值内的突发请求无法及时处理。 令牌桶算法解决了以上三个算法的所有缺陷，是一种相对比较完美的限流算法，也是限流场景中应用最为广泛的算法。使用 Redis + Lua脚本的方式可以简单的实现。 转自 http://s.iarno.cn/akFmqR\n","permalink":"https://www.iarno.cn/article/rate-limiting/","tags":["限流"],"title":"限流算法实践"},{"categories":["Lua"],"contents":"本文介绍了在ngx_lua模块中如何使用lua_shared_dict命令定义共享内存字典项对象，并通过ngx.shared.DICT接口获取这些对象。文章详细解释了相关语法和示例，包括如何设置和获取共享内存上的值。同时，还讨论了在Nginx重启和退出时，共享内存字典项的行为。\nlua_shared_dict 在ngx_lua模块中使用共享内存字典项相关API的前提条件是已经使用lua_shared_dict命令定义了一个字典项对象，该命令的具体用法为：\n语法： lua_shared_dict \u0026lt;name\u0026gt; \u0026lt;size\u0026gt;\n该命令主要是定义一块名为name的共享内存空间，内存大小为size。通过该命令定义的共享内存对象对于Nginx中所有worker进程都是可见的，当Nginx通过reload命令重启时，共享内存字典项会从新获取它的内容，当时当Nginx退出时，字典项的值将会丢失。\n示例： http { lua_shared_dict dogs 10m; server { location /set { content_by_lua \u0026#39; local dogs = ngx.shared.dogs dogs:set(\u0026#34;Jim\u0026#34;, 8) ngx.say(\u0026#34;STORED\u0026#34;) \u0026#39;; } location /get { content_by_lua \u0026#39; local dogs = ngx.shared.dogs ngx.say(dogs:get(\u0026#34;Jim\u0026#34;)) \u0026#39;; } } } 输出结果是：\n$ curl localhost/set STORED $ curl localhost/get 8 $ curl localhost/get 8 ngx.shared.DICT 可以通过ngx.shared.DICT接口获取共享内存字典项对象：\n语法： dict = ngx.shared.DICT\n示例： dict = ngx.shared[name_var] 其中，DICT和name_var表示的名称是一致的，比如上面例子中，dogs =ngx.shared.dogs 就是dict = ngx.shared.DICT的表达形式，也可以通过下面的方式达到同样的目的：\ndogs = ngx.shared[\u0026quot;dogs\u0026quot;]\n通过上面的API获取得到的共享内存字典项对象，具有如下相应的接口：\nngx.shared.DICT.get\n语法： value, flags = ngx.shared.DICT:get(key)\n获取共享内存上key对应的值。如果key不存在，或者key已经过期，将会返回nil；如果出现错误，那么将会返回nil以及错误信息。\nlocal cats = ngx.shared.cats local value, flags = cats.get(cats, \u0026#34;Marry\u0026#34;) 等价于\nlocal cats = ngx.shared.cats local value, flags = cats:get(\u0026#34;Marry\u0026#34;) 返回列表中的flags，是在ngx.shared.DICT.set方法中设置的值，默认值为0. 如果设置的flags为0，那么在这里flags的值将不会被返回。\n","permalink":"https://www.iarno.cn/article/lua-shared-dict/","tags":["lua_shared_dict"],"title":"ngx_lua模块中使用lua_shared_dict共享内存变量"},{"categories":["Lua"],"contents":"这篇文章主要介绍了如何在OpenResty中配置和使用定时任务。首先，文章解释了定时任务需要与worker绑定，通常默认绑定到worker_id=0，这样在Nginx进程中只执行一个timer。然后，文章提供了在nginx.conf中配置定时任务的具体方法。接着，文章介绍了如何使用ngx.timer.every接口，这是ngx提供的最新接口。最后，文章提供了一些相关的日志输出和错误处理方法。\nopenresty的定时任务是要跟worker绑定的。如果不绑定特定的worker，那么所有启动的woker都会去执行定时任务。\n一般情况下默认绑定worker_id=0的，这样在nginx整个进程里面，就只执行一个timer。\n在conf中具体的位置可以写自己的任务逻辑。\n具体的nginx.conf配置如下：\nworker_processes 1; error_log logs/error.log; events { worker_connections 1024; } http { init_worker_by_lua_block { local delay = 2 -- in seconds local new_timer = ngx.timer.at local log = ngx.log local ERR = ngx.ERR local check check = function(premature) if not premature then -- do the health check or other routine work log(ERR, \u0026#34;mm test mm test\u0026#34;) local ok, err = new_timer(delay, check) if not ok then log(ERR, \u0026#34;failed to create timer: \u0026#34;, err) return end end end if 0 == ngx.worker.id() then local ok, err = new_timer(delay, check) if not ok then log(ERR, \u0026#34;failed to create timer: \u0026#34;, err) return end end } server { listen 8081; location / { default_type text/html; content_by_lua \u0026#39; ngx.say(\u0026#34;\u0026lt;p\u0026gt;hello, world\u0026lt;/p\u0026gt;\u0026#34;) \u0026#39;; } location = /app/test { content_by_lua_block { local res = ngx.location.capture( \u0026#34;/sum\u0026#34;, {args={a=3, b=8}} ) ngx.say(\u0026#34;status:\u0026#34;, res.status, \u0026#34; response:\u0026#34;, res.body) } } location = /sum { internal; content_by_lua_block { ngx.sleep(0.1) local args = ngx.req.get_uri_args() ngx.print(tonumber(args.a) + tonumber(args.b)) } } location = /subduction { internal; content_by_lua_block { ngx.sleep(0.1) local args = ngx.req.get_uri_args() ngx.print(tonumber(args.a) - tonumber(args.b)) } } location = /app/test_parallels { content_by_lua_block { local start_time = ngx.now() local res1, res2 = ngx.location.capture_multi( { {\u0026#34;/sum\u0026#34;, {args={a=3, b=8}}}, {\u0026#34;/subduction\u0026#34;, {args={a=3, b=8}}} }) ngx.say(\u0026#34;status:\u0026#34;, res1.status, \u0026#34; response:\u0026#34;, res1.body) ngx.say(\u0026#34;status:\u0026#34;, res2.status, \u0026#34; response:\u0026#34;, res2.body) ngx.say(\u0026#34;time used:\u0026#34;, ngx.now() - start_time) } } location = /app/test_queue { content_by_lua_block { local start_time = ngx.now() local res1 = ngx.location.capture_multi( { {\u0026#34;/sum\u0026#34;, {args={a=3, b=8}}} }) local res2 = ngx.location.capture_multi( { {\u0026#34;/subduction\u0026#34;, {args={a=3, b=8}}} }) ngx.say(\u0026#34;status:\u0026#34;, res1.status, \u0026#34; response:\u0026#34;, res1.body) ngx.say(\u0026#34;status:\u0026#34;, res2.status, \u0026#34; response:\u0026#34;, res2.body) ngx.say(\u0026#34;time used:\u0026#34;, ngx.now() - start_time) } } } } 注意init_worker_by_lua_block是放在http里面的。因为此处只配置了error.log，因此是打印的err级别的日志，方便观察。\n接下来启动ngin：sudo nginx -p pwd/ -c conf/nginx.conf\n然后tailf logs/error.log:\n追日志会发现，每隔2s就会打印一条日志。\n二、使用ngx.timer.every接口 ngx提供了最新的ngx.timer.every接口，再来试一下：\ninit_worker_by_lua_block { local delay = 2 -- in seconds -- local new_timer = ngx.timer.at local log = ngx.log local ERR = ngx.ERR local check check = function(premature) if not premature then -- do the health check or other routine work log(ERR, \u0026#34;mm test mm test\u0026#34;) -- local ok, err = new_timer(delay, check) -- if not ok then -- log(ERR, \u0026#34;failed to create timer: \u0026#34;, err) -- return -- end end end if 0 == ngx.worker.id() then local ok, err = ngx.timer.every(delay, check) if not ok then log(ERR, \u0026#34;failed to create timer: \u0026#34;, err) return end end } 转自 https://www.cnblogs.com/sonofelice/p/8259712.html\n","permalink":"https://www.iarno.cn/article/lua-timer/","tags":["timer"],"title":"openresty 跑定时任务配置、ngx.timer.every接口使用"},{"categories":["其他"],"contents":"这篇文章主要解决了\u0026quot;too many open files\u0026quot;问题的定位。首先，它列出了可能的问题原因，包括系统资源限制小，数据库打开文件限制小，以及程序代码问题。然后，文章详细介绍了如何使用ulimit命令查看和调整资源限制，特别是打开文件数的限制。最后，文章介绍了如何使用lsof命令查看打开文件数，包括查看某个进程打开文件数和查看当前系统打开文件数。\n错误 socket：too many open files\n问题原因 系统资源限制小（ulimit -a 查看open files限制） 数据库打开文件限制小（登录数据库 show variables like '%open%';命令查看 open_files_limit 限制） 程序代码问题，进程打开文件句柄不释放。 ulimit命令查看资源限制 显示目前资源限制的设定\n示例 [root@ ~]# ulimit -a core file size (blocks, -c) 0 data seg size (kbytes, -d) unlimited file size (blocks, -f) unlimited pending signals (-i) 1024 max locked memory (kbytes, -l) 32 max memory size (kbytes, -m) unlimited open files (-n) 1024 # 打开文件数限制 pipe size (512 bytes, -p) 8 POSIX message queues (bytes, -q) 819200 stack size (kbytes, -s) 10240 cpu time (seconds, -t) unlimited max user processes (-u) 4096 virtual memory (kbytes, -v) unlimited file locks (-x) unlimited 参数 -a 显示目前资源限制的设定。 -c \u0026lt;core文件上限\u0026gt; 设定core文件的最大值，单位为区块。 -d \u0026lt;数据节区大小\u0026gt; 程序数据节区的最大值，单位为KB。 -f \u0026lt;文件大小\u0026gt; shell所能建立的最大文件，单位为区块。 -H 设定资源的硬性限制，也就是管理员所设下的限制。 -m \u0026lt;内存大小\u0026gt; 指定可使用内存的上限，单位为KB。 -n \u0026lt;文件数目\u0026gt; 指定同一时间最多可开启的文件数。 -p \u0026lt;缓冲区大小\u0026gt; 指定管道缓冲区的大小，单位512字节。 -s \u0026lt;堆叠大小\u0026gt; 指定堆叠的上限，单位为KB。 -S 设定资源的弹性限制。 -t \u0026lt;CPU时间\u0026gt; 指定CPU使用时间的上限，单位为秒。 -u \u0026lt;程序数目\u0026gt; 用户最多可开启的程序数目。 -v \u0026lt;虚拟内存大小\u0026gt; 指定可使用的虚拟内存上限，单位为KB。 调整当前用户打开文件数 [root@ ~]# ulimit -n 1234 注：此命令是设置当前用户的限制并且是临时性的。 打开数由大到小设置，否则设置不成功。\nlsof 查看打开文件数 查看某个进程打开文件数 [root@ ~]# lsof -p 进程ID |wc -l [root@ ~]# 123 查看当前系统打开文件数 [root@ ~]# lsof |wc -l [root@ ~]# 1234 参数 -a 列出打开文件存在的进程 -c\u0026lt;进程名\u0026gt; 列出指定进程所打开的文件 -g 列出GID号进程详情 -d\u0026lt;文件号\u0026gt; 列出占用该文件号的进程 +d\u0026lt;目录\u0026gt; 列出目录下被打开的文件 +D\u0026lt;目录\u0026gt; 递归列出目录下被打开的文件 -n\u0026lt;目录\u0026gt; 列出使用NFS的文件 -i\u0026lt;条件\u0026gt; 列出符合条件的进程。（4、6、协议、:端口、 @ip ） -p\u0026lt;进程号\u0026gt; 列出指定进程号所打开的文件 -u 列出UID号进程详情 -h 显示帮助信息 -v 显示版本信息 ","permalink":"https://www.iarno.cn/article/lsof/","tags":["linux"],"title":"too many open files 问题定位"},{"categories":["Go"],"contents":"这篇文章介绍了如何使用Gin pprof进行Go语言的性能分析。首先，通过导入github.com/DeanThompson/ginpprof包并使用ginpprof.Wrapper(router)将其集成到gin框架中。然后，通过命令行工具go tool pprof获取和分析程序的性能数据。文章还提供了如何使用top命令查看当前内存使用情况，并建议定期使用此命令以检测是否存在内存持续增长的情况。最后，文章提供了两个参考链接，供读者深入学习。\npprof // 导入包 import ( \u0026#34;github.com/DeanThompson/ginpprof\u0026#34; ) // gin框架直接集成 router := gin.New() ginpprof.Wrapper(router) 命令行分析 $ go tool pprof http://localhost:6060/debug/pprof/heap Fetching profile over HTTP from http://localhost:6060/debug/pprof/heap Saved profile in /Users/root/pprof/pprof.alloc_objects.alloc_space.inuse_objects.inuse_space.008.pb.gz Type: inuse_space Entering interactive mode (type \u0026#34;help\u0026#34; for commands, \u0026#34;o\u0026#34; for options) (pprof) top10 (pprof) topShowing nodes accounting for 837.48MB, 100% of 837.48MB total flat flat% sum% cum cum% 837.48MB 100% 100% 837.48MB 100% main.main.func1 top命令查看当前内存使用情况\n隔段时间继续使用此命令查看看是否有内存持续增长的数据。\n参考 https://segmentfault.com/a/1190000016412013\nhttps://eddycjy.gitbook.io/golang/di-9-ke-gong-ju/go-tool-pprof#qian-yan\n","permalink":"https://www.iarno.cn/article/pprof/","tags":["内存泄漏"],"title":"Gin pprof性能分析"},{"categories":["Go"],"contents":"这篇文章介绍了如何在Go中使用gRPC。首先，它解释了如何在.proto文件中定义服务，并使用protocol buffer编译器生成客户端和服务端代码。然后，它详细介绍了如何安装gRPC包，设置环境变量，以及如何创建gRPC服务器和客户端。最后，它提供了一个完整的gRPC示例代码，并提供了代码的GitHub链接。\n相关定义 在.proto文件中定义一个服务。 使用protocol buffer编译器生成客户端和服务端代码。 使用gRPC的Go API为你的服务写一个客户端和服务器。 安装grpc包 go get google.golang.org/grpc go get -u github.com/golang/protobuf/protoc-gen-go 设置环境变量 export PATH=$(go env GOPATH)/bin:$PATH Server 目录结构 grpc-server/ ├── go.mod ├── go.sum ├── grpc-server.iml ├── proto │ ├── demo.pb.go │ └── demo.proto ├── server.go └── service └── get_data.go 定义proto文件 syntax = \u0026#34;proto3\u0026#34;; package proto; option go_package = \u0026#34;.;proto\u0026#34;; service Demo { rpc GetData(DemoReq) returns (DemoRsp){} } message DemoReq { string a = 1; // 请求参数a } message DemoRsp{ string rel = 1; // 返回参数值 } 生成pb.go文件 protoc --go_out=plugins=grpc,paths=source_relative:. *.proto demo.pb.go文件生成\nserver.go package main import ( \u0026#34;fmt\u0026#34; \u0026#34;google.golang.org/grpc\u0026#34; \u0026#34;grpc-server/proto\u0026#34; \u0026#34;grpc-server/service\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; ) const grpcPort = 6655 func main() { l, err := net.Listen(\u0026#34;tcp\u0026#34;, fmt.Sprintf(\u0026#34;:%d\u0026#34;, grpcPort)) if err != nil { log.Fatal(err) } g := grpc.NewServer() //注册server,使用service.go文件中的Demo方法 proto.RegisterDemoServer(g, \u0026amp;service.Demo{}) if err = g.Serve(l); err != nil { log.Fatal(err) } } service.go package service import ( \u0026#34;context\u0026#34; \u0026#34;grpc-server/proto\u0026#34; ) type Demo struct { } // 方法实现，直接把请求参数返回 func (c Demo) GetData(ctx context.Context, msg *proto.DemoReq) (*proto.DemoRsp, error) { params := msg.A return \u0026amp;proto.DemoRsp{ Rel: params, }, nil } client 目录结构 grpc-client/ ├── client.go ├── go.mod ├── go.sum └── proto ├── demo.pb.go └── demo.proto 文件拷贝 将Server服务生成的demo.pb.go文件拷贝到Client目录中。\nclient.go package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;google.golang.org/grpc\u0026#34; \u0026#34;grpc-client/proto\u0026#34; ) const ( grpcAddr = \u0026#34;127.0.0.1:6655\u0026#34; ) func main() { c, err := grpc.Dial(grpcAddr, grpc.WithInsecure()) if err != nil { panic(c) } // 发送grpc请求 请求参数为123 rsp, err := proto.NewDemoClient(c). GetData(context.Background(), \u0026amp;proto.DemoReq{ A: \u0026#34;123\u0026#34;, }) // 打印返回的值 fmt.Println(rsp) } 代码地址 https://github.com/iarno/grpc-demo.git\n","permalink":"https://www.iarno.cn/article/grpc/","tags":["grpc"],"title":"Go grpc案例"},{"categories":["Go"],"contents":"这篇文章介绍了如何在Go语言中使用协程进行异步请求。文章首先解释了协程是Go语言中的轻量级线程实现，由Go运行时管理。然后，通过一个示例展示了如何使用sync.WaitGroup来同步多个协程。示例中，我们创建了两个协程，每个协程都会调用getData()函数并将结果存储在rel映射中。最后，我们等待所有协程完成，然后打印rel映射的内容。运行结果显示，两个协程都成功地获取了数据并存储在rel映射中。\nDemo package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func main() { var gp sync.WaitGroup rel := make(map[string]interface{}) gp.Add(2) go func(g *sync.WaitGroup) { defer g.Done() rel[\u0026#34;demo1\u0026#34;] = getData() }(\u0026amp;gp) go func(g *sync.WaitGroup) { defer g.Done() rel[\u0026#34;demo2\u0026#34;] = getData() }(\u0026amp;gp) gp.Wait() fmt.Println(rel) } func getData() string { return \u0026#34;test\u0026#34; } 响应结果 map[demo1:test demo2:test] ","permalink":"https://www.iarno.cn/article/sync_wait_group/","tags":["异步请求"],"title":"Golang 协程异步请求"},{"categories":["其他"],"contents":"这篇文章主要介绍了如何使用Go语言开发自定义插件。首先，我们需要下载并安装go-pluginserver，然后在CentOS环境下安装C相关的编译环境。接着，我们可以下载官方的插件示例，并通过Go语言编写自己的插件。最后，我们需要配置相关的环境变量并启动Kong服务。文章还提供了Konga插件的示例图和相关参考链接。\n1、进入官网下载所需版本 https://www.postgresql.org/download/linux/redhat/\n2、开始安装 yum install https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm -y\nyum install postgresql12 -y yum install postgresql12-server -y 3、数据库初始化与设置自启动 /usr/pgsql-12/bin/postgresql-12-setup initdb systemctl enable postgresql-12 systemctl start postgresql-12 这一步初始化数据库命令会在 /var/lib/pgsql 目录下创建名称为12文件夹，12为数据库版本。这里如果已经有对应版本的文件夹了，初始化这一步会报错，需要你自行去删除对应的文件夹再去初始化。\n4、默认会创建一个名为postgres的linux登录用户，这里进行密码修改 5、修改配置文件 5.1修改postgresql.conf 修改：#listen_addresses = \u0026#39;localhost\u0026#39;为 listen_addresses = \u0026#39;*\u0026#39; 5.2修改pg_hba.conf 修改前\n修改后\n并重新启动\nsystemctl restart postgresql-12\n6、设置登录数据库账密 su postgres #不能使用root用户登录，切换到普通用户 psql -U postgres \\password #设置用户密码 select version(); #查看版本 ","permalink":"https://www.iarno.cn/article/postgresql-centos/","tags":["网关"],"title":"centos7安装Postgresql"},{"categories":["其他"],"contents":"这篇文章主要介绍了如何在CentOS 7上安装和配置Kong网关。首先，提供了Kong安装包的下载链接，然后详细说明了如何使用YUM命令进行安装。接着，文章介绍了如何准备PostgreSQL数据库，并给出了创建用户和数据库的命令。然后，文章描述了如何配置Kong的数据库连接，并提供了相关的命令。最后，文章介绍了如何启动、检查和停止Kong服务。\n下载安装包： https://bintray.com/kong/kong-community-edition-rpm/download_file?file_path=centos/7/kong-community-edition-1.0.2.el7.noarch.rpm\n运行下面的两个命令进行安装 $ sudo yum install epel-release $ sudo yum install kong-community-edition-1.0.2.el7.noarch.rpm --nogpgcheck 准备数据库 安装PostgreSQL请参考centos7安装PostgreSQL\nKONG 使用PostgreSQL 9.5+ 或 Cassandra 3.x.x 作为数据存储。这里使用 PostgreSQL，需要事先准备好。创建一个名为 kong 的用户，并且创建一个名为 kong 的数据库。\n$ sudo -s -u postgres psql CREATE USER kong WITH PASSWORD \u0026#39;123456\u0026#39;; CREATE DATABASE kong OWNER kong; GRANT ALL PRIVILEGES ON DATABASE kong to kong; 数据库连接配置 复制配置文件： cp /etc/kong/kong.conf.default /etc/kong/kong.conf\n编辑 /etc/kong/kong.conf， 配置下面几项\n配置完后，运行下面的命令 $ kong migrations bootstrap -c /etc/kong/kong.conf 启动 KONG --vv 可以打印更多的启动日志\nkong start -c /etc/kong/kong.conf --vv 检查 KONG 是否正确运行 $ curl -i http://localhost:8001/ 或者 kong health 停止 KONG $ kong stop 参考 https://docs.konghq.com/install/centos/?_ga=2.186851116.589591982.1605191133-180474188.1599576441\n","permalink":"https://www.iarno.cn/article/kong-centos/","tags":["网关"],"title":"centos7 安装kong网关"},{"categories":["Go"],"contents":"这篇文章介绍了如何通过Go语言获取图片URL的尺寸大小。首先，我们需要导入image/gif，image/jpeg，image/png这三个包，以便解码不同格式的图片。然后，我们使用http.Get方法获取图片，使用image.Decode解码图片，最后通过m.Bounds().Dx()，m.Bounds().Dy()和m.Bounds().Size()获取图片的宽度、高度和尺寸。\n通过图片url获取图片尺寸大小(size)\n问题 当使用image.Decode时报image: unknown format· 这是因为忘记引入包import _ \u0026quot;image/jpeg\u0026quot;，image包不知道怎么Decode图片，需要导入\u0026quot;image/jpeg\u0026quot;去解码jpg图片。 gif和png图片需要导入相应\u0026quot;image/gif\u0026quot;，“image/png”。 如这三种图片类型都用到，需要都导入。\nDemo package main import ( _ \u0026#34;image/gif\u0026#34; // 必须导入该包 _ \u0026#34;image/jpeg\u0026#34; // 必须导入该包 _ \u0026#34;image/png\u0026#34; // 必须导入该包 \u0026#34;fmt\u0026#34; \u0026#34;image\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { res, err := http.Get(\u0026#34;https://www.iarno.cn/images/gopher.svg\u0026#34;) if err != nil || res.StatusCode != 200 { fmt.Println(err) } defer res.Body.Close() m, _, err := image.Decode(res.Body) if err != nil { fmt.Println(err) } fmt.Println(m.Bounds().Dx()) // 宽：32 fmt.Println(m.Bounds().Dy()) // 高：32 fmt.Println(m.Bounds().Size()) // size：(32,32) } ","permalink":"https://www.iarno.cn/article/image-url-size/","tags":["图片尺寸"],"title":"通过图片url获取图片尺寸大小"},{"categories":["其他"],"contents":"这篇文章主要介绍了如何配置Kong网关进行负载均衡。首先，文章提供了两个微服务接口用于测试。然后，通过Konga和Kong Admin API两种方式分别进行了详细的配置步骤说明。在Konga部分，包括了如何配置upstream、Service发布、Route匹配规则以及验证结果。在Kong Admin API部分，也包括了如何配置upstream、service和route。最后，文章提供了通过浏览器和命令行API进行测试的方法。\n环境说明\n注：由于docker network原因，宿主机127.0.0.1可能会访问不到，可直接使用外网域名+端口\n# 开放两个测试的微服务接口 http://myhost1:8881 http://myhost2:8882 通过konga实现 1. 配置upstream 打开Konga左侧列表菜单中的UPSTREAMS, 点击 CREATE UPSTREAM\n这里，只需要写一个Name，保证Service的配置可以正确匹配到我们就可以了。\n既然是负载均衡，自然少不了后端服务，接下来配置在Upstreams进行负载均衡的终端——Targets。 找到我们刚才创建的upstream，然后点击DETALS\nTargets to + ADD TARGET，填写测试接口信息，完成对UPSTREAM的配置\n2. 配置Service发布 配置一个Service，字段Url填写我们刚刚配置的Upstream的Name\n3. 配置Route，匹配规则 提示： 在输入 hosts,paths,methods时，要按回车！！！\n4. 验证结果 浏览器测试 通过Shift+F5 或 Ctrl+Shift+R，不使用缓存进行请求测试\n命令行API 测试\n$ curl -i -X GET --url http://localhost:8000 --header \u0026#39;Host: test.app.com\u0026#39; 通过 Kong Admin API实现 route根据paths转发给相应的service根据host（upstream的name）转发给 upstream负载均衡至targets，这就是kong的负载均衡执行流程。\n下面再学习一下通过Admin API如何完成负责均衡配置\n1. 配置upstream 创建upstream\n$ curl -X POST localhost:8001/upstreams \\ --data \u0026#34;name=app.com\u0026#34; 为upstream配置target\n$ curl -X POST localhost:8001/upstreams/app.com/targets \\ --data \u0026#34;target=myhost1:8881\u0026#34; \\ --data \u0026#34;weight=100\u0026#34; $ curl -X POST localhost:8001/upstreams/app.com/targets \\ --data \u0026#34;target=myhost2:8882\u0026#34; \\ --data \u0026#34;weight=100\u0026#34; 等同于创建了如下配置：\nupstream upstream.api { server myhost1:8881 weight=100; server myhost2:8882 weight=100; } 2. 配置service $ curl -X POST localhost:8001/services \\ --data \u0026#34;name=my-app-service\u0026#34; \\ --data \u0026#34;host=app.com\u0026#34; 3. 配置route(more) $ curl -X POST localhost:8001/services/a9b8a3e9-826b-47fa-ae78-0fcf111662a1/routes \\ --data \u0026#34;name=test-app-route\u0026#34; \\ --data \u0026#34;hosts[]=test.app.com\u0026#34; \\ --data \u0026#39;strip_path=false\u0026#39; 或者\n$ curl -X POST localhost:8001/routes \\ --data \u0026#34;name=test-app-route\u0026#34; \\ --data \u0026#34;hosts[]=test.app.com\u0026#34; \\ --data \u0026#34;service.id=a9b8a3e9-826b-47fa-ae78-0fcf111662a1\u0026#34; \\ --data \u0026#39;strip_path=false\u0026#39; ","permalink":"https://www.iarno.cn/article/upstream/","tags":["网关"],"title":"Kong网关配置负载均衡"},{"categories":["其他"],"contents":"这篇文章主要解释了宽带、带宽、流量、网速、内网、外网之间的区别。宽带是一种业务，带宽是传输速度。内网IP只在局域网内部具有唯一性，而公网IP具有世界范围的唯一性。文章还介绍了如何判断一个IP地址是内网IP还是公网IP，包括直观法和经验法。最后，文章提到了一些关于网络的常见误解和实际情况。\n大纲结构 一.带宽与宽带的区别是什么？ 带宽是量词，指的是网速的大小，比如1Mbps的意思是一兆比特每秒，这个数值就是指带宽。\n宽带是名词，说明网络的传输速率很高 。宽带的标准各不相同，最初认为128kbps以上带宽的就是宽带，而以下的就是窄带。\n但现在国内运营商一般提供至少512kbps带宽的宽带服务。也就是说，带宽是一个具体数值，而宽带则是满足一定带宽数值的一种传输标准(服务)。\n即：宽带是一种业务，带宽是传输速度。\n宽带：在数字通信中通常指64kbit/s以上信号的带宽。 窄带：在数字通信中通常指64kbit/s以下信号的带宽。 1. 宽带\n通常别人会说你家能不能上网呀？其实这个意思就是你家有没有宽带，换句话说，就是一个名词，先有了宽带一词，然后才可以说你带宽是多少，宽带与上网的速度快慢没有直接关系。\n2. 带宽\n当我们想申请宽带了，需要到一些服务提供商那里注册登记，这时会根据套餐的不同，你可能会有10Mb/s 、 20Mb/s等，通过计算机字节换算比例可以计算出自己的带宽大小。\n比如：\n1B=8b //1字节=8位1KB=1024B1MB=1024KB1GB=1024MB 我们申请的带宽是10Mb/s。这个单位中的b是小写的，而我们刚才说的1B(字节)=8b(位)，这里刚好是8倍的关系，即下载速度：10Mb / 8 = 1.25MB。\n有的人就会问，为什么要除以8？\n在计算机中，下载速度是以字节(B)为单位的，而提供商说的是以比特(b)为单位的。\n比如说: 在网上下载一个软件，都会以**B(字节)**为单位的，再比如你打开一个网页，这个网页中可能会有图片、文字、视频等内容，这些内容本质上来说，也是下载到你电脑了，然后你才能看到的。\n我们可以通过带宽来计算出自己的下载速度：\n计算方式：带宽大小 / 8\n带宽 下载速度 公式 带宽为2Mb 下载速度为256KB/s 2 / 8 = 0.25 带宽为4Mb 下载速度为512KB/s 4 / 8 = 0.5 带宽为8Mb 下载速度为1.00MB/s 8 / 8= 1.0 带宽为10Mb 下载速度为1.25MB/s 10 / 8 = 1.25 带宽为20Mb 下载速度为2.50MB/s 20 / 8 = 2.50 带宽为100Mb 下载速度为12.5MB/s 100 / 8 = 12.50 有的时候，使用一些软件测试网速时，发现与我们计算的结果有点差距，这个是正常现象，这是由于一些物理线路磨损等客观原因造成的。\n还有的时候，大家在深夜下载软件时，会发现，下载速度超过了我们理论上计算出来的值，这种情况也是存在的。\n我们可以这样理解: 比如你家在J区，那么提供商拉到J区的总线路是100Mb/s , 而你家申请的是10M，由于限制都是从路由器里设置的，这个与路由器的设置有关。\n第二种情况就是，你下载软件的服务器比较闲，这样速度也是比较快的。\n第三种情况就是我们下载软件时，可能会用迅雷呀这方面的软件，也是会影响到下载速度的。\n通俗理解的话：\n带宽就好比你的水龙头大小，网速就相好比从水龙头里出来的水流速有多快。\n以上都是说下载速度，那么上传速度是怎么计算的呢，其实上传速度这个因地域的不同而不同，一般上传速度都被提供商限制了，这个说不准。\n3.流量\n流量是对外发送数据与接收数据包的大小总和，单位是采取1024进制的，单位有 B,KB,MB(M),GB(G)。\n1G=1024MB1M=1024KB1KB=1024字节(B） 一般我们手机有 5元30MB,10元70MB的流量套餐，当我们打开一个网页，需要多少流量呢？(以前哈)\n假设某一个网页上有 100个汉字与一张100KB的图片，一个汉字=2个字节，\n即这个页面的数据大小为：100 * 2B / 1024 + 100KB = 0.2KB +100KB =100.2KB；\n每访问一次这个页面，将产生100.2KB的流量，如果是70MB的流量，那么访问几个网页基本快没有了，所以更不要说看视频了。\n二.带宽、网速和流量之间的关系\n通常情况下，我们说的：\n我家的带宽10M现在网速：200KB/s看一张图片使用了8M的流量 那么带宽、网速、流量之间有什么关系，他们分别代表什么呢？\n1、带宽单位是：比特/秒（bps）：10M=10Mbps。\n2、网速是数据传输的速度，单位是：字节/秒 (B/s， KB/s， MB/s)。\n1MB/s=1024KB/s1KB/s=1024B/s 3、流量是用户上网 发送和接收 的 数据量总和 ，单位是：字节（Byte）。\n比特是信息的最小单位：1字节=8比特 ，也就是1B=8bit 或者 1B=8b。\n1字节/秒=8比特/秒 (1B/s=8bps)。\n1比特 (1b or 1位) 是信息技术中的最小存储单位，1位代表一个“1”或者“0”。\n1B（1字节）是比较小的存储单位：一般情况下1个英文字母占1个字节，一个汉字占2个字节。\n4、他们之间的换算：带宽大小 / 8\n10M带宽(10Mb/s)=1.25MB/s网速1M带宽(1Mb/s)=0.125MB/s=128KB/s10Mbps = 10*1024Kbps =10*1024*1024bps =10*1024*1024/8 Byte/s =10/8 MB/s =1.25 MB/s 三.上行带宽和下行带宽是什么意思？各有什么作用？\n上行带宽和下行带宽，或者说上行速度和下行速度是什么意思？\n在设置路由器的限速，或者配置其它一些软件时会遇到上行速度和下行速度的配置，很多用户根本就不知道这两个所代表的意思，下面会对这两种进行详细讲解。\n在访问互联网时存在两种行为：一是上传数据，二是下载数据。上行带宽(速度) 指的是上传的速度，而下行带宽(速度) 指的是下载数据时的数度。\n再详细一点可以理解为：\n上行带宽即上行速率。\n一般是指从你的电脑上传的速度，别人对你的电脑进行通讯的速率。比如你往QQ空间上传你的相片，这个时候上传相片的速度就是上行速度，其他还有比如你往一些云盘里面上传文件的时候，这个时候的速度也是上行速率，我们可能会发现，通常情况下，上传文件的速度比我们平常使用的网络速度要慢很多。\n下行带宽即下行速率。\n一般是你从网络上的主机下载的速度，比如你下载文件的速度，打开网页的速度，这种速度就是下行速率，下行速率通常就是我们平常所说的网速，比如你的带宽是电信8M，光纤20M等，这种速度其实就是指的网络的下行速率。\n上行带宽(速度)和下行带宽(速度)是不对称的。\n一般是下行速度大于上行速度。我们平时所使用的宽带说多少M，都是指的下行带宽，因为我们上网主要是从互联网上下载数据，而上传的数据量要少很多。\n为什么在使用宽带的过程中，发现电脑下载的速度根本就达不到自己办理的宽带的标准，例如10Mb/s的宽带，下载速度只有1MB/s左右的速度，这是为什么呢?\n因为宽带运营商的带宽下行速度和Windows电脑上的下行速度的单位不一样，Windows电脑的单位是KBbs/s，而宽带运营上的单位是Kbbs/s，1B=8b(1字节=8位)。\n假设你办理了10M的宽带，10Mbps=10240Kbps/8=1280KBps,所以在你电脑的最大的下载速度只有1280KBps，也就是大概1.25MB/s左右的样子。所以不要再说宽带公司坑人、办理的宽带扣量了，这只不过是计算的单位不同引起的。\n宽带的下载速率除宽带带宽外，与计算机配置、使用的下载软件，下载的大小、下载网站的速率等均有关系，一般的下载软件都可以查看到宽带下载速率(如迅雷)。\n理想的状态下：100M光纤宽带的下行带宽在10M/S-11M/s之间；上行带宽会达到多少呢？这个要看你开通的宽带是上下行等同还是不等同了，不知道的可以咨询你的运营商。如果是等同的你的上行带宽也是10M/S - 11M/s之间；不是等同的一般上行带宽只有400kbs/s-500Kbs/s。\n注：一般企业开通的是上下行带宽等同的；家用的是不等同，一般只管下行带宽，上行的不管的。\n四.服务器的上行和下行带宽理解\n对服务器而言， 客户端下载资源消耗的是服务器的上行流量，客户端上传资源消耗的是服务器的下行流量。\n通常买的服务器，比如阿里云，一般买的带宽指的是上行带宽，下行通常是不限的。而且流量的计算一般都是以上行的来计算的。\n所以，客户端上传资源，对服务器的带宽基本没有影响，因为服务器的下行基本不限的，跟客户端本身网络的带宽有影响。\n而客户端下载资源，除了跟服务器的带宽有影响，跟客户端本身的网络带宽也有影响的。\n服务器的上行带宽\n服务器的上行带宽主要用于本地用户请求服务器上的资源(每秒钟服务器传给客户端的最大数据量，服务器流出的带宽)（即本地的下载、服务器的上传），如果是在其他机器下载服务器上的文件，用的主要是服务器的上行带宽。\n这里一定要分清楚上行带宽和下行带宽是对谁而言的，个人PC下载速度看的是自己的下行带宽和服务器的上行带宽。\n个人PC（A）与服务器（B）连接，服务器B的最大上行带宽（上行速度）决定了PC最大下载速度。\n服务器的下行带宽\n下行带宽主要用于本地用户上传文件至服务器(客户上传数据到服务器)，对于服务器来说，下行带宽是不限制的，网络因素取决于客户端当前的网络情况。\n五.内网ip和外网ip区别\n如图，假设我们的计算机是设备一，想要访问百度。\n如果使用校园网，首先需要先通过校园网的路由器把我们的内网ip转为校园网``外网ip。\n然后通过这个外网ip先连接上湖南电信的网关，最后再连接上百度的网关。\n百度把你请求的信息回传到你的校园网网关，校园网网关再把信息传给你（整个网络呈网状结构，它会自动找到一条通往百度的路径——基于深度优先搜索或者广度优先搜索）。\n这个过程就跟淘宝购物差不多。\n假设在学校里订购了一本书，淘宝那边接收到你的订单准备好物品就开始给你发货了。\n他发现你的收货地址在湖南，于是它可能从杭州出发，先去了福建的中转站，然后再到江西的中转站，突然发现江西到湖南的中转站不通，于是它只能再绕到广东的中转站，最后再到湖南中转站。这些中转站就相当于公网上的各个网关。\n到了湖南中转站，快递小哥再把包裹送到你的校门（这就是最后一级网关）。\n这时快递小哥就走了，校门处的管理人员再根据你的宿舍信息把包裹拿给你。（局域网内部的信息交流由校园网这个网关来处理）。\n这对刚接触互联网的人来说有些难以理解内网ip和公网ip的区别，那我们再举一个例子。\n我们把酒店的201房比作内网ip，那么凡是酒店都可能有201房，假如你饿了会对服务员说：“我在201房间，麻烦送些吃的过来。”而假如你要点外卖的话你对店家仅说送来201房间（内网ip），外面的人是不可能知道的，这时你就要对店家说某某市某某区某某酒店（公网ip)再加上201房，店家才能找到你。\n运营商`所分配公网`ip`地址（`某某市某某区某某酒店`）也就是所住的酒店，而`201房（内网ip）`则是`酒店管家（路由器）所分配的`。所以`一个酒店可以有很多的房间（内网ip）`，但是当外面的朋友问你住哪里，你肯定不会说`你住在201房间（内网ip）`，而会说你住在`某某市某某区某某酒店（公网ip)。 这是内网ip和公网ip的本质区别。一个对内，一个对外。\n注意点：\n1、公网ip具有世界范围的唯一性，而内网ip只在局域网内部具有唯一性。\n2、一个局域网里所有电脑的**内网**ip****是互不相同的，但共用一个外网ip。\n就像前面酒店的例子一样：你所在学校的校名在整个世界上只有一个，但是你学校里面的A栋大楼3层3号教室只有在你的校园内部才具有唯一性，别的学校也有A栋大楼3层3号教室。你只能跟快递小哥说请帮我把包裹送到xx大学，而不能直接说请帮我把包裹送到A栋大楼3层3号教室。\n3、在局域网中，每台电脑都可以自己分配自己的IP，但是这个IP只在局域网中有效。而如果你将电脑连接到互联网，你的网络提供商的服务器会为你分配一个IP地址，这个IP地址才是你在外网的IP。两个IP同时存在，一个对内，一个对外。\n4、互联网上的IP（即外网IP）地址统一由一个叫“IANA(互联网网络号分配机构)”的组织来管理。由于分配不合理以及IPv4协议本身存在的局限，现在互联网的IP地址资源越来越紧张。IANA将A、B、C类IP地址的一部分保留下来，留作局域网使用。具体如下：\nIP地址空间：\na类网10.0.0.0 ~ 10.255.255.255 b类网172.16.0.0 ~ 172.31.255.255 c类网192.168.0. 0~ 192.168.255.255 也就是说，如果你查到的ip地址在以上A、B、C类IP地址的范围内，它一定就是局域网的ip地址，否则就是公网的地址。\n5、实际生活中不仅有一级NET技术，还有二级NET技术。也就是可能你的校园网关也只是个局域网。通过多级转换可以得到更多的地址。\n这里介绍两种判断是否内网IP的方法，一种是直观法，一种是经验法。\n直观法：\n以下IP段的地址都是内网IP地址：\n10.0.0.0 到 10.255.255.255172.16.0.0 到 172.31.255.255192.168.0.0 到 192.168.255.255 经验法：\n（1）一般电信ADSL带宽在未升级大带宽前是（动态）公网IP。如果花费很少的钱给你升级为100M光纤上网，99.99%是内网IP，那0.01%是我还没有发现过案例。\n（2）代理网络运营商99.99%都是内网IP，如长城带宽、聚友E家等。\n（3）光纤上网的99.99%都是内网IP。\n转载 https://mp.weixin.qq.com/s/l-JD-ZmxzpyPBHfl7_ztQQ\n","permalink":"https://www.iarno.cn/article/network/","tags":[],"title":"宽带、带宽、流量、网速、内网、外网之间的区别"},{"categories":["Mysql"],"contents":"本文介绍了如何使用MySQL命令行工具导出Excel表格或txt文件。主要通过mysql -h x.x.x.x -P 3306 -u用户名 -p密码 -e \u0026ldquo;select * from test\u0026rdquo; 数据库 \u0026gt; /tmp/test.xls这条命令实现。其中，-h代表数据库Host，-P代表数据库端口，-u代表用户名，-p代表密码，-e代表sql语句，/tmp/test.xls代表文件名。\n命令 mysql -h x.x.x.x -P 3306 -u用户名 -p密码 -e \u0026#34;select * from test\u0026#34; 数据库 \u0026gt; /tmp/test.xls 说明\n-h ：数据库Host\n-P： 数据库端口\n-u： 用户名\n-p： 密码\n-e：sql语句\n/tmp/test.xls： 文件名\n","permalink":"https://www.iarno.cn/article/mysql-excel/","tags":[],"title":"Mysql 导出Excel表"},{"categories":["其他"],"contents":"这篇文章主要介绍了Konga插件的使用案例，包括创建消费者、添加凭证、路由添加插件以及使用Postman发送请求等步骤。文章详细解释了如何添加Basic Auth插件，并通过图文并茂的方式展示了操作流程。同时，文章还提供了相关参考链接，供读者深入学习。\nCREATE CONSUMER Cerdentials 默认为所有consumer\n创建\n例：\nUsername: test\nPassword：test\nRoute 添加插件 添加 Basic Auth 插件\n添加成功\nPostman 发送请求 注：header中的 Authorization值为之前consumer的用户名:密码base64后值\n参考 https://www.jianshu.com/p/61761396d285\n","permalink":"https://www.iarno.cn/article/kong-plugins/","tags":["网关"],"title":"Konga 插件使用案例"},{"categories":["其他"],"contents":"这篇文章主要介绍了如何使用Konga，包括安装、配置Dashboard、创建Service、配置路由以及使用Postman请求网关。文章首先提供了Konga的安装链接，然后详细解释了如何配置Dashboard，包括如何查找Kong Admin URL。接着，文章介绍了如何创建Service和配置路由，特别强调了在配置路由时，对于hosts、paths、methods等配置项需要按回车键来应用每个输入的值。最后，文章展示了如何使用Postman请求网关，包括请求的端口和Headers头的配置。\nkonga使用 konga安装请参考Docker安装kong网关\nUrl：http://127.0.0.1:1337 注册账号并登陆平台\n配置DASHBOARD 注：Kong Admin URL为kong容器分配的ip \u0026lt;请进入kong容器服务使用ifconfig命令查看\u0026gt;\n例：http://172.19.0.3:8001/\n创建Service 配置路由 注： For hosts, paths, methods and protocols, snis, sources, headers and destinations press enter to apply every value you type (这些个配置项需要按回车键)\nPostman请求网关 注：请求8000端口、配置Headers头\n","permalink":"https://www.iarno.cn/article/konga/","tags":["网关"],"title":"Konga使用"},{"categories":["其他"],"contents":"这篇文章主要介绍了如何使用Docker安装Kong网关。首先，创建一个Docker网络，然后创建PostgreSQL或Cassandra数据库。接着，准备数据库并启动Kong服务。Kong服务默认监听8000、8443、8001和8444端口。验证Kong服务后，安装Konga，一个Kong的管理界面。最后，提供了几个参考链接，包括Kong的官方文档和其他相关文章。\n创建Docker network $ docker network create kong-net 创建数据库 本案例使用的是PostgreSQL数据库\nCassandra数据库\n$ docker run -d --name kong-database \\ --network=kong-net \\ -p 9042:9042 \\ cassandra:3 PostgreSQL数据库\n$ docker run -d --name kong-database \\ --network=kong-net \\ -p 5432:5432 \\ -e \u0026#34;POSTGRES_USER=kong\u0026#34; \\ -e \u0026#34;POSTGRES_DB=kong\u0026#34; \\ -e \u0026#34;POSTGRES_PASSWORD=kong\u0026#34; \\ postgres:9.6 准备数据库 此命令使用的是postgres数据库\n$ docker run --rm \\ --network=kong-net \\ -e \u0026#34;KONG_DATABASE=postgres\u0026#34; \\ -e \u0026#34;KONG_PG_HOST=kong-database\u0026#34; \\ -e \u0026#34;KONG_PG_USER=kong\u0026#34; \\ -e \u0026#34;KONG_PG_PASSWORD=kong\u0026#34; \\ -e \u0026#34;KONG_CASSANDRA_CONTACT_POINTS=kong-database\u0026#34; \\ kong:latest kong migrations bootstrap 启动Kong服务 $ docker run -d --name kong \\ --network=kong-net \\ -e \u0026#34;KONG_DATABASE=postgres\u0026#34; \\ -e \u0026#34;KONG_PG_HOST=kong-database\u0026#34; \\ -e \u0026#34;KONG_PG_USER=kong\u0026#34; \\ -e \u0026#34;KONG_PG_PASSWORD=kong\u0026#34; \\ -e \u0026#34;KONG_CASSANDRA_CONTACT_POINTS=kong-database\u0026#34; \\ -e \u0026#34;KONG_PROXY_ACCESS_LOG=/dev/stdout\u0026#34; \\ -e \u0026#34;KONG_ADMIN_ACCESS_LOG=/dev/stdout\u0026#34; \\ -e \u0026#34;KONG_PROXY_ERROR_LOG=/dev/stderr\u0026#34; \\ -e \u0026#34;KONG_ADMIN_ERROR_LOG=/dev/stderr\u0026#34; \\ -e \u0026#34;KONG_ADMIN_LISTEN=0.0.0.0:8001, 0.0.0.0:8444 ssl\u0026#34; \\ -p 8000:8000 \\ -p 8443:8443 \\ -p 127.0.0.1:8001:8001 \\ -p 127.0.0.1:8444:8444 \\ kong:latest Kong默认监听下面端口：\n8000，监听来自客户端的HTTP流量，转发到你的upstream服务上。\n8443，监听HTTPS的流量，功能跟8000一样。可以通过配置文件禁止。\n8001，Kong的HTTP监听的api管理接口。\n8444，Kong的HTTPS监听的API管理接口。\n验证Kong服务 $ curl -i http://127.0.0.1:8001/ 安装Konga $ docker pull postgres:latest $ docker run -d -p 1337:1337 --network kong-net -e \u0026#34;TOKEN_SECRET=kongtoken\u0026#34; -e \u0026#34;DB_ADAPTER=postgres\u0026#34; -e \u0026#34;DB_HOST=kong-database\u0026#34; -e \u0026#34;DB_USER=kong\u0026#34; -e \u0026#34;DB_PASSWORD=kong\u0026#34; --name konga pantsel/konga 访问URL：http://{konga-ip}:1337/\n参考 https://docs.konghq.com/install/docker/\nhttps://www.jianshu.com/p/5049b3bb4b80\nhttps://juejin.im/post/6844903951070920711\n","permalink":"https://www.iarno.cn/article/docker-kong/","tags":["网关"],"title":"Docker安装Kong网关"},{"categories":["其他"],"contents":"这篇文章主要介绍了如何使用破解版本的Burp Suite，一个多线程请求工具。首先，文章详细解释了如何启动软件，包括运行关键的burp-loader-keygen.jar文件。然后，文章逐步指导读者如何配置host，请求信息，请求数量，线程数，并执行请求。每个步骤都配有清晰的图片指导。\n正版Burp Suite无法修改线程数，本文主要介绍破解版本的使用流程。\n破解之后下载的正版无法正常启动 ￣□￣｜｜\n启动 注：如对路径有疑问请查看macOS安装BurpSuite并破解\ncd /Applications/Burp\\ Suite\\ Community\\ Edition.app/Contents/java/app/ open . 运行burp-loader-keygen.jar文件\n点击run运行软件\n使用 配置host\n配置请求信息\n配置请求数\n配置线程数\n执行发起请求\n","permalink":"https://www.iarno.cn/article/user-burp/","tags":["多线程"],"title":"Burp Suite使用"},{"categories":["其他"],"contents":"这篇文章主要介绍了如何在MacOS上安装并破解BurpSuite。首先，从官网下载社区版的BurpSuite，然后下载注册机。由于JDK10版本过高无法破解，需要卸载JDK10并安装JDK1.8。设置好JDK环境变量后，将注册机的文件拷贝进app目录，修改vmoptions.txt文件，运行注册机并按照指示进行破解。\n1、官网下载社区版BurpSuite 2、下载注册机 3、载安装的JDK10 （版本太高破解不了） 4、安装JDK1.8 5、按参考链接破解 1、官网下载社区版BurpSuite Download for Mac OSX Burp Suite Community Edition v1.7.36\n2、下载注册机 链接:https://pan.baidu.com/s/1k-TTAVe-OdOIWSMvvVdSNA 密码:i37h Burp_Suite_Pro_v1.7.37_Loader_Keygen 有2个文件 burp-loader-keygen.jar 、burpsuite_community.jar\n$ md5 burp-loader-keygen.jar MD5 (burp-loader-keygen.jar) = a4a02e374695234412e2c66b0649b757 $ md5 burpsuite_community.jar MD5 (burpsuite_community.jar) = 0350199495f1d026363980b581b4aeb9 1234 3、卸载安装的JDK10 （版本太高破解不了） 在Finder中删除JavaAppletPlugin.plugin和JavaControlPanel.prefPane文件 路径：\n/Library/Internet\\ Plug-Ins/JavaAppletPlugin.plugin /Library/PreferencesPanes/JavaControlPanel.prefpane\n4、安装JDK1.8 下载安装JDK和JRE，设置JDK环境变量。\n$ java -version java version \u0026#34;1.8.0_211\u0026#34; Java(TM) SE Runtime Environment (build 1.8.0_211-b12) Java HotSpot(TM) 64-Bit Server VM (build 25.211-b12, mixed mode) $ /usr/libexec/java_home -V Matching Java Virtual Machines (1): 1.8.0_211, x86_64:\t\u0026#34;Java SE 8\u0026#34;\t/Library/Java/JavaVirtualMachines/jdk1.8.0_211.jdk/Contents/Home /Library/Java/JavaVirtualMachines/jdk1.8.0_211.jdk/Contents/Home 12345678910 设置环境变量 vim ~/.bash_profile export JAVA_10_HOME=/Library/Java/JavaVirtualMachines/jdk-10.0.2.jdk/Contents/Home export JAVA_8_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_181.jdk/Contents/Home alias jdk10=\u0026#39;export JAVA_HOME=$JAVA_10_HOME\u0026#39; alias jdk8=\u0026#39;export JAVA_HOME=$JAVA_8_HOME\u0026#39; #default jdk8 export JAVA_HOME=$JAVA_8_HOME $ source .bash_profile $ echo ${JAVA_HOME} /Library/Java/JavaVirtualMachines/jdk1.8.0_211.jdk/Contents/Home 5、按参考链接破解 burp-loader-keygen.jar burpsuite_community.jar 拷贝进app目录\n$ cd /Applications/Burp\\ Suite\\ Community\\ Edition.app/Contents/java/app/ vmoptions.txt 添加 -Xbootclasspath/p:burp-loader-keygen.jar\n$ pwd /Applications/Burp Suite Community Edition.app/Contents $ vim vmoptions.txt 运行 burp-loader-keygen.jar License 内容，复制 另存为一个txt文件 BurpSuiteLocense.txt（名称自定义）\n点击 Run 如下界面，Select license key file 选择 BurpSuiteLocense.txt\n点击 Manual activation\nCopy request 复制到 Activation Request ，Activation Response 复制到 Paste response 参考：\n苹果电脑macbook 安装 Burp Suite pro_v1.7.37破解版 编译BurpSuite破解版为Mac Applocation How to Uninstall Java on Mac ","permalink":"https://www.iarno.cn/article/burp/","tags":["多线程"],"title":"MacOS安装BurpSuite并破解"},{"categories":["其他"],"contents":"这篇文章主要介绍了如何破解 IntelliJ IDEA，包括 IDEA2020.2 的激活码和破解教程。文章提供了 IDEA 的下载链接和激活码的下载链接，以及如何使用 jetbrains-agent.jar 文件进行激活的步骤。请注意，这些信息仅供个人学习使用，不得用于商业用途。\nIDEA2020.2激活码，IDEA2020.2破解，IDEA2020破解教程，idea2020最新破解教程\n申明：本教程 IntelliJ IDEA 破解补丁、激活码均收集于网络，请勿商用，仅供个人学习使用。\nidea下载 链接: https://pan.baidu.com/s/1rNQq_3-TisLb255Z8JeqFQ 密码: scpv\n激活码下载 链接: https://pan.baidu.com/s/1nrpM1WjriuajRyjH14b_hw 密码: 3aqs\n使用 将jetbrains-agent.jar文件拖入idea编辑器，输入文件中激活码激活。\n","permalink":"https://www.iarno.cn/article/idea/","tags":["ide"],"title":"idea 破解"},{"categories":["Linux"],"contents":"这篇文章是关于wrk压测工具的使用指南。它首先介绍了如何安装wrk，然后详细解释了wrk的基本使用方法，包括如何查看使用帮助、版本信息，以及如何进行简单的压测。文章还介绍了如何增加header参数进行压测，以及如何压测POST接口。在每个示例后，作者都对结果进行了详细的注释和解释。\n安装 wrk支持大多数类UNIX系统，不支持windows。需要操作系统支持LuaJIT和OpenSSL，不过不用担心，大多数类Unix系统都支持。安装wrk非常简单，只要从github上下载wrk源码，在项目路径下执行make命令即可。\ngit clone https://github.com/wg/wrk // 切换到wrk目录 make make之后，会在项目路径下生成可执行文件wrk，随后就可以用其进行HTTP压测了。可以把这个可执行文件拷贝到某个已在path中的路径，比如/usr/local/bin，这样就可以在任何路径直接使用wrk了。\n默认情况下wrk会使用自带的LuaJIT和OpenSSL，如果你想使用系统已安装的版本，可以使用WITH_LUAJIT和WITH_OPENSSL这两个选项来指定它们的路径。比如：\nmake WITH_LUAJIT=/usr WITH_OPENSSL=/usr 基本使用 命令行敲下wrk，可以看到使用帮助\nUsage: wrk \u0026lt;options\u0026gt; \u0026lt;url\u0026gt; Options: -c, --connections \u0026lt;N\u0026gt; Connections to keep open -d, --duration \u0026lt;T\u0026gt; Duration of test -t, --threads \u0026lt;N\u0026gt; Number of threads to use -s, --script \u0026lt;S\u0026gt; Load Lua script file -H, --header \u0026lt;H\u0026gt; Add header to request --latency Print latency statistics --timeout \u0026lt;T\u0026gt; Socket/request timeout -v, --version Print version details Numeric arguments may include a SI unit (1k, 1M, 1G) Time arguments may include a time unit (2s, 2m, 2h) 简单翻成中文：\n使用方法: wrk \u0026lt;选项\u0026gt; \u0026lt;被测HTTP服务的URL\u0026gt; Options: -c, --connections \u0026lt;N\u0026gt; 跟服务器建立并保持的TCP连接数量 -d, --duration \u0026lt;T\u0026gt; 压测时间 -t, --threads \u0026lt;N\u0026gt; 使用多少个线程进行压测 -s, --script \u0026lt;S\u0026gt; 指定Lua脚本路径 -H, --header \u0026lt;H\u0026gt; 为每一个HTTP请求添加HTTP头 --latency 在压测结束后，打印延迟统计信息 --timeout \u0026lt;T\u0026gt; 超时时间 -v, --version 打印正在使用的wrk的详细版本信息 \u0026lt;N\u0026gt;代表数字参数，支持国际单位 (1k, 1M, 1G) \u0026lt;T\u0026gt;代表时间参数，支持时间单位 (2s, 2m, 2h) 看下版本\nwrk -v 输出： wrk 4.0.2 [epoll] Copyright (C) 2012 Will Glozer 看到是4.0.2版本的wrk，使用了epoll。这意味着我们可以用少量的线程来跟被测服务创建大量连接，进行压测。\n做一次简单压测，分析下结果\nwrk -t8 -c200 -d30s --latency \u0026#34;http://www.bing.com\u0026#34; 输出： Running 30s test @ http://www.bing.com 8 threads and 200 connections Thread Stats Avg Stdev Max +/- Stdev Latency 46.67ms 215.38ms 1.67s 95.59% Req/Sec 7.91k 1.15k 10.26k 70.77% Latency Distribution 50% 2.93ms 75% 3.78ms 90% 4.73ms 99% 1.35s 1790465 requests in 30.01s, 684.08MB read Requests/sec: 59658.29 Transfer/sec: 22.79MB 以上使用8个线程200个连接，对bing首页进行了30秒的压测，并要求在压测结果中输出响应延迟信息。以下对压测结果进行简单注释：\nRunning 30s test @ http://www.bing.com （压测时间30s） 8 threads and 200 connections （共8个测试线程，200个连接） Thread Stats Avg Stdev Max +/- Stdev （平均值） （标准差）（最大值）（正负一个标准差所占比例） Latency 46.67ms 215.38ms 1.67s 95.59% （延迟） Req/Sec 7.91k 1.15k 10.26k 70.77% （处理中的请求数） Latency Distribution （延迟分布） 50% 2.93ms 75% 3.78ms 90% 4.73ms 99% 1.35s （99分位的延迟） 1790465 requests in 30.01s, 684.08MB read （30.01秒内共处理完成了1790465个请求，读取了684.08MB数据） Requests/sec: 59658.29 （平均每秒处理完成59658.29个请求及QPS） Transfer/sec: 22.79MB （平均每秒读取数据22.79MB） 可以看到，wrk使用方便，结果清晰。并且因为非阻塞IO的使用，可以在普通的测试机上创建出大量的连接，从而达到较好的压测效果。\n增加header参数压测\nab -c50 -n1000 -t30 -H \u0026#34;token: xxx\u0026#34; \u0026#34;http://127.0.0.1:80/test/test1?a=111\u0026#34; # 注意Header头的空格 wrk -t8 -c200 -d30s --header \u0026#34;token: xxx\u0026#34; --latency \u0026#34;http://127.0.0.1:80/test/test1?a=111\u0026#34; # 注意Header头的空格 压测POST接口\n如果post请求的body不为空则指定lua文件进行读取，示例如下：\n./wrk -t 5 -c 300 -d 60 --script=post.lua --latency https://api.midukanshu.com/logstash/userbehavior/create // post.lua文件内容 wrk.method = \u0026#34;POST\u0026#34; wrk.body = \u0026#34;\u0026#34; wrk.headers[\u0026#34;Content-Type\u0026#34;] = \u0026#34;application/x-www-form-urlencoded\u0026#34; ","permalink":"https://www.iarno.cn/article/wrk/","tags":["压测"],"title":"wrk压测"},{"categories":["Linux"],"contents":"这篇文章介绍了如何使用telnet和nc命令来测试端口是否开放。首先，使用telnet ip port命令来判断端口是否通，如果连接被拒绝则端口不通。然后，文章介绍了nc命令的使用，通过nc -v localhost port命令来检测端口，如果显示Connection refused则端口不通，如果显示Connection to x.x.x.x port [tcp/http] succeeded!则端口通。\n一般情况下使用telnet ip port判断端口通不通，其实测试方法不止这一种，本文主要介绍nc检测工具。\n1、使用telnet判断 1）先用telnet连接不存在的端口\n[root@localhost ~]# telnet 10.0.250.3 80 Trying 10.0.250.3... telnet: connect to address 10.0.250.3: Connection refused #直接提示连接被拒绝 2）再连接存在的端口\n[root@localhost ~]# telnet localhost 22 Trying ::1... Connected to localhost. #看到Connected就连接成功了 Escape character is \u0026#39;^]\u0026#39;. SSH-2.0-OpenSSH_5.3 a Protocol mismatch. Connection closed by foreign host. 2、nc命令 1）不存在的端口\n[root@localhost] nc -v localhost 8889 Ncat: Version 7.50 ( https://nmap.org/ncat ) Ncat: Connection refused. 2）存在的端口\n[root@localhost] nc -v localhost 8889 Connection to x.x.x.x 8889 port [tcp/http] succeeded! ","permalink":"https://www.iarno.cn/article/nc/","tags":[],"title":"如何测试端口通不通"},{"categories":["Linux"],"contents":"这篇文章主要介绍了如何在Centos系统上安装Nodejs。首先，从Nodejs官网下载最新稳定版的安装包。然后，将安装包解压并移动到指定目录。接着，建立软连接，使得Nodejs和npm命令可以在全局范围内使用。最后，通过查看版本号来验证安装是否成功。\nNodejs官网下载 下载最新稳定版https://nodejs.org/dist/v10.16.0/node-v10.16.0-linux-x64.tar.xz\nmkdir /opt/software/ \u0026amp;\u0026amp; cd /opt/software/ tar -xvf node-v10.16.0-linux-x64.tar.xz mv node-v10.16.0-linux-x64 nodejs 建立软连接，变为全局\nln -s /opt/software/nodejs/bin/npm /usr/local/bin/ ln -s /opt/software/nodejs/bin/node /usr/local/bin/ 查看安装的版本\n[root@localhost]# node -v v10.16.0 [root@localhost]# npm -v 6.2.0 ","permalink":"https://www.iarno.cn/article/%E5%AE%89%E8%A3%85nodejs/","tags":["node"],"title":"Centos安装Nodejs"},{"categories":["Go"],"contents":"这篇文章介绍了如何使用Golang进行Excel文件的导出。它详细解释了如何使用excelize库创建一个新的Excel文件，并设置单元格的值。然后，它展示了如何将这个Excel文件作为一个下载响应发送给客户端。文章还提供了相关的Github和文档链接，供读者进一步学习和探索。\nExcel 导出 Github 地址 https://github.com/360EntSecGroup-Skylar/excelize\nDemo package excel import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;github.com/360EntSecGroup-Skylar/excelize\u0026#34; ) func Download(ctx *gin.Context) { xlsx := excelize.NewFile() xlsx.SetCellValue(\u0026#34;Sheet1\u0026#34;, \u0026#34;A2\u0026#34;, \u0026#34;我要下载一个excel文件\u0026#34;) xlsx.SetCellValue(\u0026#34;Sheet1\u0026#34;, \u0026#34;B1\u0026#34;, \u0026#34;b1\u0026#34;) xlsx.SetCellValue(\u0026#34;Sheet1\u0026#34;, \u0026#34;A1\u0026#34;, \u0026#34;有没有看到我帅气的脸庞\u0026#34;) //保存文件方式 //_ = xlsx.SaveAs(\u0026#34;./aaa.xlsx\u0026#34;) ctx.Header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/octet-stream\u0026#34;) ctx.Header(\u0026#34;Content-Disposition\u0026#34;, \u0026#34;attachment; filename=\u0026#34;+\u0026#34;Workbook.xlsx\u0026#34;) ctx.Header(\u0026#34;Content-Transfer-Encoding\u0026#34;, \u0026#34;binary\u0026#34;) //回写到web 流媒体 形成下载 _ = xlsx.Write(ctx.Writer) } 相关文档 https://xuri.me/excelize/zh-hans/\n","permalink":"https://www.iarno.cn/article/golang-excel%E5%AF%BC%E5%87%BA/","tags":["excel"],"title":"Golang excel导出"},{"categories":["Go"],"contents":"这篇文章介绍了如何在Go语言中实现蓄水池抽样法。蓄水池抽样法是一种等概率随机抽取的方法，适用于从大量数据中抽取样本。文章首先构建了一个可以放置m个元素的蓄水池，然后将前m个数依次放入。从第m+1个元素开始，以m/n的概率决定元素是否被替换到池子中。当遍历完所有元素后，就可以得出随机挑选的k个元素。该方法的时间复杂度为O(n)。\n相关文章 https://www.cnblogs.com/snowInPluto/p/5996269.html\n代码示例 const Num = 10 /** * 蓄水池抽样法 * 先构建一个可以放m个元素的蓄水池 * 将前m个数依次放入，从第m+1个元素开始，以m/n的概率决定元素是否被替换到池子中 * 当遍历完所有的的元素后，及得出随机挑选的k个元素，时间复杂度为O(n) */ func sampling(ids []string) []string { reservoir := make([]string, 10) for i := 0; i \u0026lt; Num; i++{ reservoir[i] = ids[i]; } for i := Num; i \u0026lt; len(ids); i++ { /*随机获得一个[0, i]内的随机整数*/ d := rand.Intn(i + 1) /*如果随机整数落在[0, m-1]范围内，则替换蓄水池中的元素*/ if d \u0026lt; Num { reservoir[d] = ids[i] } } return reservoir } ","permalink":"https://www.iarno.cn/article/golang-%E8%93%84%E6%B0%B4%E6%B1%A0%E6%8A%BD%E6%A0%B7%E6%B3%95/","tags":["抽样"],"title":"Golang 蓄水池抽样法"},{"categories":["其他"],"contents":"这篇文章主要介绍了如何迁移Hexo博客。首先，将原电脑上配置好的Hexo目录拷贝到新电脑，包括_config.yml、package.json、scaffolds/、source/和themes/等文件和目录。然后在新电脑上配置Hexo环境，包括安装Node.js和Hexo。接着，将博客中的node_modules设置为环境变量。最后，进入Hexo目录，安装模块并部署。\n1.将你原来电脑上已经配置好并生成的hexo目录拷到你的新电脑上，注意无需拷全部，只拷如下几个目录： _config.yml package.json scaffolds/ source/ themes/ 将这些目录放到一个目录下，如：hexo／\n2.在你的新电脑上首先配置hexo环境： 安装Node.js\n3.安装hexo，执行命令： npm install -g hexo 注:若提示hexo命令问题需要将博客中的node_modules设置为环境变量\nexport PATH=$PATH:/home/iarno.github.io/node_modules/.bin/ 4.安装好之后，进入hexo／目录 5.模块安装，执行命令： npm install npm install hexo-deployer-git --save npm install hexo-generator-feed --save npm install hexo-generator-sitemap --save 6.部署，执行命令： hexo g hexo d ","permalink":"https://www.iarno.cn/article/hexo%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB/","tags":["hexo"],"title":"hexo博客迁移"},{"categories":["Mysql"],"contents":"本文介绍了如何在MySQL中查询多个字段重复的值。文章提供了一段SQL查询语句，该语句可以从指定的表中找出在特定字段（字段1和字段2）上有重复值的记录。这个查询语句首先通过子查询找出所有在字段1和字段2上有重复值的记录，然后在主查询中返回这些记录。这种方法可以帮助我们快速找出数据库中的重复记录，对于数据清理和分析非常有用。\n代码示例 SELECT * FROM 表名 (字段1,字段2) IN (SELECT 字段1,字段2 FROM 表名 GROUP BY 字段1,字段2 HAVING COUNT(*)\u0026gt;1) ORDER BY 字段1; ","permalink":"https://www.iarno.cn/article/mysql%E6%9F%A5%E8%AF%A2%E5%A4%9A%E4%B8%AA%E5%AD%97%E6%AE%B5%E9%87%8D%E5%A4%8D%E7%9A%84%E5%80%BC/","tags":[],"title":"Mysql查询多个字段重复的值"},{"categories":["PHP"],"contents":"这篇文章主要介绍了PHP的pcntl_fork函数，这是一个用于创建子进程的函数。文章详细解释了如何使用这个函数，并通过代码示例展示了其用法。文章还进行了一个实验，测试了在创建子进程后，是父进程先执行还是子进程先执行。实验结果显示，pcntl_fork会首先执行父进程的逻辑，然后再执行子进程的逻辑。\npcntl 简介 PHP的进程控制支持实现了Unix方式的进程创建, 程序执行, 信号处理以及进程的中断。 进程控制不能被应用在Web服务器环境，当其被用于Web服务环境时可能会带来意外的结果。\n这份文档用于阐述每个进程控制函数的通常用法。关于Unix进程控制的更多信息建议您查阅 系统文档中关于fork（2）,waitpid（2），signal（2）等的部分或更全面的参考资料比如 《Unix环境高级编程》（作者：W. Richard Stevens，Addison-Wesley出版）。\nPCNTL现在使用了ticks作为信号处理的回调机制，ticks在速度上远远超过了之前的处理机制。 这个变化与“用户ticks”遵循了相同的语义。您可以使用declare() 语句在程序中指定允许发生回调的位置。这使得我们对异步事件处理的开销最小化。在编译PHP时 启用pcntl将始终承担这种开销，不论您的脚本中是否真正使用了pcntl。\n有一个调整是PHP 4.3.0之前的所有pcntl脚本要使其工作，要么在期望允许回调的（代码）部分使用 declare() ，要么使用declare()新的全局语法 使其在整个脚本范围有效。\nNote: 此扩展在 Windows 平台上不可用。\npcntl_fork PHP 4 \u0026gt;= 4.1.0, PHP 5, PHP 7)\npcntl_fork — 在当前进程当前位置产生分支（子进程）。译注：fork是创建了一个子进程，父进程和子进程 都从fork的位置开始向下继续执行，不同的是父进程执行过程中，得到的fork返回值为子进程 号，而子进程得到的是0。\n说明 int pcntl_fork ( void ) pcntl_fork()函数创建一个子进程，这个子进程仅PID（进程号） 和PPID（父进程号）与其父进程不同。fork怎样在您的系统工作的详细信息请查阅您的系统 的fork（2）手册。\n返回值 成功时，在父进程执行线程内返回产生的子进程的PID，在子进程执行线程内返回0。失败时，在 父进程上下文返回-1，不会创建子进程，并且会引发一个PHP错误。\n代码 \u0026lt;?php /** * Created by PhpStorm. * User: Object * Date: 2018/6/11 * Time: 10:12 */ const NEWLINE = \u0026#34;\\n\\n\u0026#34;; if (strtolower(php_sapi_name()) != \u0026#39;cli\u0026#39;) { die(\u0026#34;请在cli模式下运行\u0026#34;); } echo \u0026#34;当前进程：\u0026#34; . getmypid() . NEWLINE; $pid = pcntl_fork(); //fork出子进程 //fork后父进程会走自己的逻辑，子进程从处开始走自己的逻辑，堆栈信息会完全复制给子进程内存空间，父子进程相互独立 if ($pid == -1) { // 创建错误，返回-1 die(\u0026#39;进程fork失败\u0026#39;); } else if ($pid) { // $pid \u0026gt; 0, 如果fork成功，返回子进程id // 父进程逻辑 $time = microtime(true); echo \u0026#34;我是父进程:{$time}\u0026#34;.NEWLINE; } else { // $pid = 0 // 子进程逻辑 $time = microtime(true); echo \u0026#34;我是子进程:{$time}\u0026#34;.NEWLINE; } 执行结果 当前进程：17472\n我是父进程:1528697500.2961\n我是子进程:1528697500.2961\nfork后会子进程先执行还是父进程先执行逻辑呢？\n测试代码 此处我们调换上面代码的父子进程的if顺序\nif ($pid == -1) { // 创建错误，返回-1 die(\u0026#39;进程fork失败\u0026#39;); } else if (!$pid) { // $pid = 0 // 子进程逻辑 $time = microtime(true); echo \u0026#34;我是子进程:{$time}\u0026#34;.NEWLINE; } else if ($pid) { // $pid \u0026gt; 0, 如果fork成功，返回子进程id // 父进程逻辑 $time = microtime(true); echo \u0026#34;我是父进程:{$time}\u0026#34;.NEWLINE; } 执行结果 当前进程：17472\n我是父进程:1528697500.2961\n我是子进程:1528697500.2961\n测试总结 fork首先会执行父进程逻辑再执行子进程逻辑\n","permalink":"https://www.iarno.cn/article/pcntl-fork-%E5%A4%9A%E8%BF%9B%E7%A8%8B/","tags":["pcntl_fork"],"title":"pcntl_fork 多进程"},{"categories":["PHP"],"contents":"这篇文章介绍了PHP内容缓存Yac的基本使用和安装方法。Yac是一个基于共享内存，无锁的内容缓存，主要应用于让PHP进程之间共享一些简单的数据和高效地缓存一些页面结果。文章详细介绍了如何下载和安装Yac，以及如何在php.ini中进行配置。同时，文章也列出了使用Yac的一些限制，例如缓存的键长度不超过48字节，缓存值不能超过60兆字节等。最后，文章通过一个简单的例子展示了如何在PHP中使用Yac进行数据的存取。\nYac 是为PHP实现的一个基于共享内存, 无锁的内容Cache\nYac的两个应用场景: 让PHP进程之间共享一些简单的数据 高效地缓存一些页面结果 安装： wget https://github.com/laruence/yac/archive/master.zip unzip master.zip cd yac-master/ phpize ./configure --prefix=/usr/local/yac --with-php-config=/usr/local/php/bin/php-config sudo make \u0026amp;\u0026amp; make install 配置php.ini,添加如下代码: extension=yac.so yac.enable = 1 yac.keys_memory_size = 4M yac.values_memory_size = 64M yac.compress_threshold = -1 yac.enable_cli = 0 限制： 缓存的键长度不超过 48 字节\n缓存值不能超过 60 兆字节\n压缩后的缓存值不能超过 1M\n查看php配置php -m\n重启phpservice php-fpm restart\n事例: \u0026lt;?php $set = $yac = new Yac(); $yac-\u0026gt;set(\u0026#39;key\u0026#39;,\u0026#39;123\u0026#39;); $key = $yac-\u0026gt;get(\u0026#39;key\u0026#39;); var_dump($key); ","permalink":"https://www.iarno.cn/article/php%E5%86%85%E5%AE%B9%E7%BC%93%E5%AD%98yac/","tags":["yac","本地缓存"],"title":"PHP内容缓存Yac"},{"categories":["Go"],"contents":"最近在鼓捣golang守护进程的实现，无意发现了supervisor这个有意思的东西。supervisor是一个unix的系统进程管理软件，可以用它来管理apache、nginx等服务，若服务挂了可以让它们自动重启。当然也可以用来实现golang的守护进程，下面描述下具体实现。\n安装supervisor 基于centos 6.4。\nsupervisor使用python编写的，可以用easy_install安装。centos上默认有python的运行环境，安装起来就非常简单了。\n$ sudo yum install python-setuptools $ sudo easy_install supervisor 如果没有看到什么报错，那么就安装成功了，可以使用echo_supervisord_conf查看配置详情，而后生成配置文件。\n$ sudo echo_supervisord_conf \u0026gt; /etc/supervisord.conf golang http服务 先整一个简单的golang http服务\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { http.HandleFunc(\u0026#34;/\u0026#34;, func(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;Hello world\u0026#34;) }) err := http.ListenAndServe(\u0026#34;:9090\u0026#34;, nil) if err != nil { log.Fatal(\u0026#34;ListenAndServe: \u0026#34;, err) } } 直接运行这个程序会占用住终端，下面看看如何用supervisor来跑这个程序。\nsupervisor配置golang 编辑/etc/supervisord.conf，在最后增加运行程序设置\n[program:golang-http-server] command=/home/golang/simple_http_server //必须指到bin文件 autostart=true autorestart=true startsecs=10 stdout_logfile=/var/log/simple_http_server.log stdout_logfile_maxbytes=1MB stdout_logfile_backups=10 stdout_capture_maxbytes=1MB stderr_logfile=/var/log/simple_http_server.log stderr_logfile_maxbytes=1MB stderr_logfile_backups=10 stderr_capture_maxbytes=1MB 几个配置说明：\ncommand：表示运行的命令，填入完整的路径即可。\nautostart：表示是否跟随supervisor一起启动。\nautorestart：如果该程序挂了，是否重新启动。\nstdout_logfile：终端标准输出重定向文件。\nstderr_logfile：终端错误输出重定向文件。\n其余配置说明可以查看官方文档。\n启动supervisor $ sudo /usr/bin/supervisord -c /etc/supervisord.conf 如果出现什么问题，可以查看日志进行分析，日志文件路径/tmp/supervisord.log\ntips：如果修改了配置文件，可以用kill -HUP重新加载配置文件\n$ cat /tmp/supervisord.pid | xargs sudo kill -HUP 补充：\n#根据最新的配置文件，启动新配置或有改动的进程，配置没有改动的进程不会受影响而重启。 supervisorctl update #启动进程 supervisorctl start test #重启进程 supervisorctl restart test #停止进程 supervisorctl stop test 查看supervisor运行状态 $ supervisorctl golang-http-server RUNNING pid 23307, uptime 0:02:55 supervisor\u0026gt; 输入help可以查看帮助 supervisor\u0026gt; help default commands (type help ): ===================================== add clear fg open quit remove restart start stop update avail exit maintail pid reload reread shutdown status tail version supervisor运行原理 supervisor运行后本身是守护进程，通过自身来管理相应的子进程，通过观察相应的进程状态就很明了了。\n$ ps -ef | grep supervisord root 23306 1 0 07:30 ? 00:00:00 /usr/bin/python /usr/bin/supervisord -c /etc/supervisord.conf root 23331 23222 0 07:41 pts/0 00:00:00 grep supervisord $ ps -ef | grep simple_http_server root 23307 23306 0 07:30 ? 00:00:00 /home/golang/simple_http_server root 23333 23222 0 07:41 pts/0 00:00:00 grep simple_http_server 可以很直观的看出golang simple_http_server进程是supervisord的子进程。\nsupervisor是否靠谱 supervisor的诞生已经10年了，现在是3+版本，所以放心使用吧。\n参考 supervisor官网：http://supervisord.org/\n转自 supervisor运行golang守护进程\nsupervisor管理golang程序\n","permalink":"https://www.iarno.cn/article/supervisor%E7%AE%A1%E7%90%86golang%E7%A8%8B%E5%BA%8F/","tags":["进程管理"],"title":"supervisor管理golang程序"},{"categories":["Mysql"],"contents":"本文主要介绍了MySQL中utf8_bin和utf8_general_ci两种编码格式的区别。utf8_bin编码将字符串中的每个字符用二进制数据存储，区分大小写。而utf8_general_ci编码则不区分大小写，是utf8的默认编码。通过实例演示了在插入数据时，两种编码方式对大小写的处理差异。因此，在选择编码时，应注意这种区别。\nMySQL中存在多种格式的utf8编码，其中最常见的两种为：\nutf8_bin 将字符串中的每一个字符用二进制数据存储，区分大小写; utf8_genera_ci 不区分大小写，ci为case insensitive的缩写，即大小写不敏感，为utf8默认编码。\n示例： CREATE TABLE `t_bin` ( `id` int(11) DEFAULT NULL, `name` varchar(20) DEFAULT NULL, UNIQUE KEY `uk_name` (`name`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin； CREATE TABLE `t_ci` ( `id` int(11) DEFAULT NULL, `name` varchar(20) DEFAULT NULL, UNIQUE KEY `uk_name` (`name`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_general_ci; CREATE TABLE `t_default` ( `id` int(11) DEFAULT NULL, `name` varchar(20) DEFAULT NULL, UNIQUE KEY `uk_name` (`name`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; 执行以下语句： insert into t_bin values (1, \u0026#39;Alex\u0026#39;); insert into t_bin values (2, \u0026#39;alex\u0026#39;); insert into t_ci values (1, \u0026#39;Alex\u0026#39;); insert into t_ci values (2, \u0026#39;alex\u0026#39;); insert into t_default values (1, \u0026#39;Alex\u0026#39;); insert into t_default values (2, \u0026#39;alex\u0026#39;); 结果如下： root@zow 11:13:44\u0026gt;insert into t_bin values (1, \u0026#39;Alex\u0026#39;); Query OK, 1 row affected (0.01 sec) root@zow 11:14:14\u0026gt;insert into t_bin values (2, \u0026#39;alex\u0026#39;); Query OK, 1 row affected (0.01 sec) root@zow 11:14:17\u0026gt;insert into t_ci values (1, \u0026#39;Alex\u0026#39;); Query OK, 1 row affected (0.00 sec) root@zow 11:14:32\u0026gt;insert into t_ci values (2, \u0026#39;alex\u0026#39;); ERROR 1062 (23000): Duplicate entry \u0026#39;alex\u0026#39; for key \u0026#39;uk_name\u0026#39; root@zow 11:14:36\u0026gt;insert into t_default values (1, \u0026#39;Alex\u0026#39;); Query OK, 1 row affected (0.01 sec) root@zow 11:14:50\u0026gt;insert into t_default values (2, \u0026#39;alex\u0026#39;); ERROR 1062 (23000): Duplicate entry \u0026#39;alex\u0026#39; for key \u0026#39;uk_name\u0026#39; 分析： 编码为utf8_bin时，Alex和alex被认为是两个不同的值，区分大小写；\n编码为utf8_general_ci时，即默认的编码时，Alex和alex被认为是相同的值，不区分大小写。\n所以在选择编码的时候应该注意区分。\n","permalink":"https://www.iarno.cn/article/utf8-bin%E5%92%8Cutf8-general-ci%E7%BC%96%E7%A0%81%E7%9A%84%E5%8C%BA%E5%88%AB/","tags":["编码"],"title":"utf8_bin和utf8_general_ci编码的区别"},{"categories":["Mysql"],"contents":"这篇文章主要介绍了如何分析MySQL的Binlog日志。首先，我们需要确认mysqlbinlog命令是否存在。然后，文章提供了几种不同的命令来解析Binlog日志，包括全量解析、按时间范围解析、只解析某个数据库和只解析某个binlog文件。最后，文章解释了在解析过程中可能遇到的错误，这些错误可能是由于MySQL版本问题造成的，建议使用高于5.6版本的MySQL进行分析。\n相关命令 分析Mysql的Binlog日志，按时间维度查询mysql操作记录。\n#查看mysqlbinlog命令是否存在 \u0026gt;mysqlbinlog mysqlbinlog Ver 3.3 for Linux at x86_64 Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Dumps a MySQL binary log in a format usable for viewing or for piping to the mysql command line client. #全量解析 ./mysqlbinlog --base64-output=\u0026#39;DECODE-ROWS\u0026#39; --verbose *-binlog.000* \u0026gt;\u0026gt; xxxx.sql #按时间范围解析 ./mysqlbinlog --base64-output=\u0026#39;DECODE-ROWS\u0026#39; --verbose --start-datetime=\u0026#39;2016-05-20 10:00:00\u0026#39; --stop-datetime=\u0026#39;2016-05-20 12:00:00\u0026#39; *-binlog.0008* \u0026gt;\u0026gt; xxxx.sql #只解析某个数据库 ./mysqlbinlog --base64-output=\u0026#39;DECODE-ROWS\u0026#39; --verbose --database=databasename *-binlog.000* \u0026gt;\u0026gt; xxxx.sql #只解析某个binlog文件 ./mysqlbinlog --base64-output=\u0026#39;DECODE-ROWS\u0026#39; --verbose 3306-binlog.000001 \u0026gt;\u0026gt; xxxx.sql 问题 报错内容 ERROR: Error in Log_event::read_log_event(): \u0026#39;Found invalid event in binary log\u0026#39;, data_len: 31, event_type: 35 ERROR: Could not read entry at offset 120: Error in log format or read error. 原因 这是因为Mysql版本问题造成的，请选择高于5.6版本的Mysql进行分析。\n","permalink":"https://www.iarno.cn/article/%E5%88%86%E6%9E%90mysql-binlog-%E6%97%A5%E5%BF%97/","tags":["binlog"],"title":"分析Mysql Binlog 日志"},{"categories":["其他"],"contents":"这篇文章介绍了如何将博客导流到微信公众号。主要包括两个步骤：第一步是在微信公众号设置关键词回复，第二步是在博客文章页面末尾增加特定的js代码。这种方法可以帮助博客自然增长，同时也可以提高微信公众号的粉丝数量。\n使用指南 下面您只需要在公众号和博客中做如下设置，然后就等着来自博客的自然增长吧！\n第一步：公众号设置 登录要增粉的微信公众号，按如下规则设置关键词回复\n关键词，设置为：vip 回复内容，设置为如下文本内容： \u0026lt;a href=\u0026#34;https://my.openwrite.cn/code/generate?blogId=21839-1591198660133-778\u0026#34;\u0026gt;点击该链接，获取博客解锁验证码\u0026lt;/a\u0026gt; 第二步：博客设置 在您博客的文章页面的末尾，增加如下js代码。\n\u0026lt;script src=\u0026#34;https://my.openwrite.cn/js/readmore.js\u0026#34; type=\u0026#34;text/javascript\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; document.getElementsByClassName(\u0026#39;article-container\u0026#39;)[0].setAttribute(\u0026#34;id\u0026#34;,\u0026#34;container\u0026#34;) const btw = new BTWPlugin(); btw.init({ id: \u0026#39;container\u0026#39;, blogId: \u0026#39;21839-1603629348090-282\u0026#39;, name: \u0026#39;努力升级中\u0026#39;, qrcode: \u0026#39;https://i.loli.net/2020/10/25/fVQpdYESFXjGBmo.png\u0026#39;, keyword: \u0026#39;验证码\u0026#39;, }); \u0026lt;/script\u0026gt; 其中id中设置的container需要用户根据文章页面中的文章容器来调整，或者直接将文章最外面的容器设置为该id。\nOpenWrite 本篇文章已使用\n博客群发助手(https://openwrite.cn/)\nReadMore(https://openwrite.cn/openwrite/openwrite-readmore/)\n参考地址 https://my.openwrite.cn/user/blog2weixin/list\n","permalink":"https://www.iarno.cn/article/%E5%8D%9A%E5%AE%A2%E5%AF%BC%E6%B5%81%E5%85%AC%E4%BC%97%E5%8F%B7/","tags":[],"title":"博客导流公众号"},{"categories":["PHP"],"contents":"这篇文章主要讨论了跨域的概念、同源策略及其限制，以及如何处理跨域问题。文章首先解释了什么是跨域，然后介绍了同源策略及其对Cookie、LocalStorage、IndexedDB等存储性内容、DOM节点和AJAX请求的限制。最后，文章详细介绍了CORS（跨源资源共享）的原理和优缺点，并提供了PHP代码示例，展示了如何在服务器端添加CORS头部和验证Referer以防止CSRF攻击。\n一、什么是跨域 url的组成 JavaScript出于安全方面的考虑，不允许跨域调用其他页面的对象。那什么是跨域呢，简单地理解就是因为JavaScript同源策略的限制，a.com域名下的js无法操作b.com或是c.a.com域名下的对象。\n当协议、子域名、主域名、端口号中任意一个不相同时，都算作不同域。不同域之间相互请求资源，就算作“跨域”。 例如：http://www.abc.com/index.html 请求 http://www.efg.com/service.php。\n有一点必须要注意：跨域并不是请求发不出去，请求能发出去，服务端能收到请求并正常返回结果，只是结果被浏览器拦截了。之所以会跨域，是因为受到了同源策略的限制，同源策略要求源相同才能正常进行通信，即协议、域名、端口号都完全一致。\n大家可以参照下图，有助于深入理解跨域。 特别说明两点： 第一：如果是协议和端口造成的跨域问题“前台”是无能为力的。\n第二：在跨域问题上，域仅仅是通过“URL的首部”来识别而不会根据域名对应的IP地址是否相同来判断。“URL的首部”可以理解为“协议, 域名和端口必须匹配”。\n二、什么是同源策略及其限制 同源策略限制从一个源加载的文档或脚本如何与来自另一个源的资源进行交互。这是一个用于隔离潜在恶意文件的关键的安全机制。它的存在可以保护用户隐私信息，防止身份伪造等(读取Cookie)。\n同源策略限制内容有： Cookie、LocalStorage、IndexedDB 等存储性内容\nDOM 节点\nAJAX 请求不能发送\n但是有三个标签是允许跨域加载资源： 1.\u0026lt;img src=XXX\u0026gt; 2.\u0026lt;link href=XXX\u0026gt; 3.\u0026lt;script src=XXX\u0026gt; 接下来我们讨论下有哪些处理跨域的方法。但所有的跨域都必须经过信息提供方的允许。如果未经允许即可获取，那是浏览器同源策略出现漏洞。\n处理跨域方法——CORS 1.CORS原理 整个CORS通信过程，都是浏览器自动完成，不需要用户参与。对于开发者来说，CORS通信与同源的AJAX通信没有差别，代码完全一样。浏览器一旦发现AJAX请求跨源，就会自动添加一些附加的头信息，有时还会多出一次附加的请求，但用户不会有感觉。因此，实现CORS通信的关键是服务器。只要服务器实现了CORS接口，就可以跨源通信。\n2.CORS优缺点 CORS要求浏览器(\u0026gt;IE10)和服务器的同时支持，是跨域的根本解决方法，由浏览器自动完成。 优点在于功能更加强大支持各种HTTP Method，缺点是兼容性不如JSONP。 只需要在服务器端做一些小小的改造即可：\n/** * 验证Refer，允许跨域访问 * @param mixed $whiteHostList 白名单域名或ip */ public static function addCrosHeader($whiteHostList = array()) { if (!isset($_SERVER[\u0026#39;HTTP_REFERER\u0026#39;])) { return; } $origin = parse_url($_SERVER[\u0026#39;HTTP_REFERER\u0026#39;], PHP_URL_HOST); if (in_array($origin, $whiteHostList)) { header(\u0026#34;Access-Control-Allow-Origin: \u0026#34;.\u0026#34;https://\u0026#34;.$origin); // header(\u0026#34;Access-Control-Allow-Origin: \u0026#34;.\u0026#34;http://\u0026#34;.$origin.\u0026#34;:8081\u0026#34;); header(\u0026#39;Access-Control-Allow-Credentials: true\u0026#39;); // 跨域cookie生效必备 header(\u0026#39;Access-Control-Allow-Methods: GET,POST,PUT,DELETE,OPTIONS\u0026#39;); header(\u0026#39;Access-Control-Allow-Headers: X-Requested-With,X_Requested_With,Content-Type\u0026#39;); header(\u0026#39;P3P: CP=\u0026#34;CAO PSA OUR\u0026#34;\u0026#39;); } return; } 验证Refer防止Refer攻击 /** * 验证Refer，防范csrf攻击 * @param mixed $whiteHostList 白名单域名或ip * @return boolean true/false */ public static function checkReferer($whiteHostList = array()) { $referer = isset($_SERVER[\u0026#39;HTTP_REFERER\u0026#39;]) ? $_SERVER[\u0026#39;HTTP_REFERER\u0026#39;] : false; if (empty($referer)) { return false; } // referer 必须以 http 或 https 开头 if (strpos($referer, \u0026#39;http://\u0026#39;) !== 0 \u0026amp;\u0026amp; strpos($referer, \u0026#39;https://\u0026#39;) !== 0) { return false; } // 设置默认域名 if (empty($whiteHostList)) { $whiteHostList = array( $_SERVER[\u0026#39;HTTP_HOST\u0026#39;] ); } elseif (is_string($whiteHostList)) { $whiteHostList = array( $whiteHostList ); } // refer 主机地址判断 $refererHost = parse_url($referer, PHP_URL_HOST); if (is_array($whiteHostList) \u0026amp;\u0026amp; in_array($refererHost, $whiteHostList)) { return true; } else { return false; } } ","permalink":"https://www.iarno.cn/article/%E8%B7%A8%E5%9F%9F/","tags":["跨域"],"title":"跨域"},{"categories":["其他"],"contents":"本文提供了在阿里云服务器上设置VPN服务器的全面指南。它涵盖了Linux服务器的初始设置，IPsec VPN的安装，以及从iOS和Mac设备连接到VPN的详细说明。文章还提供了故障排除链接和进一步阅读的参考。\nwget https://git.io/vpnsetup -O vpnsetup.sh \u0026amp;\u0026amp; sudo sh vpnsetup.sh 如果使用 CentOS，请将上面的地址换成 https://git.io/vpnsetup-centos。\n你的 VPN 登录凭证将会被自动随机生成，并在安装完成后显示在屏幕上。\n如需了解其它安装选项，以及如何配置 VPN 客户端，请继续阅读以下部分。\n一个专用服务器或者虚拟专用服务器 (VPS)。OpenVZ VPS 不受支持。\n注：需开启udp 500和4500端口\nios连接 进入设置 -\u0026gt; 通用 -\u0026gt; VPN。 单击 添加VPN配置\u0026hellip;。 单击 类型 。选择 L2TP 并返回。 在 描述 字段中输入任意内容。 在 服务器 字段中输入你的 VPN 服务器 IP。 在 帐户 字段中输入你的 VPN 用户名。 在 密码 字段中输入你的 VPN 密码。 在 密钥 字段中输入你的 VPN IPsec PSK。 启用 发送所有流量 选项。 单击右上角的 完成。 启用 VPN 连接。 VPN 连接成功后，会在通知栏显示图标。最后你可以到 这里 检测你的 IP 地址，应该显示为你的 VPN 服务器 IP。 如果在连接过程中遇到错误，请参见 故障排除。\nMac连接 打开系统偏好设置并转到网络部分。 在窗口左下角单击 + 按钮。 从 接口 下拉菜单选择 VPN。 从 VPN类型 下拉菜单选择 IPSec 上的 L2TP。 在 服务名称 字段中输入任意内容。 单击 创建。 在 服务器地址 字段中输入你的 VPN 服务器 IP。 在 帐户名称 字段中输入你的 VPN 用户名。 单击 鉴定设置 按钮。 在 用户鉴定 部分，选择 密码 单选按钮，然后输入你的 VPN 密码。 在 机器鉴定 部分，选择 共享的密钥 单选按钮，然后输入你的 VPN IPsec PSK。 单击 好。 选中 在菜单栏中显示 VPN 状态 复选框。 （重要） 单击 高级 按钮，并选中 通过VPN连接发送所有通信 复选框。 单击 TCP/IP 选项卡，并在 配置IPv6 部分中选择 仅本地链接。 单击 好 关闭高级设置，然后单击 应用 保存VPN连接信息。 要连接到 VPN： 使用菜单栏中的图标，或者打开系统偏好设置的网络部分，选择 VPN 并单击 连接。最后你可以到 这里 检测你的 IP 地址，应该显示为你的 VPN 服务器 IP。 如果在连接过程中遇到错误，请参见 故障排除。\n服务器安装 https://github.com/hwdsl2/setup-ipsec-vpn/blob/master/README-zh.md\n设备连接 https://github.com/hwdsl2/setup-ipsec-vpn/blob/master/docs/clients-zh.md\n","permalink":"https://www.iarno.cn/article/%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BAvpn/","tags":["vpn"],"title":"阿里云服务器搭建vpn"},{"categories":null,"contents":"","permalink":"https://www.iarno.cn/search/","tags":null,"title":"Search Results"}]